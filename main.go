package main

import (
	"context"
	"encoding/csv"
	"encoding/json"
	"encoding/xml"
	"fmt"
	"io"
	"iter"
	"log"
	"maps"
	"net"
	"net/http"
	"os"
	"regexp"
	"strings"
	"sync"
	"time"

	"google.golang.org/genai"
)

type Feed struct {
	Title    string
	RSSUrl   string
	Website  string
	Category string
}

type RSS struct {
	Channel Channel `xml:"channel"`
}

type Channel struct {
	Title       string `xml:"title"`
	Description string `xml:"description"`
	Link        string `xml:"link"`
	Items       []Item `xml:"item"`
}

type Item struct {
	Title       string `xml:"title"`
	Description string `xml:"description"`
	Link        string `xml:"link"`
	PubDate     string `xml:"pubDate"`
	GUID        string `xml:"guid"`
}

type FeedItem struct {
	Title       string
	Link        string
	PubDate     time.Time
	Description string
	Category    string
	Source      string
}

type Config struct {
	FeedsFile    string `json:"feeds_file"`
	GeminiModel  string `json:"gemini_model"`
	CutoffHours  int    `json:"cutoff_hours"`
	HTTPTimeout  int    `json:"http_timeout_seconds"`
}

const (
	MaxURLs = 20 // ìµœëŒ€ URL ê°œìˆ˜ (ê³ ì •ê°’)
)

var (
	client       *http.Client
	geminiClient *genai.Client
	config       Config
)

func main() {
	// ì„¤ì • íŒŒì¼ ë¡œë“œ
	err := loadConfig("config.json")
	if err != nil {
		log.Fatal("ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨:", err)
	}

	// Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
	ctx := context.Background()
	apiKey := os.Getenv("GEMINI_API_KEY")
	if apiKey == "" {
		log.Fatal("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
	}

	geminiClient, err = genai.NewClient(ctx, &genai.ClientConfig{
		APIKey:  apiKey,
		Backend: genai.BackendGeminiAPI,
	})
	if err != nil {
		log.Fatal("Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:", err)
	}

	feeds, err := loadFeeds(config.FeedsFile)
	if err != nil {
		log.Fatal("feeds íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜:", err)
	}

	cutoffTime := time.Now().Add(-time.Duration(config.CutoffHours) * time.Hour)
	var wg sync.WaitGroup
	itemsChan := make(chan FeedItem, 1000)

	for _, feed := range feeds {
		wg.Add(1)
		go func(f Feed) {
			defer wg.Done()
			processFeed(f, cutoffTime, itemsChan)
		}(feed)
	}

	go func() {
		wg.Wait()
		close(itemsChan)
	}()

	var allItems []FeedItem
	for item := range itemsChan {
		allItems = append(allItems, item)
	}

	if len(allItems) == 0 {
		fmt.Printf("ìµœê·¼ %dì‹œê°„ ë‚´ ìƒˆë¡œìš´ í”¼ë“œê°€ ì—†ìŠµë‹ˆë‹¤.\n", config.CutoffHours)
		return
	}

	// AI ìš”ì•½ ìˆ˜í–‰
	fmt.Println("AI ìš”ì•½ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
	summary, err := generateAISummary(allItems)
	if err != nil {
		log.Printf("AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: %v", err)
		summary = "AI ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
	}

	outputMarkdown(allItems, summary)
}

func loadFeeds(filename string) ([]Feed, error) {
	file, err := os.Open(filename)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	reader := csv.NewReader(file)
	records, err := reader.ReadAll()
	if err != nil {
		return nil, err
	}

	var feeds []Feed
	for i, record := range records {
		if i == 0 { // í—¤ë” ìŠ¤í‚µ
			continue
		}
		if len(record) < 4 {
			log.Printf("CSV ë ˆì½”ë“œ %dë²ˆì§¸ ì¤„: í•„ë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (í•„ìš”: 4ê°œ, ì‹¤ì œ: %dê°œ)", i+1, len(record))
			continue
		}
		if strings.TrimSpace(record[1]) == "" {
			log.Printf("CSV ë ˆì½”ë“œ %dë²ˆì§¸ ì¤„: RSS URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤", i+1)
			continue
		}
		feeds = append(feeds, Feed{
			Title:    strings.TrimSpace(record[0]),
			RSSUrl:   strings.TrimSpace(record[1]),
			Website:  strings.TrimSpace(record[2]),
			Category: strings.TrimSpace(record[3]),
		})
	}

	return feeds, nil
}

// initHTTPClient initializes HTTP client with Go 1.23+ network improvements
func initHTTPClient() {
	client = &http.Client{
		Timeout: time.Duration(config.HTTPTimeout) * time.Second,
		Transport: &http.Transport{
			DialContext: (&net.Dialer{
				Timeout:   30 * time.Second,
				KeepAlive: 30 * time.Second,
				KeepAliveConfig: net.KeepAliveConfig{
					Enable:   true,
					Idle:     30 * time.Second,
					Interval: 10 * time.Second,
					Count:    3,
				},
			}).DialContext,
		},
	}
}

func loadConfig(filename string) error {
	// ê¸°ë³¸ê°’ ì„¤ì •
	config = Config{
		FeedsFile:   "feeds.csv",
		GeminiModel: "gemini-2.5-pro",
		CutoffHours: 24,
		HTTPTimeout: 15,
	}

	// HTTP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
	initHTTPClient()

	// íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
	if _, err := os.Stat(filename); os.IsNotExist(err) {
		log.Printf("ì„¤ì • íŒŒì¼ %sì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.", filename)
		return nil
	}

	// íŒŒì¼ ì½ê¸°
	file, err := os.Open(filename)
	if err != nil {
		return fmt.Errorf("ì„¤ì • íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: %v", err)
	}
	defer file.Close()

	// JSON íŒŒì‹±
	decoder := json.NewDecoder(file)
	if err := decoder.Decode(&config); err != nil {
		return fmt.Errorf("ì„¤ì • íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: %v", err)
	}

	// HTTP í´ë¼ì´ì–¸íŠ¸ ì¬ì´ˆê¸°í™”
	initHTTPClient()

	log.Printf("ì„¤ì • ë¡œë“œ ì™„ë£Œ: feeds_file=%s, gemini_model=%s, cutoff_hours=%d, max_urls=%d(ê³ ì •), http_timeout=%d", 
		config.FeedsFile, config.GeminiModel, config.CutoffHours, MaxURLs, config.HTTPTimeout)
	return nil
}

func processFeed(feed Feed, cutoffTime time.Time, itemsChan chan<- FeedItem) {
	resp, err := client.Get(feed.RSSUrl)
	if err != nil {
		log.Printf("í”¼ë“œ %s ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: %v", feed.Title, err)
		return
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		log.Printf("í”¼ë“œ %s ì½ê¸° ì‹¤íŒ¨: %v", feed.Title, err)
		return
	}

	// XML ì—”í‹°í‹° ì˜¤ë¥˜ ìˆ˜ì •
	bodyStr := fixXMLEntities(string(body))

	var rss RSS
	if err := xml.Unmarshal([]byte(bodyStr), &rss); err != nil {
		log.Printf("í”¼ë“œ %s XML íŒŒì‹± ì‹¤íŒ¨: %v", feed.Title, err)
		return
	}

	for _, item := range rss.Channel.Items {
		pubDate, err := parseDate(item.PubDate)
		if err != nil {
			continue
		}

		if pubDate.After(cutoffTime) {
			itemsChan <- FeedItem{
				Title:       item.Title,
				Link:        item.Link,
				PubDate:     pubDate,
				Description: item.Description,
				Category:    feed.Category,
				Source:      feed.Title,
			}
		}
	}
}

func parseDate(dateStr string) (time.Time, error) {
	formats := []string{
		time.RFC1123Z,
		time.RFC1123,
		time.RFC822Z,
		time.RFC822,
		"2006-01-02T15:04:05Z",
		"2006-01-02T15:04:05-07:00",
		"2006-01-02 15:04:05",
		"Mon, 02 Jan 2006 15:04:05 -0700",
		"Mon, 02 Jan 2006 15:04:05 MST",
	}

	for _, format := range formats {
		if t, err := time.Parse(format, dateStr); err == nil {
			return t, nil
		}
	}

	return time.Time{}, fmt.Errorf("ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: %s", dateStr)
}


func generateAISummary(items []FeedItem) (string, error) {
	ctx := context.Background()
	
	// í”¼ë“œ ë°ì´í„°ì™€ URL ì¤€ë¹„
	feedData, urls := prepareFeedData(items)
	
	// í”„ë¡¬í”„íŠ¸ ìƒì„±
	prompt := generatePrompt(feedData, urls)
	
	// Gemini API í˜¸ì¶œ
	return callGeminiAPI(ctx, prompt)
}

// prepareFeedData prepares feed data and extracts URLs using Go 1.23+ iterators
func prepareFeedData(items []FeedItem) (string, []string) {
	var feedData strings.Builder
	feedData.WriteString("ë‹¤ìŒì€ ìµœì‹  AI ê´€ë ¨ í”¼ë“œ ë°ì´í„°ì…ë‹ˆë‹¤:\n\n")

	// Go 1.23+ iteratorë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë“œ ì•„ì´í…œ ì²˜ë¦¬
	var urls []string
	i := 1
	for item := range feedItemIterator(items) {
		feedData.WriteString(fmt.Sprintf("%d. **%s**\n", i, item.Title))
		feedData.WriteString(fmt.Sprintf("   - ì¶œì²˜: %s\n", item.Source))
		feedData.WriteString(fmt.Sprintf("   - ë§í¬: %s\n", item.Link))
		feedData.WriteString(fmt.Sprintf("   - ë‚ ì§œ: %s\n", item.PubDate.Format("2006-01-02")))
		if item.Description != "" {
			feedData.WriteString(fmt.Sprintf("   - ìš”ì•½: %s\n", cleanHTML(item.Description)))
		}
		feedData.WriteString("\n")
		i++
	}

	// URL iteratorë¥¼ ì‚¬ìš©í•˜ì—¬ URL ìˆ˜ì§‘
	for url := range urlIterator(items) {
		urls = append(urls, url)
	}

	// ì¤‘ë³µ URL ì œê±° ë° ìµœëŒ€ ê°œìˆ˜ ì œí•œ
	urls = removeDuplicateURLs(urls, MaxURLs)

	// URLë“¤ì„ ì¶”ê°€ë¡œ ëª…ì‹œ
	if len(urls) > 0 {
		feedData.WriteString("ìœ„ ê¸°ì‚¬ë“¤ì˜ ì „ì²´ ë‚´ìš©ì„ ë¶„ì„í•˜ê¸° ìœ„í•´ ë‹¤ìŒ URLë“¤ì„ ì°¸ì¡°í•˜ì„¸ìš”:\n")
		for _, url := range urls {
			feedData.WriteString(fmt.Sprintf("- %s\n", url))
		}
		feedData.WriteString("\n")
	}
	
	return feedData.String(), urls
}

// generatePrompt creates the AI prompt
func generatePrompt(feedData string, urls []string) string {
	return fmt.Sprintf(`ë‹¹ì‹ ì€ ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ëŠ” ì—ë””í„°ì…ë‹ˆë‹¤. ë°”ìœ ëŒ€í•™ìƒë“¤ì´ ë§¤ì¼ 3-5ë¶„ ì•ˆì— ì½ì„ ìˆ˜ ìˆëŠ” ëª…í™•í•˜ê³  í¥ë¯¸ë¡œìš´ ì¼ê°„ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

%s

**ì¤‘ìš”í•œ ì¶œë ¥ ì§€ì¹¨:**
- ì‘ë‹µì— URL ì ‘ê·¼ ìƒíƒœ, ë¶„ì„ ê³¼ì •, ë‚´ë¶€ ì²˜ë¦¬ ì •ë³´ ë“±ì˜ ë””ë²„ê·¸ ë‚´ìš©ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- ë°”ë¡œ ì™„ì„±ëœ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œë§Œ ì¶œë ¥í•˜ì„¸ìš”
- ì‘ë‹µì€ ë°˜ë“œì‹œ "## ğŸŒ… ì˜¤ëŠ˜ì˜ í…Œí¬ í—¤ë“œë¼ì¸"ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤
- ì–´ë–¤ ë©”íƒ€ ì •ë³´ë‚˜ ê³¼ì • ì„¤ëª…ë„ í¬í•¨í•˜ì§€ ë§ê³ , ìˆœìˆ˜í•œ ë‰´ìŠ¤ ë¸Œë¦¬í•‘ë§Œ ì œê³µí•˜ì„¸ìš”
- GitHub Flavored Markdownì„ ì™„ë²½íˆ ì§€ì›í•˜ë„ë¡ ì‘ì„±í•˜ì„¸ìš” (í…Œì´ë¸”, ì½”ë“œ ë¸”ë¡, ì²´í¬ë°•ìŠ¤ ë“± í•„ìš”ì‹œ ì‚¬ìš©)

**ëª©í‘œ:** 
ì˜¤ëŠ˜ ê¸°ìˆ  ì—…ê³„ì—ì„œ ì¼ì–´ë‚œ ì¤‘ìš”í•œ ì¼ë“¤ì„ ëŒ€í•™ìƒ ìˆ˜ì¤€ì—ì„œ ì´í•´í•  ìˆ˜ ìˆê²Œ ì„¤ëª…í•˜ì„¸ìš”.

**ì‘ì„± ìŠ¤íƒ€ì¼:**
- ëŒ€í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì ì ˆí•œ ìˆ˜ì¤€ì˜ ì–¸ì–´ ì‚¬ìš©
- ì „ë¬¸ìš©ì–´ëŠ” ê°„ë‹¨í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì‚¬ìš© (ë„ˆë¬´ ì‰½ê²Œ í’€ì–´ì“°ì§€ ë§ê³ )
- ê¸°ìˆ ì  ì›ë¦¬ë³´ë‹¤ëŠ” ì‹¤ìš©ì  ì˜ë¯¸ì™€ íŠ¸ë Œë“œì— ì§‘ì¤‘
- ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° í¸í•œ ë¬¸ì²´ ì‚¬ìš©

**ë³´ê³ ì„œ êµ¬ì¡° (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ì§€ì¼œì£¼ì„¸ìš”):**

## ğŸŒ… ì˜¤ëŠ˜ì˜ í…Œí¬ í—¤ë“œë¼ì¸
*ê°€ì¥ ì¤‘ìš”í•œ 2-3ê°œ ì´ìŠˆë¥¼ í•œ ì¤„ë¡œ*

## ğŸ”¥ ì£¼ëª©í•  ì†Œì‹
### ğŸ“± ì£¼ìš” ê¸°ì—… ë™í–¥
*í”¼ë“œì— ë“±ì¥í•˜ëŠ” ê¸°ì—…ë“¤ì˜ ìµœì‹  ë°œí‘œì™€ ê·¸ ì˜ë¯¸*

### ğŸš€ ê¸°ìˆ  ë°œì „  
*ìƒˆë¡œìš´ ê¸°ìˆ  íŠ¸ë Œë“œì™€ ë°œì „ ë°©í–¥*

### ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì 
*ì‚°ì—… ë³€í™”ì™€ ì§„ë¡œì— ì£¼ëŠ” ì‹œì‚¬ì *

## âš¡ í•œ ì¤„ ìš”ì•½
*ì˜¤ëŠ˜ ì†Œì‹ ì¤‘ ê°€ì¥ ê¸°ì–µí•  ë§Œí•œ ê²ƒ í•˜ë‚˜*

**ì¤‘ìš” ì§€ì‹œì‚¬í•­:**
- ìœ„ì— ë‚˜ì—´ëœ URLë“¤ì˜ ì „ì²´ ë‚´ìš©ì„ ì‹¤ì œë¡œ ì½ê³  ë¶„ì„í•˜ì„¸ìš”
- URL context ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ê° ê¸°ì‚¬ì˜ ìƒì„¸ ë‚´ìš©ì„ íŒŒì•…í•˜ì„¸ìš”
- í•„ìš”ì‹œ Google Search ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì¶”ê°€ ë°°ê²½ ì •ë³´ë‚˜ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”
- **ë°˜ë“œì‹œ ìœ„ì— ëª…ì‹œëœ ë§ˆí¬ë‹¤ìš´ í—¤ë” êµ¬ì¡°ë¥¼ ì •í™•íˆ ë”°ë¥´ì„¸ìš” (## ğŸŒ… ì˜¤ëŠ˜ì˜ í…Œí¬ í—¤ë“œë¼ì¸, ## ğŸ”¥, ### ğŸ“±, ### ğŸš€, ### ğŸ’¼, ## âš¡)**
- ì „ë¬¸ ìš©ì–´ëŠ” ê°„ë‹¨í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì‚¬ìš© (ì˜ˆ: "íŒŒìš´ë°ì´ì…˜ ëª¨ë¸(ëŒ€ê·œëª¨ AI ê¸°ë°˜ ëª¨ë¸)")
- ê° ì„¹ì…˜ì€ 2-3ê°œ í¬ì¸íŠ¸ë¡œ ì œí•œ
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„° í™œìš©ìœ¼ë¡œ ì‹ ë¢°ì„± í™•ë³´
- **ğŸš¨ CRITICAL: ë³¸ë¬¸ì— ì¸ìš© ì—†ìœ¼ë©´ ì™„ì „íˆ ì‹¤íŒ¨ì…ë‹ˆë‹¤! ğŸš¨**
- **ëª¨ë“  ì‚¬ì‹¤, ìˆ˜ì¹˜, íšŒì‚¬ëª…, ë°œí‘œ ë‚´ìš©, ê¸°ìˆ ëª… ë’¤ì— ë°˜ë“œì‹œ [^1], [^2], [^3] í˜•íƒœ ì¸ìš© í•„ìˆ˜**
- **ë³¸ë¬¸ ì‘ì„± ê·œì¹™: ë¬¸ì¥ì„ ì“¸ ë•Œë§ˆë‹¤ "ì´ ì •ë³´ëŠ” ì–´ëŠ ê¸°ì‚¬ì—ì„œ ì™”ëŠ”ê°€?"ë¥¼ ìë¬¸í•˜ê³  ì¦‰ì‹œ [^ìˆ«ì] ì¶”ê°€**
- **ì¤‘ìš”: ì—¬ëŸ¬ ê°œë¥¼ ì¸ìš©í•  ë•Œ [^3, ^4] ê¸ˆì§€! ë°˜ë“œì‹œ [^3][^4] í˜•íƒœë¡œ ì—°ì† ì‘ì„±**
- ì˜¬ë°”ë¥¸ ì˜ˆì‹œë“¤:
  - "Appleì´ 16ë§Œ 2ì²œ ëª…ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤[^2]"
  - "Googleì´ ì •ì‹ ê±´ê°• AI ë„êµ¬ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤[^4]" 
  - "ì‹œê°„ë‹¹ 100TB ì†ë„ë¡œ ì´ì „í–ˆìŠµë‹ˆë‹¤[^5]"
  - "GeminiëŠ” ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì…ë‹ˆë‹¤[^1]"
  - "Googleê³¼ Appleì˜ ì‚¬ë¡€ë¥¼ ë³´ë©´[^3][^4]" (ì—¬ëŸ¬ ì¸ìš© ì‹œ)
- **ì˜ëª»ëœ ì˜ˆì‹œ (ì ˆëŒ€ ê¸ˆì§€):**
  - "Appleì´ 16ë§Œ 2ì²œ ëª…ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤" (ì¸ìš© ì—†ìŒ)
  - "ìµœê·¼ AI ê¸°ìˆ ì´ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤" (ì¶œì²˜ ì—†ëŠ” ì¼ë°˜ë¡ )
  - "Googleê³¼ Appleì˜ ì‚¬ë¡€ë¥¼ ë³´ë©´[^3, ^4]" (ì‰¼í‘œ ì‚¬ìš© ê¸ˆì§€)
- **ì¸ìš© ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸:**
  âœ… íšŒì‚¬ëª… ì–¸ê¸‰ì‹œ ì¸ìš© ìˆìŒ
  âœ… ìˆ˜ì¹˜/ë°ì´í„° ì–¸ê¸‰ì‹œ ì¸ìš© ìˆìŒ  
  âœ… ì œí’ˆ/ê¸°ìˆ ëª… ì–¸ê¸‰ì‹œ ì¸ìš© ìˆìŒ
  âœ… ë°œí‘œ/ì—°êµ¬ ë‚´ìš© ì–¸ê¸‰ì‹œ ì¸ìš© ìˆìŒ
- **ë°˜ë“œì‹œ ë¬¸ì„œ ë§¨ ëì— footnote ì •ì˜ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš” (ì•ë’¤ì— --- ë””ë°”ì´ë” ë„£ì§€ ë§ˆì„¸ìš”):**
  [^1]: ê¸°ì‚¬ì œëª© - ì¶œì²˜ ë§í¬
  [^2]: ê¸°ì‚¬ì œëª© - ì¶œì²˜ ë§í¬
  [^3]: ê¸°ì‚¬ì œëª© - ì¶œì²˜ ë§í¬
- ê¸°ì—… ì´ë¦„ì€ í”¼ë“œ ë‚´ìš©ì— ë“±ì¥í•˜ëŠ” ê¸°ì—…ë“¤ë§Œ ì–¸ê¸‰í•˜ê³ , ì„ì˜ë¡œ íŠ¹ì • ê¸°ì—…ì„ ì˜ˆì‹œë¡œ ë“¤ì§€ ë§ˆì„¸ìš”
- **ìµœì¢… ì œì¶œ ì „ í•„ìˆ˜ ê²€í† : ë³¸ë¬¸ì— [^ìˆ«ì] ì¸ìš©ì´ ì¶©ë¶„íˆ ìˆëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì„¸ìš”**`, feedData)
}

// callGeminiAPI calls the Gemini API with the given prompt
func callGeminiAPI(ctx context.Context, prompt string) (string, error) {
	// URL Contextì™€ Google Search ë„êµ¬ ëª¨ë‘ í™œì„±í™”
	tools := []*genai.Tool{
		{
			URLContext: &genai.URLContext{},
		},
		{
			GoogleSearch: &genai.GoogleSearch{},
		},
	}

	// ì»¨í…ì¸  ìƒì„±
	parts := []*genai.Part{
		{Text: prompt},
	}

	content := []*genai.Content{{Parts: parts}}

	// Toolê³¼ structured outputì„ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ toolë§Œ ì‚¬ìš©
	thinkingBudget := int32(-1)
	generateConfig := &genai.GenerateContentConfig{
		Tools: tools,
		ThinkingConfig: &genai.ThinkingConfig{
			ThinkingBudget: &thinkingBudget,
		},
		ResponseMIMEType: "text/plain",
	}

	// Gemini API í˜¸ì¶œ
	resp, err := geminiClient.Models.GenerateContent(ctx, config.GeminiModel, content, generateConfig)
	if err != nil {
		return "", fmt.Errorf("Gemini API í˜¸ì¶œ ì‹¤íŒ¨: %v", err)
	}

	// ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ ë°˜í™˜ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ë””ë²„ê·¸ ë‚´ìš© ì œì™¸ ì§€ì‹œ)
	return resp.Text(), nil
}

func outputMarkdown(items []FeedItem, aiSummary string) {
	now := time.Now()
	filename := fmt.Sprintf("daily-feed-%s.md", now.Format("2006-01-02-15-04-05"))

	var content strings.Builder
	content.WriteString(fmt.Sprintf("# Daily Feed - %s\n\n", now.Format("2006-01-02")))

	// AI ìš”ì•½ë§Œ ì¶”ê°€
	if aiSummary != "" {
		content.WriteString(aiSummary)
	}

	err := os.WriteFile(filename, []byte(content.String()), 0644)
	if err != nil {
		log.Fatal("íŒŒì¼ ì €ì¥ ì‹¤íŒ¨:", err)
	}

	fmt.Printf("í”¼ë“œê°€ %s íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n", filename)
}

// fixXMLEntities fixes common XML entity issues
func fixXMLEntities(bodyStr string) string {
	body := bodyStr
	body = strings.ReplaceAll(body, "&nbsp;", " ")
	body = strings.ReplaceAll(body, "&ldquo;", "\"")
	body = strings.ReplaceAll(body, "&rdquo;", "\"")
	body = strings.ReplaceAll(body, "&lsquo;", "'")
	body = strings.ReplaceAll(body, "&rsquo;", "'")
	body = strings.ReplaceAll(body, "&mdash;", "-")
	body = strings.ReplaceAll(body, "&ndash;", "-")
	return body
}

func cleanHTML(html string) string {
	re := regexp.MustCompile(`<[^>]*>`)
	return strings.TrimSpace(re.ReplaceAllString(html, ""))
}

// feedItemIterator creates an iterator for processing feed items (Go 1.23+ iter package)
func feedItemIterator(items []FeedItem) iter.Seq[FeedItem] {
	return func(yield func(FeedItem) bool) {
		for _, item := range items {
			if !yield(item) {
				return
			}
		}
	}
}

// urlIterator creates an iterator for processing URLs from feed items
func urlIterator(items []FeedItem) iter.Seq[string] {
	return func(yield func(string) bool) {
		for _, item := range items {
			if item.Link != "" {
				if !yield(item.Link) {
					return
				}
			}
		}
	}
}

// removeDuplicateURLs removes duplicate URLs and limits to maxCount using Go 1.23+ maps package
func removeDuplicateURLs(urls []string, maxCount int) []string {
	// Go 1.23+ maps íŒ¨í‚¤ì§€ë¥¼ í™œìš©í•˜ì—¬ ë” íš¨ìœ¨ì ì¸ ì²˜ë¦¬
	urlMap := make(map[string]bool, len(urls))
	
	// URLì„ ë§µì— ì¶”ê°€ (ì¤‘ë³µ ìë™ ì œê±°)
	for _, url := range urls {
		urlMap[url] = true
	}
	
	// maps.Keysë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ìœ  URL ì¶”ì¶œ
	var result []string
	count := 0
	for url := range maps.All(urlMap) {
		result = append(result, url)
		count++
		if count >= maxCount {
			break
		}
	}
	
	if len(urlMap) > maxCount {
		log.Printf("URL ê°œìˆ˜ê°€ %dê°œë¥¼ ì´ˆê³¼í•˜ì—¬ ì¤‘ë³µ ì œê±° í›„ ìµœì‹  %dê°œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤", len(urlMap), len(result))
	}
	
	return result
}
