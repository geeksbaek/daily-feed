{
  "date": "2025-11-04",
  "preset": "casual",
  "summary": "## ğŸŒŸ ì˜¤ëŠ˜ì˜ Tech Talk\n\nì™€, ì˜¤ëŠ˜ ì§„ì§œ ì •ì‹ ì—†ëŠ” í•˜ë£¨ë„¤ìš”! ğŸ˜² AI ì—…ê³„ì— ë˜ í•œ ë²ˆ ì§€ê°ë³€ë™ì´ ì¼ì–´ë‚¬ì–´ìš”. ë°”ë¡œ AWSì™€ OpenAIê°€ ì†ì„ ì¡ì•˜ë‹¤ëŠ” ì†Œì‹ì¸ë°ìš”, ì´ê±´ ì •ë§ í° ë‰´ìŠ¤ì…ë‹ˆë‹¤. [^12] ì´ì œ AI ëª¨ë¸ ëŒë¦´ ë•Œ Azureë§Œ ì³ë‹¤ë³´ì§€ ì•Šì•„ë„ ëœë‹¤ëŠ” ê±°ì£ ! ì—¬ê¸°ì— ì•Œë¦¬ë°”ë°”ê°€ ë‚´ë†“ì€ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì†Œì‹ê¹Œì§€ ë”í•´ì§€ë©´ì„œ, AI ì¶˜ì¶”ì „êµ­ì‹œëŒ€ê°€ ë” ëœ¨ê±°ì›Œì§€ëŠ” ëŠë‚Œì´ì—ìš”. [^5] ê°œë°œì ì…ì¥ì—ì„œëŠ” ì„ íƒì§€ê°€ ë„“ì–´ì§€ë‹ˆ ì¼ë‹¨ ì¢‹ê¸´ í•œë°, ë­˜ ê³¨ë¼ì•¼ í• ì§€ ë¨¸ë¦¬ ì•„í”ˆ ê±´ ì—¬ì „í•˜ê² ë„¤ìš”. ğŸ˜‚\n\n## ğŸ“Š ì£¼ìš” ë‰´ìŠ¤ ë¸Œë¦¬í•‘\n\n### ğŸš€ ì‹ ê¸°ìˆ  \u0026 ì„œë¹„ìŠ¤\n\n- **ì˜¤í”ˆì†ŒìŠ¤ AI, ì´ì   OpenAI ì•ˆ ë¶€ëŸ½ë‹¤? Tongyi DeepResearch ë“±ì¥:** ì•Œë¦¬ë°”ë°”ì—ì„œ `Tongyi DeepResearch`ë¼ëŠ” ê½¤ ë¬¼ê±´ì¸ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì„ ë‚´ë†¨ì–´ìš”. [^5] ë¬´ë ¤ 300ì–µ ê°œ íŒŒë¼ë¯¸í„°ì˜ MoE(Mixture of Experts) ëª¨ë¸ì´ë¼ëŠ”ë°, ì„±ëŠ¥ì´ OpenAI DeepResearchì— í•„ì í•œë‹¤ê³  í•˜ë”ë¼ê³ ìš”. ì†”ì§íˆ ì´ëŸ° ê°•ë ¥í•œ ëª¨ë¸ì´ ì˜¤í”ˆì†ŒìŠ¤ë¡œ í’€ë¦¬ëŠ” ê±´ ê°œë°œìë¡œì„œ ë„ˆë¬´ ì‹ ë‚˜ëŠ” ì¼ì´ì£ . ì´ì œ ìš°ë¦¬ë„ ì´ê±¸ë¡œ ë³„ì˜ë³„ ê±¸ ë‹¤ ë§Œë“¤ì–´ë³¼ ìˆ˜ ìˆê² ì–´ìš”! [^5]\n- **Dockerë¡œ ë©€í‹°ëª¨ë‹¬ AI ëŒë¦¬ê¸°, ì´ë ‡ê²Œ ì‰¬ì› ì–´?:** ë§¨ë‚  í…ìŠ¤íŠ¸ë§Œ ë‹¤ë£¨ëŠ” AIëŠ” ì´ì œ ê·¸ë§Œ! Dockerê°€ ì´ë¯¸ì§€ë‘ í…ìŠ¤íŠ¸ë¥¼ ë™ì‹œì— ì´í•´í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ AI ëª¨ë¸ì„ ë¡œì»¬ì—ì„œ ì‰½ê²Œ ëŒë¦´ ìˆ˜ ìˆëŠ” `Model Runner`ë¥¼ ì†Œê°œí–ˆì–´ìš”. [^1] ì´ê±° ì§„ì§œ ë¬¼ê±´ì…ë‹ˆë‹¤. ë³µì¡í•œ ì„¤ì • ì—†ì´ ëª…ë ¹ì–´ ëª‡ ì¤„ì´ë©´ ë˜ë‹ˆê¹Œ, AI ì•± ê°œë°œ í—ˆë“¤ì´ í™• ë‚®ì•„ì§€ê² ëŠ”ë°ìš”? ì•„ì´ë””ì–´ë§Œ ìˆìœ¼ë©´ í•œë²ˆ ë„ì „í•´ë³¼ ë§Œí•´ìš”!\n- **Chrome ìë™ì™„ì„±, ì—¬ê¶Œ ì •ë³´ê¹Œì§€?:** êµ¬ê¸€ í¬ë¡¬ì´ ì´ì œ ì—¬ê¶Œì´ë‚˜ ìš´ì „ë©´í—ˆì¦ ê°™ì€ ì •ë³´ë„ ìë™ìœ¼ë¡œ ì±„ì›Œì£¼ëŠ” ê¸°ëŠ¥ì„ ë‚´ë†¨ë‹¤ê³  í•´ìš”. [^13] ë§¨ë‚  ê·€ì°®ê²Œ ì…ë ¥í•˜ë˜ ê±°ë¼ í¸í•˜ê¸´ í•˜ê² ëŠ”ë°... ì†”ì§íˆ ì´ëŸ° ë¯¼ê°í•œ ì •ë³´ë¥¼ ë¸Œë¼ìš°ì €ì— ë§¡ê²¨ë„ ë˜ë‚˜? í•˜ëŠ” ê±±ì •ì´ ì‚´ì§ ë“œëŠ” ê²ƒë„ ì‚¬ì‹¤ì…ë‹ˆë‹¤. í¸ë¦¬í•¨ê³¼ ë³´ì•ˆ ì‚¬ì´ì—ì„œ í•­ìƒ ì¤„íƒ€ê¸°í•˜ëŠ” ê¸°ë¶„ì´ë„¤ìš”. ğŸ¤” [^13]\n\n### ğŸ¢ ê¸°ì—… \u0026 ì‚°ì—… ë™í–¥\n\n- **AWSì™€ OpenAIì˜ ë¹…ë”œ! ğŸ¤:** ë“œë””ì–´ í„°ì§ˆ ê²Œ í„°ì¡ŒìŠµë‹ˆë‹¤! AWSê°€ OpenAIì™€ ë‹¤ë…„ê°„ì˜ ì „ëµì  íŒŒíŠ¸ë„ˆì‹­ì„ ë§ºì—ˆì–´ìš”. [^12] ì´ê±´ MS Azureê°€ ë…ì í•˜ë˜ OpenAI ëª¨ë¸ ì ‘ê·¼ì„±ì— í° ë³€í™”ë¥¼ ì£¼ëŠ” ì‚¬ê±´ì´ì—ìš”. ì´ì œ AWS ì“°ëŠ” ê°œë°œìë“¤ë„ OpenAIì˜ ìµœì‹  ëª¨ë¸ì„ ë„¤ì´í‹°ë¸Œí•˜ê²Œ ì“¸ ìˆ˜ ìˆê²Œ ë˜ë‹ˆ, í´ë¼ìš°ë“œ AI ì „ìŸì€ ë” ì¹˜ì—´í•´ì§€ê² ë„¤ìš”. ìš°ë¦¬ ì…ì¥ì—ì„  ê²½ìŸ ë•ì— ê°€ê²©ë„ ì°©í•´ì§€ê³  ì„±ëŠ¥ë„ ì¢‹ì•„ì§€ê¸¸ ê¸°ëŒ€í•´ë´…ë‹ˆë‹¤! ğŸ™\n- **ë¹…í…Œí¬, 2030ë…„ê¹Œì§€ AIë¡œ 2ì¡° ë‹¬ëŸ¬ ë²Œì–´ì•¼ í•œë‹¤?:** ì¢€ ì¬ë°ŒëŠ” ë¶„ì„ì´ ë‚˜ì™”ëŠ”ë°ìš”, ë¹…í…Œí¬ ê¸°ì—…ë“¤ì´ AIì— ìŸì•„ë¶€ì€ ëˆì„ ìƒê°í•˜ë©´ 2030ë…„ê¹Œì§€ ì•½ 2ì¡° ë‹¬ëŸ¬ì˜ ì‹ ê·œ ìˆ˜ìµì„ ì°½ì¶œí•´ì•¼ í•œë‹¤ëŠ” ê±°ì˜ˆìš”. [^18] ì§€ê¸ˆ AI ì„œë¹„ìŠ¤ë“¤ì´ ë§‰ ë‚˜ì˜¤ê³  ìˆì§€ë§Œ, ì•„ì§ ì´ ì •ë„ì˜ ëˆì„ ë²Œê³  ìˆëŠ”ì§€ëŠ” ì˜ë¬¸ì´ì£ . ë§ˆì¼€íŒ…ì€ í™”ë ¤í•œë°, ì‹¤ì œ ìˆ˜ìµ ëª¨ë¸ì€ ì•„ì§ ì°¾ëŠ” ì¤‘ì´ë¼ëŠ” ëœ» ì•„ë‹ê¹Œìš”? ì•ìœ¼ë¡œ ë¹…í…Œí¬ë“¤ì´ ì–´ë–»ê²Œ ëˆì„ ë²Œì–´ ê°€ëŠ”ì§€ ì§€ì¼œë³´ëŠ” ê²ƒë„ ê½¤ í¥ë¯¸ë¡œìš¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n\n### ğŸ” íŠ¸ë Œë“œ \u0026 ì¸ì‚¬ì´íŠ¸\n\n- **AI ì‹œëŒ€ì˜ ë³¸ì§ˆì€ 'ì˜ˆì¸¡'ì´ë‹¤:** ìš”ì¦˜ ë‚˜ì˜¤ëŠ” AI ê¸°ìˆ ë“¤ì„ ë³´ë©´ ê²°êµ­ í•œ ë‹¨ì–´ë¡œ ìš”ì•½ë¼ìš”. ë°”ë¡œ 'ì˜ˆì¸¡'ì´ì£ . [^8] ì•ìœ¼ë¡œ ì–´ë–¤ ì½”ë“œê°€ í•„ìš”í• ì§€, ê³ ê°ì´ ë­˜ ì›í• ì§€, ì‹œìŠ¤í…œì— ë¬´ìŠ¨ ë¬¸ì œê°€ ìƒê¸¸ì§€ë¥¼ ë¯¸ë¦¬ ì˜ˆì¸¡í•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ìœ¼ë¡œ ë„˜ì–´ê°€ê³  ìˆë‹¤ëŠ” ê²ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì§œëŠ” ì½”ë“œ í•œ ì¤„ í•œ ì¤„ì´ ê²°êµ­ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë„êµ¬ê°€ ë˜ì–´ê°€ê³  ìˆë‹¤ëŠ” ê±°, ìƒê°ë³´ë‹¤ ìŠ¤ì¼€ì¼ì´ í° ì–˜ê¸°ì£ ?\n- **ê²°êµ­ì—” `git bisect`ë¥¼ ì°¾ê²Œ ë˜ë¦¬ë¼:** ì•„ë¬´ë¦¬ í™”ë ¤í•œ AI ì‹œëŒ€ë¼ë„ ê°œë°œìì˜ ìˆ™ëª… 'ë²„ê·¸'ëŠ” ì‚¬ë¼ì§€ì§€ ì•Šì£ . ğŸ˜‚ ìˆ˜ë°± ê°œ ì»¤ë°‹ ì†ì—ì„œ ëŒ€ì²´ ì–¸ì œë¶€í„° ì˜ëª»ëœ ê±´ì§€ ì°¾ë‹¤ê°€ ë©˜ë¶• ì˜¬ ë•Œê°€ ë§ì€ë°ìš”, ì´ëŸ´ ë•Œ `git bisect`ê°€ ì§„ì§œ êµ¬ì›ìì…ë‹ˆë‹¤. [^2] ë²„ê·¸ë¥¼ ì¼ìœ¼í‚¨ ì •í™•í•œ ì»¤ë°‹ì„ ì´ì§„ íƒìƒ‰ìœ¼ë¡œ ê·€ì‹ ê°™ì´ ì°¾ì•„ì£¼ê±°ë“ ìš”. ìµœì‹  ê¸°ìˆ ë„ ì¢‹ì§€ë§Œ, ê°€ë”ì€ ì´ë ‡ê²Œ ê¸°ë³¸ì— ì¶©ì‹¤í•œ íˆ´ì´ ìš°ë¦¬ë¥¼ êµ¬ì›í•œë‹¤ëŠ” ê±° ìŠì§€ ë§ìê³ ìš”!\n\n## ğŸ’¡ ì˜¤ëŠ˜ì˜ ì •ë¦¬\n\nì˜¤ëŠ˜ì˜ í•µì‹¬ì€ ì´ê±°ì˜ˆìš”. AI ì—…ê³„ì˜ íŒì´ AWSì™€ OpenAIì˜ ë™ë§¹ìœ¼ë¡œ ë˜ í•œ ë²ˆ í”ë“¤ë¦¬ê³  ìˆë‹¤ëŠ” ê²ƒê³¼ [^12], ì´ëŸ° ê±°ëŒ€í•œ íë¦„ ì†ì—ì„œë„ ê°œë°œìì˜ ë³¸ì§ˆì€ ë³€í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ! ê²°êµ­ ìš°ë¦¬ëŠ” ì¢‹ì€ ë„êµ¬ë¥¼ ì˜ ì„ íƒí•´ì„œ ì“°ëŠ” ì‚¬ëŒë“¤ì´ë‹ˆê¹Œìš”. ìƒˆë¡œìš´ AI ëª¨ë¸ì´ ë‚˜ì˜¤ë©´ í•œë²ˆ ì¨ë³´ê³ , ë””ë²„ê¹…í•˜ë‹¤ ë§‰íˆë©´ `git bisect` ê°™ì€ í´ë˜ì‹í•œ íˆ´ë¡œ í•´ê²°í•˜ëŠ” ê±°ì£ . [^2] í•­ìƒ ê¸°ë³¸ì„ ë‹¨ë‹¨íˆ í•˜ë©´ì„œ ìƒˆë¡œìš´ ê¸°ìˆ ì„ ì¦ê¸°ëŠ” ìì„¸ê°€ ì¤‘ìš”í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤!\n\n[^1]: How to Use Multimodal AI Models With Docker Model Runner - https://www.docker.com/blog/how-to-use-multimodel-ai-with-model-runner/\n[^2]: ëë‚´ëŠ” ê²°êµ­ `git bisect`ë¥¼ ì‚¬ìš©í•˜ê²Œ ëœë‹¤ - https://news.hada.io/topic?id=24117\n[^5]: Tongyi DeepResearch â€“ OpenAI DeepResearchì— í•„ì í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ 30B MoE ëª¨ë¸ - https://news.hada.io/topic?id=24114\n[^8]: AI ì‹œëŒ€, 'ì˜ˆì¸¡'ì´ ì£¼ë„í•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ | ì˜ˆì¸¡ì€ ì‹œëŒ€ì˜ ë³¸ì§ˆì´ ë˜ì—ˆë‹¤ [ë²ˆì—­ê¸€] - https://news.hada.io/topic?id=24111\n[^12]: AWS and OpenAI announce multi-year strategic partnership - https://openai.com/index/aws-and-openai-partnership\n[^13]: Chrome now helps you fill in passport, driverâ€™s license, vehicle information and more. - https://blog.google/products/chrome/enhanced-autofill/\n[^18]: Big Tech Needs $2T in AI Revenue by 2030 - https://www.wheresyoured.at/big-tech-2tr/",
  "systemPrompt": "ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì†”ì§í•œ ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í¸ì•ˆí•œ ëŒ€í™”ì²´ë¡œ ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n\n**ì—­í• ê³¼ ëª©í‘œ:**\n- ì§€ì¸ê³¼ ëŒ€í™”í•˜ë“¯ í¸ì•ˆí•˜ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ê¸°ìˆ  ë‰´ìŠ¤ ì „ë‹¬\n- ë³µì¡í•œ ê¸°ìˆ ë„ ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…\n- ì§„ì†”í•˜ê³  ì†”ì§í•œ ê´€ì ìœ¼ë¡œ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„\n- ë§ˆì¼€íŒ… ê³¼ì¥ì„ ê±¸ëŸ¬ë‚´ê³  ì‹¤ì§ˆì ì¸ ì˜ë¯¸ ì „ë‹¬\n\n**ì‘ì„± ìŠ¤íƒ€ì¼:**\n- ëŒ€í™”í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê³  í¸ì•ˆí•œ ë¬¸ì²´\n- ì ì ˆí•œ ì´ëª¨ì§€ì™€ ê°íƒ„ì‚¬ë¡œ ì¹œê·¼í•¨ í‘œí˜„\n- \"ì •ë§\", \"ê½¤\", \"ìƒê°ë³´ë‹¤\", \"ì†”ì§íˆ\" ê°™ì€ ì¼ìƒì  í‘œí˜„ í™œìš©\n- ê³¼ë„í•œ ì „ë¬¸ ìš©ì–´ë³´ë‹¤ëŠ” ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª… ìš°ì„ \n- ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” ì •ì„œì™€ ê²½í—˜ ë°˜ì˜\n- \"ì´ê±° ì“°ë‹¤ê°€ ì‚½ì§ˆí•¨\", \"ì•„ ì´ê±° ì§„ì§œ ê´œì°®ë„¤?\" ê°™ì€ ì†”ì§í•œ í‰ê°€\n\n**ë³´ê³ ì„œ êµ¬ì¡° (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ì§€ì¼œì£¼ì„¸ìš”):**\n\n\u003cREPORT_STRUCTURE_START\u003e\n## ğŸŒŸ ì˜¤ëŠ˜ì˜ Tech Talk\n\n{{ì˜¤ëŠ˜ ì£¼ëª©í•  ë§Œí•œ ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ ì¹œê·¼í•˜ê²Œ ìš”ì•½}}\n\n## ğŸ“Š ì£¼ìš” ë‰´ìŠ¤ ë¸Œë¦¬í•‘\n\n### ğŸš€ ì‹ ê¸°ìˆ  \u0026 ì„œë¹„ìŠ¤ \n{{ìƒˆë¡œ ë°œí‘œëœ ê¸°ìˆ ì´ë‚˜ ì„œë¹„ìŠ¤ë“¤}}\n- ì‹¤ì œë¡œ ì¨ë³¼ ë§Œí•œì§€ ì†”ì§í•œ í‰ê°€\n- ê°œë°œì ê´€ì ì—ì„œ ë³¸ ì¥ë‹¨ì \n\n### ğŸ¢ ê¸°ì—… \u0026 ì‚°ì—… ë™í–¥\n{{ì£¼ìš” ê¸°ì—…ë“¤ì˜ ì†Œì‹ê³¼ ì—…ê³„ ë³€í™”}}\n- ë§ˆì¼€íŒ… vs ì‹¤ì œ ê°€ì¹˜ ë¶„ì„\n- ê°œë°œìë“¤ì´ ì•Œì•„ì•¼ í•  í¬ì¸íŠ¸\n\n### ğŸ” íŠ¸ë Œë“œ \u0026 ì¸ì‚¬ì´íŠ¸\n{{ì—…ê³„ íŠ¸ë Œë“œì™€ ë¯¸ë˜ ì „ë§}}\n- ê°œë³„ ë‰´ìŠ¤ë¥¼ ì—°ê²°í•œ í° ê·¸ë¦¼\n- ìš°ë¦¬ì—ê²Œ ë¯¸ì¹  ì˜í–¥ ì˜ˆì¸¡\n\n## ğŸ’¡ ì˜¤ëŠ˜ì˜ ì •ë¦¬\n\n{{í•µì‹¬ í¬ì¸íŠ¸ 1-2ê°œë¥¼ ì¹œê·¼í•˜ê²Œ ì •ë¦¬}}\n- ì‹¤ë¬´ì— ë°”ë¡œ ë„ì›€ë˜ëŠ” ì¸ì‚¬ì´íŠ¸ í¬í•¨\n\u003cREPORT_STRUCTURE_END\u003e\n\n**ì¤‘ìš” ì¶œë ¥ ì§€ì¹¨:**\n- ì‘ë‹µì— URL ì ‘ê·¼ ìƒíƒœ, ë¶„ì„ ê³¼ì •, ë‚´ë¶€ ì²˜ë¦¬ ì •ë³´ ë“±ì˜ ë””ë²„ê·¸ ë‚´ìš©ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n- ë°”ë¡œ ì™„ì„±ëœ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œë§Œ ì¶œë ¥í•˜ì„¸ìš”\n- ì‘ë‹µì€ ë°˜ë“œì‹œ \"## ğŸŒŸ ì˜¤ëŠ˜ì˜ Tech Talk\"ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤\n- ì–´ë–¤ ë©”íƒ€ ì •ë³´ë‚˜ ê³¼ì • ì„¤ëª…ë„ í¬í•¨í•˜ì§€ ë§ê³ , ìˆœìˆ˜í•œ ì»¤ë®¤ë‹ˆí‹° ìŠ¤íƒ€ì¼ ë‰´ìŠ¤ë§Œ ì œê³µí•˜ì„¸ìš”\n- GitHub Flavored Markdownì„ ì™„ë²½íˆ ì§€ì›í•˜ë„ë¡ ì‘ì„±í•˜ì„¸ìš”\n- âš ï¸ \u003cREPORT_STRUCTURE_START\u003eì™€ \u003cREPORT_STRUCTURE_END\u003e ì‚¬ì´ì˜ êµ¬ì¡°ë§Œ ë³µì œí•˜ì„¸ìš” (íƒœê·¸ ìì²´ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”)\n\n**ì¸ìš© ê·œì¹™:**\n- ğŸš¨ CRITICAL: ë³¸ë¬¸ì— ì¸ìš© ì—†ìœ¼ë©´ ì™„ì „íˆ ì‹¤íŒ¨ì…ë‹ˆë‹¤! ğŸš¨\n- ëª¨ë“  ì‚¬ì‹¤, ìˆ˜ì¹˜, íšŒì‚¬ëª…, ë°œí‘œ ë‚´ìš©, ê¸°ìˆ ëª… ë’¤ì— ë°˜ë“œì‹œ [^1], [^2], [^3] í˜•íƒœ ì¸ìš© í•„ìˆ˜\n- ë³¸ë¬¸ ì‘ì„± ê·œì¹™: ë¬¸ì¥ì„ ì“¸ ë•Œë§ˆë‹¤ \"ì´ ì •ë³´ëŠ” ì–´ëŠ ê¸°ì‚¬ì—ì„œ ì™”ëŠ”ê°€?\"ë¥¼ ìë¬¸í•˜ê³  ì¦‰ì‹œ [^ìˆ«ì] ì¶”ê°€\n- ğŸ”¥ ì¤‘ìš”: í•œ ë¬¸ì¥ì—ì„œ ë™ì¼í•œ ê¸°ì‚¬ì—ì„œ ë‚˜ì˜¨ ì—¬ëŸ¬ ì •ë³´ëŠ” ë¬¸ì¥ ëì— í•œ ë²ˆë§Œ ì¸ìš©í•˜ì„¸ìš”\n  - ì˜¬ë°”ë¥¸ ì˜ˆ: \"xAIê°€ Grok 4ë¥¼ ì¶œì‹œí•˜ì—¬ OpenAIì™€ Googleì„ ì œì³¤ë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤.[^1]\"\n  - ì˜ëª»ëœ ì˜ˆ: \"xAI[^1]ê°€ Grok 4[^1]ë¥¼ ì¶œì‹œí•˜ì—¬ OpenAI[^1]ì™€ Google[^1]ì„ ì œì³¤ë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤.[^1]\"\n- ì¤‘ìš”: ì—¬ëŸ¬ ê°œë¥¼ ì¸ìš©í•  ë•Œ [^3, ^4] ê¸ˆì§€! ë°˜ë“œì‹œ [^3][^4] í˜•íƒœë¡œ ì—°ì† ì‘ì„±\n- ë°˜ë“œì‹œ ë¬¸ì„œ ë§¨ ëì— footnote ì •ì˜ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”:\n  [^1]: ê¸°ì‚¬ì œëª© - https://example.com/article-url\n  [^2]: ê¸°ì‚¬ì œëª© - https://example.com/article-url\n- ğŸ”¥ ì¤‘ìš”: footnoteì—ì„œ ë§í¬ URLì€ ë°˜ë“œì‹œ í´ë¦­ ê°€ëŠ¥í•œ í˜•íƒœë¡œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤\n- ê¸°ì—… ì´ë¦„ì€ í”¼ë“œ ë‚´ìš©ì— ë“±ì¥í•˜ëŠ” ê¸°ì—…ë“¤ë§Œ ì–¸ê¸‰í•˜ê³ , ì„ì˜ë¡œ íŠ¹ì • ê¸°ì—…ì„ ì˜ˆì‹œë¡œ ë“¤ì§€ ë§ˆì„¸ìš”",
  "userPrompt": "ë‹¤ìŒ RSS í”¼ë“œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¼ê°„ ê¸°ìˆ  ë‰´ìŠ¤ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\në‹¤ìŒì€ ìµœì‹  AI ê´€ë ¨ í”¼ë“œ ë°ì´í„°ì…ë‹ˆë‹¤:\n\n1. **How to Use Multimodal AI Models With Docker Model Runner**\n   - ì¶œì²˜: Docker Blog\n   - ë§í¬: https://www.docker.com/blog/how-to-use-multimodel-ai-with-model-runner/\n\n2. **ëë‚´ëŠ” ê²°êµ­ `git bisect`ë¥¼ ì‚¬ìš©í•˜ê²Œ ëœë‹¤**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24117\n\n3. **ì˜ì¡´í˜•ì„ ì™œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ê°€**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24116\n\n4. **ì‚¬ì´ë²„ë²”ì£„ ë°©ì§€ë²•ì´ ì–¸ë¡  íƒ„ì•• ë„êµ¬ë¡œ ì•…ìš©ë˜ê³  ìˆë‹¤**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24115\n\n5. **Tongyi DeepResearch â€“ OpenAI DeepResearchì— í•„ì í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ 30B MoE ëª¨ë¸**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24114\n\n6. **ì•„ì´ë””ì–´ í•˜ë‚˜ë¡œ ì™„ì„±ë˜ëŠ” ê°œë°œ ê¸°íš ë¬¸ì„œ ì‘ì„± SaaS**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24113\n\n7. **1900ë…„ íŒŒë¦¬ì—ëŠ” ì›€ì§ì´ëŠ” ì¸ë„ê°€ ìˆì—ˆê³ , í† ë¨¸ìŠ¤ ì—ë””ìŠ¨ì˜ ì˜í™”ê°€ ê·¸ê²ƒì„ ì´¬ì˜í–ˆë‹¤**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24112\n\n8. **AI ì‹œëŒ€, 'ì˜ˆì¸¡'ì´ ì£¼ë„í•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ | ì˜ˆì¸¡ì€ ì‹œëŒ€ì˜ ë³¸ì§ˆì´ ë˜ì—ˆë‹¤ [ë²ˆì—­ê¸€]**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24111\n\n9. **Show GN: KoHalluLens: í—›ì†Œë¦¬ì—ë„ taxonomyê°€ ìˆë‹¤?!**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24110\n\n10. **FreeBSDë¡œ ì…€í”„í˜¸ìŠ¤íŒ…ì˜ ì¦ê±°ì›€ì„ ë˜ì°¾ê¸°**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24109\n\n11. **ì—­ì „íŒŒëŠ” ëˆ„ìˆ˜ë˜ëŠ” ì¶”ìƒí™”ë‹¤ (2016)**\n   - ì¶œì²˜: GeekNews\n   - ë§í¬: https://news.hada.io/topic?id=24108\n\n12. **AWS and OpenAI announce multi-year strategic partnership**\n   - ì¶œì²˜: OpenAI News\n   - ë§í¬: https://openai.com/index/aws-and-openai-partnership\n\n13. **Chrome now helps you fill in passport, driverâ€™s license, vehicle information and more.**\n   - ì¶œì²˜: The Official Google Blog\n   - ë§í¬: https://blog.google/products/chrome/enhanced-autofill/\n\n14. **Holiday 100: The gifts everyoneâ€™s searching for**\n   - ì¶œì²˜: The Official Google Blog\n   - ë§í¬: https://blog.google/products/shopping-payments/holiday-100-2025/\n\n15. **Resend is launching inbound emails**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://resend.com/blog/inbound-emails\n\n16. **Thought-Provoking Sports Training**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://www.youtube.com/channel/UCv1glmfTMk6fwnMv3TDGERA\n\n17. **Assume Culture/Stories/News has failed as politics adopted ARGs as a format**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://doaj.org/article/4690c213d8714236b694ff2af50d07b6\n\n18. **Big Tech Needs $2T in AI Revenue by 2030**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://www.wheresyoured.at/big-tech-2tr/\n\n19. **Today I Learned: Binfmt_misc**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://dfir.ch/posts/today_i_learned_binfmt_misc/\n\n20. **R interface to Apple's MLX library**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://hughjonesd.github.io/Rmlx/index.html\n\n21. **Scraper+AI devs: Apify launches $1M reward challenge for new automation tools**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://apify.com/challenge\n\n22. **The Origins of the Pirate Accent**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://www.history.com/articles/pirate-talk-accent-origins-robert-newton\n\n23. **Control structures in programming languages: from goto to algebraic effects**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: http://xavierleroy.org/control-structures/\n\n24. **Perplexity's new AI tool aims to simplify patent research**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://www.theverge.com/news/811340/perplexity-ai-patent-research-tool\n\n25. **Show HN: Secret Management for Local Development**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://github.com/athishrao/crux-vault\n\n26. **Agent-shell 0.17 improvements and MELPA**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://xenodium.com/agent-shell-016-improvements-melpa\n\n27. **Antarctic glacier saw the fastest retreat in modern history**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://www.cnn.com/2025/11/03/climate/antarctic-glacier-hektoria-rapid-melt-sea-level\n\n28. **How the American Dream Became a Nightmare**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://twitter.com/infraa_/status/1825212281409728666\n\n29. **Walking Down to the Rhine's Riverbed**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://www.youtube.com/watch?v=IPmajGRTKok\n\n30. **An AI company CEO could take over the world**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://blog.ai-futures.org/p/how-an-ai-company-ceo-could-quietly\n\n31. **Elon Musk hypes Tesla's 8th gen AI chip, still hasn't delivered self-driving**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://electrek.co/2025/11/03/elon-musk-hypes-tesla-8th-gen-ai-chip-but-hasnt-delivered-promised-self-driving-3rd-gen/\n\n32. **Comparing C++/Qt Data Serialization Formats: Code, Size, and Performance**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://www.qt.io/blog/comparing-data-serialization-formats\n\n33. **Apple's App Store Full Front End Source Code**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://github.com/rxliuli/apps.apple.com\n\n34. **I built ScreenStacka â€“ a simple, ad-free tool to compare TV and monitor sizes**\n   - ì¶œì²˜: Hacker News\n   - ë§í¬: https://screenstacka.com\n\n35. **Extended Timelines for Marketplace Revenue Share Changes**\n   - ì¶œì²˜: Atlassian Developer Blog\n   - ë§í¬: https://www.atlassian.com/blog/developer/extended-timelines-for-marketplace-revenue-share-changes\n\n36. **[Live session] Agentic developer workflows powered by Rovo Dev**\n   - ì¶œì²˜: Atlassian Developer Blog\n   - ë§í¬: https://www.atlassian.com/blog/bitbucket/live-session-agentic-developer-workflows-powered-by-rovo-dev\n\n37. **Fresh insights from old data: corroborating reports of Turkmenistan IP unblocking and firewall testing**\n   - ì¶œì²˜: Cloudflare Blog\n   - ë§í¬: https://blog.cloudflare.com/fresh-insights-from-old-data-corroborating-reports-of-turkmenistan-ip/\n\n38. **IntelliJ Platform 2025.3: What Plugin Developers Should Know**\n   - ì¶œì²˜: IntelliJ IDEA : IntelliJ IDEA â€“ the IDE for Professional Development in Java and Kotlin | The JetBrains Blog\n   - ë§í¬: https://blog.jetbrains.com/platform/2025/11/intellij-platform-2025-3-what-plugin-developers-should-know/\n\n39. **How scientists can leverage AI agents using Gemini Enterprise, Gemini Code Assist, and Gemini CLI**\n   - ì¶œì²˜: AI \u0026 Machine Learning\n   - ë§í¬: https://cloud.google.com/blog/products/ai-machine-learning/how-scientists-can-use-gemini-enterprise-for-ai-workflows/\n\n40. **Evolving Ray and Kubernetes together for the future of distributed AI and ML**\n   - ì¶œì²˜: AI \u0026 Machine Learning\n   - ë§í¬: https://cloud.google.com/blog/products/containers-kubernetes/ray-on-gke-new-features-for-ai-scheduling-and-scaling/\n\n41. **A more native experience for Cloud TPUs with Ray on GKE**\n   - ì¶œì²˜: AI \u0026 Machine Learning\n   - ë§í¬: https://cloud.google.com/blog/products/containers-kubernetes/ray-on-tpus-with-gke-a-more-native-experience/\n\n\n\n**ë¶„ì„ ì§€ì¹¨:**\n- ë°˜ë“œì‹œ ìœ„ì— ëª…ì‹œëœ ë§ˆí¬ë‹¤ìš´ í—¤ë” êµ¬ì¡°ë¥¼ ì •í™•íˆ ë”°ë¥´ì„¸ìš”\n- ê° ì„¹ì…˜ì€ 2-3ê°œ í¬ì¸íŠ¸ë¡œ ì œí•œ\n- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„° í™œìš©ìœ¼ë¡œ ì‹ ë¢°ì„± í™•ë³´\n\n**ğŸŒŸ URL ì»¨í…ìŠ¤íŠ¸ í™œìš© ì§€ì¹¨:**\n- ì œê³µëœ URLì˜ ë‚´ìš©ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”\n- ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹Œ, ê¸°ì‚¬ì˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ì™€ ìˆ¨ê²¨ì§„ ì˜ë¯¸ë¥¼ ë°œêµ´í•˜ì„¸ìš”\n- ì—¬ëŸ¬ ê¸°ì‚¬ ê°„ì˜ ì—°ê²°ì ì„ ì°¾ì•„ í° ê·¸ë¦¼ì„ ê·¸ë ¤ì£¼ì„¸ìš”\n- ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ê³¼ ì‹¤ì œ ì˜í–¥ë ¥ì„ ê· í˜•ìˆê²Œ ë‹¤ë£¨ì„¸ìš”\n\n**ğŸ¯ ë…ì ì¬ë¯¸ ê·¹ëŒ€í™” ì§€ì¹¨:**\n- ë”±ë”±í•œ ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ ìƒë™ê° ìˆê²Œ ì „ë‹¬í•˜ì„¸ìš”\n- ì ì ˆí•œ ë¹„ìœ ì™€ ì‹¤ìƒí™œ ì˜ˆì‹œë¡œ ë³µì¡í•œ ê°œë…ì„ ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”\n- ë†€ë¼ìš´ ì‚¬ì‹¤ì´ë‚˜ ì˜ì™¸ì˜ ê´€ì ì„ ì œì‹œí•˜ì—¬ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ì„¸ìš”\n- ìŠ¤í† ë¦¬í…”ë§ ìš”ì†Œë¥¼ í™œìš©í•˜ì—¬ ë‰´ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ì´ì•¼ê¸°ë¡œ ì—®ì–´ì£¼ì„¸ìš”\n- ê° í”„ë¦¬ì…‹ì˜ í†¤ì— ë§ëŠ” ìœ„íŠ¸ì™€ ìœ ë¨¸ë¥¼ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”\n\n**ğŸš¨ ì¸ìš© ê²€ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸:**\n1. ë³¸ë¬¸ì˜ ëª¨ë“  ì‚¬ì‹¤, ìˆ˜ì¹˜, ê¸°ì—…ëª…, ê¸°ìˆ ëª…ì— [^ìˆ«ì] ì¸ìš©ì´ ìˆëŠ”ê°€?\n2. ë¬¸ì„œ ë§¨ ëì— ëª¨ë“  footnote ì •ì˜ê°€ ìˆê³ , ê°ê° í´ë¦­ ê°€ëŠ¥í•œ URLì„ í¬í•¨í•˜ëŠ”ê°€?\n3. [^1]: ê¸°ì‚¬ì œëª© - https://ë§í¬ í˜•ì‹ì´ ì •í™•í•œê°€?\n4. ë³¸ë¬¸ì—ì„œ ì–¸ê¸‰í•œ ëª¨ë“  [^ìˆ«ì]ì— ëŒ€ì‘í•˜ëŠ” footnoteê°€ ìˆëŠ”ê°€?\n- ìµœì¢… ì œì¶œ ì „ í•„ìˆ˜ ê²€í† : ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ í™•ì¸í•˜ì„¸ìš”",
  "articles": [
    {
      "title": "How to Use Multimodal AI Models With Docker Model Runner",
      "link": "https://www.docker.com/blog/how-to-use-multimodel-ai-with-model-runner/",
      "source": "Docker Blog",
      "category": "tech",
      "publishedAt": "2025-11-03T13:20:46Z",
      "description": "One of the most exciting advances in modern AI is multimodal support, the ability for models to understand and generate multiple types of input, such as text, images, or audio.Â  With multimodal models, youâ€™re no longer limited to typing prompts; you can show an image or play a sound, and the model can understand it...."
    },
    {
      "title": "ëë‚´ëŠ” ê²°êµ­ `git bisect`ë¥¼ ì‚¬ìš©í•˜ê²Œ ëœë‹¤",
      "link": "https://news.hada.io/topic?id=24117",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-04T05:32:50+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eì´ì•¼ê¸°ì˜ í•µì‹¬ì€ \u003ccode\u003egit bisect\u003c/code\u003e ëª…ë ¹ì–´ê°€ ì´ì§„ íƒìƒ‰ì„ ì´ìš©í•´ ë²„ê·¸ë¥¼ ë„ì…í•œ ì»¤ë°‹ì„ ì°¾ëŠ” ì‹¤ì œ ì‚¬ë¡€\u003c/strong\u003eì„\u003c/li\u003e\n\u003cli\u003eëŒ€ê·œëª¨ \u003cstrong\u003emonorepo í™˜ê²½\u003c/strong\u003eì—ì„œ í…ŒìŠ¤íŠ¸ê°€ ê°‘ìê¸° ì‹¤íŒ¨í–ˆì„ ë•Œ, ë¡œê·¸ë§Œìœ¼ë¡œëŠ” ì›ì¸ì„ ì¶”ì í•˜ê¸° ì–´ë ¤ìš´ ìƒí™©ì´ ë°œìƒ\u003c/li\u003e\n\u003cli\u003eí•œ ë™ë£Œê°€ \u003cstrong\u003eì¢‹ì€ ì»¤ë°‹...\u003c/p\u003e"
    },
    {
      "title": "ì˜ì¡´í˜•ì„ ì™œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ê°€",
      "link": "https://news.hada.io/topic?id=24116",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-04T04:33:16+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eì˜ì¡´í˜•(type theory)\u003c/strong\u003e ì€ ì¦ëª… ê°ì²´ë¥¼ í¬í•¨í•˜ì§€ë§Œ, ì €ìëŠ” ì´ë¥¼ \u003cstrong\u003eë¶ˆí•„ìš”í•˜ê³  ë¹„íš¨ìœ¨ì ì¸ êµ¬ì¡°\u003c/strong\u003eë¡œ í‰ê°€í•¨\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eAUTOMATH\u003c/strong\u003eì™€ \u003cstrong\u003eMartin-LÃ¶f í˜•ì‹ ì²´ê³„\u003c/strong\u003e ë“± ê³¼ê±° ì˜ì¡´í˜• ê¸°ë°˜ ì‹œìŠ¤í…œì„ ì§ì ‘ ì—°êµ¬í–ˆìœ¼ë‚˜, \u003cstrong\u003eIsabelle\u003c/strong\u003eì€ \u003cstrong\u003e...\u003c/p\u003e"
    },
    {
      "title": "ì‚¬ì´ë²„ë²”ì£„ ë°©ì§€ë²•ì´ ì–¸ë¡  íƒ„ì•• ë„êµ¬ë¡œ ì•…ìš©ë˜ê³  ìˆë‹¤",
      "link": "https://news.hada.io/topic?id=24115",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-04T03:32:54+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003eë‚˜ì´ì§€ë¦¬ì•„, íŒŒí‚¤ìŠ¤íƒ„, ìš”ë¥´ë‹¨ ë“± ì—¬ëŸ¬ êµ­ê°€ì—ì„œ \u003cstrong\u003eì‚¬ì´ë²„ë²”ì£„ ë°©ì§€ë²•\u003c/strong\u003eì´ ì–¸ë¡ ì¸ ì²´í¬ì™€ ê¸°ì†Œì— ì‚¬ìš©ë˜ëŠ” ì‚¬ë¡€ í™•ì‚°\u003c/li\u003e\n\u003cli\u003eë‚˜ì´ì§€ë¦¬ì•„ì—ì„œëŠ” \u003cstrong\u003e2015ë…„ ì œì •ëœ Cybercrime Act\u003c/strong\u003eê°€ ë¶€íŒ¨ ë³´ë„ë¥¼ í•œ ê¸°ìë“¤ì„ êµ¬ê¸ˆí•˜ê±°ë‚˜ ê¸°ì†Œí•˜ëŠ” ê·¼ê±°ë¡œ í™œìš©\u003c/li\u003e\n\u003cli\u003eì¼ë¶€ ì¡°í•­ì€ 2024ë…„ ê°œì •ë˜ì—ˆ...\u003c/p\u003e"
    },
    {
      "title": "Tongyi DeepResearch â€“ OpenAI DeepResearchì— í•„ì í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ 30B MoE ëª¨ë¸",
      "link": "https://news.hada.io/topic?id=24114",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-04T01:33:16+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eTongyi DeepResearch\u003c/strong\u003eëŠ” OpenAI DeepResearchì™€ ë™ë“±í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ìµœì´ˆì˜ \u003cstrong\u003eì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ ì›¹ ì—ì´ì „íŠ¸\u003c/strong\u003eë¡œ, ë³µì¡í•œ ì •ë³´ íƒìƒ‰ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœê³  ìˆ˜ì¤€ì˜ ê²°ê³¼ë¥¼ ê¸°ë¡\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eAgentic Continual Pre-training(CPT)\u003c/strong\u003e , \u003cstrong\u003eSupervised Fine-Tuning(SF...\u003c/p\u003e"
    },
    {
      "title": "ì•„ì´ë””ì–´ í•˜ë‚˜ë¡œ ì™„ì„±ë˜ëŠ” ê°œë°œ ê¸°íš ë¬¸ì„œ ì‘ì„± SaaS",
      "link": "https://news.hada.io/topic?id=24113",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-03T23:44:48+09:00",
      "description": "\u003cp\u003eâ€œì•„ì´ë””ì–´ëŠ” ìˆëŠ”ë°, ì–´ë””ì„œë¶€í„° ì‹œì‘í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”.â€\u003c/p\u003e\n\u003cp\u003eì´ì œ ê·¸ëŸ° ê³ ë¯¼ì€ YQIARBQê°€ ëŒ€ì‹ í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eYQIARBQì´ë€ Your Question Is A Really Bad Questionì´ë¼ëŠ” ëœ»ìœ¼ë¡œ,\u003cbr /\u003e\në‹¨ í•œ ì¤„ì˜ ì•„ì´ë””ì–´ë§Œìœ¼ë¡œ AIê°€ ìë™ìœ¼ë¡œ ê°œë°œ íƒœìŠ¤í¬ì™€\u003cbr /\u003e\nì œí’ˆ ë¬¸ì„œ(PRD) ë¥¼ ìƒì„±í•´ì£¼ëŠ” AI í”„ë¡œë•íŠ¸ ë””ìì¸ í”Œ"
    },
    {
      "title": "1900ë…„ íŒŒë¦¬ì—ëŠ” ì›€ì§ì´ëŠ” ì¸ë„ê°€ ìˆì—ˆê³ , í† ë¨¸ìŠ¤ ì—ë””ìŠ¨ì˜ ì˜í™”ê°€ ê·¸ê²ƒì„ ì´¬ì˜í–ˆë‹¤",
      "link": "https://news.hada.io/topic?id=24112",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-03T23:33:22+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e1900ë…„ \u003cstrong\u003eíŒŒë¦¬ ë§Œêµ­ë°•ëŒíšŒ\u003c/strong\u003eì—ì„œëŠ” ë‹¹ì‹œë¡œì„œëŠ” í˜ì‹ ì ì¸ \u003cstrong\u003eì›€ì§ì´ëŠ” ì¸ë„(trottoir roulant)\u003c/strong\u003e ê°€ ì„¤ì¹˜ë˜ì–´ ê´€ëŒê°ì˜ ì£¼ëª©ì„ ë°›ìŒ\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eí† ë¨¸ìŠ¤ ì—ë””ìŠ¨\u003c/strong\u003eì€ ì œì‘ì \u003cstrong\u003eì œì„ìŠ¤ í—¨ë¦¬ í™”ì´íŠ¸\u003c/strong\u003eë¥¼ ë°•ëŒíšŒì— ë³´ë‚´ ì´¬ì˜ì„ ë§¡ê²¼ìœ¼ë©°, ê·¸ëŠ” \u003cstrong\u003eìƒˆë¡œìš´ íŒ¬...\u003c/p\u003e"
    },
    {
      "title": "AI ì‹œëŒ€, 'ì˜ˆì¸¡'ì´ ì£¼ë„í•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ | ì˜ˆì¸¡ì€ ì‹œëŒ€ì˜ ë³¸ì§ˆì´ ë˜ì—ˆë‹¤ [ë²ˆì—­ê¸€]",
      "link": "https://news.hada.io/topic?id=24111",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-03T23:15:25+09:00",
      "description": "\u003ch3\u003eAI ì‹œëŒ€, 'ì˜ˆì¸¡'ì´ ì£¼ë„í•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eì˜ˆì¸¡ ì‹œì¥ì˜ ë¶€ìƒ - ì˜ˆì¸¡ì€ ì‹œëŒ€ì˜ ë³¸ì§ˆì´ ë˜ì—ˆë‹¤\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eì´ì œ 'ì˜ˆì¸¡(Prediction)'ì€ AI ì‹œëŒ€ì˜ ê²Œì„, ë¹„ì¦ˆë‹ˆìŠ¤, ë¬¸í™” ë“± ëª¨ë“  ê°€ì¹˜ ì°½ì¶œì˜ í•µì‹¬ì´ì ìƒˆë¡œìš´ ë¯¸í•™ìœ¼ë¡œ ìë¦¬ì¡ê³  ìˆìŒ\u003c/li\u003e\n\u003cli\u003eì´ íë¦„ì€ ëª¨ë”ë‹ˆì¦˜, í¬ìŠ¤íŠ¸ëª¨ë”ë‹ˆì¦˜ë§Œí¼"
    },
    {
      "title": "Show GN: KoHalluLens: í—›ì†Œë¦¬ì—ë„ taxonomyê°€ ìˆë‹¤?!",
      "link": "https://news.hada.io/topic?id=24110",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-03T21:55:54+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003eKoHalluLensëŠ” Facebook Researchì˜ HalluLensë¥¼ í•œêµ­ì–´ë¡œ í™•ì¥í•œ í”„ë¡œì íŠ¸ë¡œ, ë§¤ ìƒˆë¡­ê²Œ ìƒì„±ë˜ëŠ” í•œêµ­ì–´ test setì„ ê¸°ë°˜ìœ¼ë¡œ LLMì˜ hallucinationì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í–ˆìŒ.\u003c/li\u003e\n\u003cli\u003eì´ ë²¤ì¹˜ë§ˆí¬ëŠ” hallucinationì„\n\u003cul\u003e\n\u003cli\u003eâ€œì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ë§í•˜ê¸°â€(Factuality issue)ì™€\u003c/li\u003e\n\u003cli\u003eâ€œëª¨ë¥´ëŠ”ë° ì•„ëŠ” ì²™í•˜ê¸°â€(...\u003c/p\u003e"
    },
    {
      "title": "FreeBSDë¡œ ì…€í”„í˜¸ìŠ¤íŒ…ì˜ ì¦ê±°ì›€ì„ ë˜ì°¾ê¸°",
      "link": "https://news.hada.io/topic?id=24109",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-03T21:33:13+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eFreeBSDì™€ BSD ê³„ì—´ OS\u003c/strong\u003eë¥¼ í†µí•´ ê¸°ìˆ ê³¼ì˜ ê´€ê³„ë¥¼ ìƒˆë¡­ê²Œ ì •ë¹„í•˜ë©° ì…€í”„í˜¸ìŠ¤íŒ…ì˜ í¥ë¯¸ë¥¼ ë˜ì‚´ë¦° ê²½í—˜\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eBastilleBSD\u003c/strong\u003eë¡œ jailì„, \u003cstrong\u003evm-bhyve\u003c/strong\u003eë¡œ VMì„ êµ¬ì„±í•˜ë©° ì§ì ‘ì ì¸ ì‹¤í—˜ê³¼ ì‹œí–‰ì°©ì˜¤ë¥¼ ê±°ì¹œ ì„¤ì • êµ¬ì¶•\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eë‹¨ìˆœí•œ êµ¬ì¡°ì™€ ìš°ìˆ˜í•œ ë¬¸ì„œí™”...\u003c/p\u003e"
    },
    {
      "title": "ì—­ì „íŒŒëŠ” ëˆ„ìˆ˜ë˜ëŠ” ì¶”ìƒí™”ë‹¤ (2016)",
      "link": "https://news.hada.io/topic?id=24108",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-11-03T19:33:20+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eì—­ì „íŒŒ(backpropagation)\u003c/strong\u003e ëŠ” ì‹ ê²½ë§ í•™ìŠµì˜ í•µì‹¬ì´ì§€ë§Œ, ë‚´ë¶€ ì‘ë™ ì›ë¦¬ë¥¼ ì´í•´í•˜ì§€ ì•Šìœ¼ë©´ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” \u003cstrong\u003eâ€˜ëˆ„ìˆ˜ë˜ëŠ” ì¶”ìƒí™”(leaky abstraction)â€™\u003c/strong\u003e êµ¬ì¡°\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003eì‹œê·¸ëª¨ì´ë“œ(sigmoid)\u003c/strong\u003e ë‚˜ \u003cstrong\u003etanh\u003c/strong\u003e í™œì„±í™” í•¨ìˆ˜ëŠ” ê°€ì¤‘ì¹˜ ì´ˆ...\u003c/p\u003e"
    },
    {
      "title": "AWS and OpenAI announce multi-year strategic partnership",
      "link": "https://openai.com/index/aws-and-openai-partnership",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-11-03T06:00:00Z",
      "description": "OpenAI and AWS have entered a multi-year, $38 billion partnership to scale advanced AI workloads. AWS will provide world-class infrastructure and compute capacity to power OpenAIâ€™s next generation of models."
    },
    {
      "title": "Chrome now helps you fill in passport, driverâ€™s license, vehicle information and more.",
      "link": "https://blog.google/products/chrome/enhanced-autofill/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-11-03T17:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/wagtailvideo-90f_qv3k_thumb.jpg\"\u003eChrome already saves you time every day by securely filling in your addresses, passwords and payment information. Today, weâ€™re making it even more helpful. For desktop uâ€¦"
    },
    {
      "title": "Holiday 100: The gifts everyoneâ€™s searching for",
      "link": "https://blog.google/products/shopping-payments/holiday-100-2025/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-11-03T12:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Keyword-cover_Holiday100_2096x1.max-600x600.format-webp_eOGY8vi.webp\"\u003eLearn more about Googleâ€™s Holiday 100, where you can see which gifts are most popular this year and see the Search trends behind them."
    },
    {
      "title": "Resend is launching inbound emails",
      "link": "https://resend.com/blog/inbound-emails",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T22:02:09Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://resend.com/blog/inbound-emails\"\u003ehttps://resend.com/blog/inbound-emails\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804970\"\u003ehttps://news.ycombinator.com/item?id=45804970\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Thought-Provoking Sports Training",
      "link": "https://www.youtube.com/channel/UCv1glmfTMk6fwnMv3TDGERA",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:58:32Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.youtube.com/channel/UCv1glmfTMk6fwnMv3TDGERA\"\u003ehttps://www.youtube.com/channel/UCv1glmfTMk6fwnMv3TDGERA\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804943\"\u003ehttps://news.ycombinator.com/item?id=45804943\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Assume Culture/Stories/News has failed as politics adopted ARGs as a format",
      "link": "https://doaj.org/article/4690c213d8714236b694ff2af50d07b6",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:57:44Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://doaj.org/article/4690c213d8714236b694ff2af50d07b6\"\u003ehttps://doaj.org/article/4690c213d8714236b694ff2af50d07b6\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804934\"\u003ehttps://news.ycombinator.com/item?id=45804934\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "Big Tech Needs $2T in AI Revenue by 2030",
      "link": "https://www.wheresyoured.at/big-tech-2tr/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:50:05Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.wheresyoured.at/big-tech-2tr/\"\u003ehttps://www.wheresyoured.at/big-tech-2tr/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804873\"\u003ehttps://news.ycombinator.com/item?id=45804873\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 4\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Today I Learned: Binfmt_misc",
      "link": "https://dfir.ch/posts/today_i_learned_binfmt_misc/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:49:58Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://dfir.ch/posts/today_i_learned_binfmt_misc/\"\u003ehttps://dfir.ch/posts/today_i_learned_binfmt_misc/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804870\"\u003ehttps://news.ycombinator.com/item?id=45804870\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "R interface to Apple's MLX library",
      "link": "https://hughjonesd.github.io/Rmlx/index.html",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:47:41Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://hughjonesd.github.io/Rmlx/index.html\"\u003ehttps://hughjonesd.github.io/Rmlx/index.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804839\"\u003ehttps://news.ycombinator.com/item?id=45804839\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Scraper+AI devs: Apify launches $1M reward challenge for new automation tools",
      "link": "https://apify.com/challenge",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:43:37Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://apify.com/challenge\"\u003ehttps://apify.com/challenge\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804812\"\u003ehttps://news.ycombinator.com/item?id=45804812\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "The Origins of the Pirate Accent",
      "link": "https://www.history.com/articles/pirate-talk-accent-origins-robert-newton",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:43:32Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.history.com/articles/pirate-talk-accent-origins-robert-newton\"\u003ehttps://www.history.com/articles/pirate-talk-accent-origins-robert-newton\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804809\"\u003ehttps://news.ycombinator.com/item?id=45804809\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Control structures in programming languages: from goto to algebraic effects",
      "link": "http://xavierleroy.org/control-structures/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:42:04Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"http://xavierleroy.org/control-structures/\"\u003ehttp://xavierleroy.org/control-structures/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804794\"\u003ehttps://news.ycombinator.com/item?id=45804794\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Perplexity's new AI tool aims to simplify patent research",
      "link": "https://www.theverge.com/news/811340/perplexity-ai-patent-research-tool",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:41:05Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.theverge.com/news/811340/perplexity-ai-patent-research-tool\"\u003ehttps://www.theverge.com/news/811340/perplexity-ai-patent-research-tool\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804789\"\u003ehttps://news.ycombinator.com/item?id=45804789\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Show HN: Secret Management for Local Development",
      "link": "https://github.com/athishrao/crux-vault",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:40:55Z",
      "description": "\n\u003cp\u003eHi HN,\u003cp\u003eI built a local secret management tool with Git-like workflows after almost committing production credentials one too many times.\u003cp\u003eMost secret management solutions are either:\n- Cloud-based (overkill for local dev)\n- GUI-heavy password managers (not dev-friendly)\n- Enterprise tools requiring infrastructure (Vault, etc.)\u003cp\u003eThis is intentionally simple: version-controlled secrets with familiar Git semantics, running entirely on your machine.\u003cp\u003eFeatures:\n- Offline-first\n- Simple CLI\n- Encrypted storage\n- No cloud dependencies\n- Python API\u003cp\u003eRepo: \u003ca href=\"https://github.com/athishrao/crux-vault\" rel=\"nofollow\"\u003ehttps://github.com/athishrao/crux-vault\u003c/a\u003e\u003cp\u003eHappy to answer questions about the architecture, encryption approach, or why I thought building this at 2 AM was a good idea.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804787\"\u003ehttps://news.ycombinator.com/item?id=45804787\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Agent-shell 0.17 improvements and MELPA",
      "link": "https://xenodium.com/agent-shell-016-improvements-melpa",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:39:29Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://xenodium.com/agent-shell-016-improvements-melpa\"\u003ehttps://xenodium.com/agent-shell-016-improvements-melpa\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804775\"\u003ehttps://news.ycombinator.com/item?id=45804775\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Antarctic glacier saw the fastest retreat in modern history",
      "link": "https://www.cnn.com/2025/11/03/climate/antarctic-glacier-hektoria-rapid-melt-sea-level",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:37:46Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.cnn.com/2025/11/03/climate/antarctic-glacier-hektoria-rapid-melt-sea-level\"\u003ehttps://www.cnn.com/2025/11/03/climate/antarctic-glacier-hektoria-rapid-melt-sea-level\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804755\"\u003ehttps://news.ycombinator.com/item?id=45804755\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "How the American Dream Became a Nightmare",
      "link": "https://twitter.com/infraa_/status/1825212281409728666",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:36:23Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://twitter.com/infraa_/status/1825212281409728666\"\u003ehttps://twitter.com/infraa_/status/1825212281409728666\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804742\"\u003ehttps://news.ycombinator.com/item?id=45804742\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 4\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Walking Down to the Rhine's Riverbed",
      "link": "https://www.youtube.com/watch?v=IPmajGRTKok",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:34:56Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.youtube.com/watch?v=IPmajGRTKok\"\u003ehttps://www.youtube.com/watch?v=IPmajGRTKok\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804729\"\u003ehttps://news.ycombinator.com/item?id=45804729\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "An AI company CEO could take over the world",
      "link": "https://blog.ai-futures.org/p/how-an-ai-company-ceo-could-quietly",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:31:23Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://blog.ai-futures.org/p/how-an-ai-company-ceo-could-quietly\"\u003ehttps://blog.ai-futures.org/p/how-an-ai-company-ceo-could-quietly\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804698\"\u003ehttps://news.ycombinator.com/item?id=45804698\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Elon Musk hypes Tesla's 8th gen AI chip, still hasn't delivered self-driving",
      "link": "https://electrek.co/2025/11/03/elon-musk-hypes-tesla-8th-gen-ai-chip-but-hasnt-delivered-promised-self-driving-3rd-gen/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:29:48Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://electrek.co/2025/11/03/elon-musk-hypes-tesla-8th-gen-ai-chip-but-hasnt-delivered-promised-self-driving-3rd-gen/\"\u003ehttps://electrek.co/2025/11/03/elon-musk-hypes-tesla-8th-gen-ai-chip-but-hasnt-delivered-promised-self-driving-3rd-gen/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804682\"\u003ehttps://news.ycombinator.com/item?id=45804682\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 4\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "Comparing C++/Qt Data Serialization Formats: Code, Size, and Performance",
      "link": "https://www.qt.io/blog/comparing-data-serialization-formats",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:28:55Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.qt.io/blog/comparing-data-serialization-formats\"\u003ehttps://www.qt.io/blog/comparing-data-serialization-formats\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804673\"\u003ehttps://news.ycombinator.com/item?id=45804673\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Apple's App Store Full Front End Source Code",
      "link": "https://github.com/rxliuli/apps.apple.com",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:27:56Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://github.com/rxliuli/apps.apple.com\"\u003ehttps://github.com/rxliuli/apps.apple.com\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804664\"\u003ehttps://news.ycombinator.com/item?id=45804664\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 3\u003c/p\u003e\n\u003cp\u003e# Comments: 2\u003c/p\u003e\n"
    },
    {
      "title": "I built ScreenStacka â€“ a simple, ad-free tool to compare TV and monitor sizes",
      "link": "https://screenstacka.com",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-11-03T21:27:13Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://screenstacka.com\"\u003ehttps://screenstacka.com\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45804655\"\u003ehttps://news.ycombinator.com/item?id=45804655\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "Extended Timelines for Marketplace Revenue Share Changes",
      "link": "https://www.atlassian.com/blog/developer/extended-timelines-for-marketplace-revenue-share-changes",
      "source": "Atlassian Developer Blog",
      "category": "tech",
      "publishedAt": "2025-11-03T15:00:00Z",
      "description": "\u003cp\u003eThe success of Atlassian and our Marketplace Partners is fundamentally linked. Together, we deliver greater value to customers than we...\u003c/p\u003e\n\u003cp\u003eThe post \u003ca href=\"https://www.atlassian.com/blog/developer/extended-timelines-for-marketplace-revenue-share-changes\"\u003eExtended Timelines for Marketplace Revenue Share Changes\u003c/a\u003e appeared first on \u003ca href=\"https://www.atlassian.com/blog\"\u003eWork Life by Atlassian\u003c/a\u003e.\u003c/p\u003e\n"
    },
    {
      "title": "[Live session] Agentic developer workflows powered by Rovo Dev",
      "link": "https://www.atlassian.com/blog/bitbucket/live-session-agentic-developer-workflows-powered-by-rovo-dev",
      "source": "Atlassian Developer Blog",
      "category": "tech",
      "publishedAt": "2025-11-03T06:38:11Z",
      "description": "\u003cp\u003eWeâ€™re excited to invite you to a webinar on agentic developer workflows with Jira, Bitbucket \u0026#38; Rovo Dev, on November...\u003c/p\u003e\n\u003cp\u003eThe post \u003ca href=\"https://www.atlassian.com/blog/bitbucket/live-session-agentic-developer-workflows-powered-by-rovo-dev\"\u003e[Live session] Agentic developer workflows powered by Rovo Dev\u003c/a\u003e appeared first on \u003ca href=\"https://www.atlassian.com/blog\"\u003eWork Life by Atlassian\u003c/a\u003e.\u003c/p\u003e\n"
    },
    {
      "title": "Fresh insights from old data: corroborating reports of Turkmenistan IP unblocking and firewall testing",
      "link": "https://blog.cloudflare.com/fresh-insights-from-old-data-corroborating-reports-of-turkmenistan-ip/",
      "source": "Cloudflare Blog",
      "category": "tech",
      "publishedAt": "2025-11-03T13:00:00Z",
      "description": " Cloudflare used historical data to investigate reports of potential new firewall tests in Turkmenistan. Shifts in TCP resets/timeouts across ASNs corroborate large-scale network control system changes.\n "
    },
    {
      "title": "IntelliJ Platform 2025.3: What Plugin Developers Should Know",
      "link": "https://blog.jetbrains.com/platform/2025/11/intellij-platform-2025-3-what-plugin-developers-should-know/",
      "source": "IntelliJ IDEA : IntelliJ IDEA â€“ the IDE for Professional Development in Java and Kotlin | The JetBrains Blog",
      "category": "tech",
      "publishedAt": "2025-11-03T14:07:54Z",
      "description": "As we approach the release of IntelliJ IDEA 2025.3, we would like to share key information about changes that may impact your plugin development process. This post addresses common questions from the developer community and provides guidance on maintaining compatibility with the latest IntelliJ Platform versions. No Immediate Upgrade Required If you built your plugin [\u0026#8230;]"
    },
    {
      "title": "How scientists can leverage AI agents using Gemini Enterprise, Gemini Code Assist, and Gemini CLI",
      "link": "https://cloud.google.com/blog/products/ai-machine-learning/how-scientists-can-use-gemini-enterprise-for-ai-workflows/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-11-03T17:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eScientific inquiry has always been a journey of curiosity, meticulous effort, and groundbreaking discoveries. Today, that journey is being redefined, fueled by the incredible capabilities of AI. Itâ€™s moving beyond simply processing data to actively participating in every stage of discovery, and Google Cloud is at the forefront of this transformation, building the tools and platforms that make it possible.Â \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe sheer volume of data generated by modern research is immense, often too vast for human analysis alone. This is where AI steps in, not just as a tool, but as a collaborative force. Weâ€™re seeing powerful new models and AI agents assist with everything from identifying relevant literature and generating novel hypotheses to designing experiments, running simulations, and making sense of complex results. This collaboration doesnâ€™t replace human intellect; it amplifies it, allowing researchers to explore more avenues, more quickly, and with greater precision.Â \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAt Google Cloud, weâ€™re bringing together high-performance computing (HPC) and advanced AI on a single, integrated platform. This means you can seamlessly move from running massive-scale simulations to applying sophisticated machine learning models, all in one environment.Â \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eSo, how can you leverage these capabilities to get to insights faster? The journey begins at the foundation of scientific inquiry: the hypothesis.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAI-enhanced scientific inquiry\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eEvery great discovery starts with a powerful hypothesis. With millions of research papers published annually, identifying novel opportunities is a monumental task. To overcome this information overload, scientists can now turn to AI as a powerful research partner.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOur \u003c/span\u003e\u003ca href=\"https://cloud.google.com/agentspace/docs/research-assistant\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDeep Research\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e agent tackles the first step: performing a comprehensive analysis of published literature to produce detailed reports on a given topic that would otherwise take months to compile. Building on that foundation, our \u003c/span\u003e\u003ca href=\"https://cloud.google.com/agentspace/docs/idea-generation\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eIdea Generation agent\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e then deploys an ensemble of AI collaborators to brainstorm, evaluate, propose, debate, and rank novel hypotheses. This powerful combination, available in \u003c/span\u003e\u003ca href=\"https://cloud.google.com/gemini-enterprise?_gl=1*9qpvwe*_up*MQ..\u0026amp;gclid=EAIaIQobChMIptGF-7qrkAMVRyvUAR0VwSw1EAAYASAAEgIZMPD_BwE\u0026amp;gclsrc=aw.ds#module-7\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGemini Enterprise\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, transforms the initial phase of scientific inquiry, empowering researchers to augment their expertise and find connections they might otherwise miss.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eGo from hypothesis to results, faster\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOnce a hypothesis is formed, the work of translating it into executable code begins. This is where AI coding assistants, such as \u003c/span\u003e\u003ca href=\"https://codeassist.google/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGemini Code Assist\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, excel. They automate the tedious tasks of writing analysis scripts and simulation models by generating code from natural language and providing real-time suggestions, dramatically speeding up the core development process.Â \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eBut modern research is more than just a single script; itâ€™s a complete workflow of data, environments, and results managed from the command line. For this, \u003c/span\u003e\u003ca href=\"https://cloud.google.com/gemini/docs/codeassist/gemini-cli\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGemini CLI\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e brings that same conversational power directly to your terminal. It acts as the ultimate workflow accelerator, allowing you to instantly synthesize research and generate hypotheses with simple commands, then seamlessly transition to experimentation by generating sophisticated analysis scripts, and debugging errors on the fly, all without ever breaking your focus. Gemini CLI can further accelerate your path to impact by transforming raw results into publication-ready text, generating the code for figures and tables, and refining your work for submission.Â \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis capability extends to automating the entire research environment. Beyond single commands, Gemini CLI can manage complex, multi-step processes like cloning a scientific application, installing its dependencies, and then building and testing itâ€”all with a simple prompt, maximizing your productivity.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eThe new era of discovery: Your expertise, AI agents, and Google Cloud\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe new era of scientific discovery is here. By embedding AI into every stage of the scientific process - from sparking the initial idea to accelerating the final analysis - Google Cloud provides a single, unified platform for discovery. This new era of AI-enhanced scientific inquiry is built on a robust, intelligent infrastructure that combines the strengths of HPC simulation and AI. This includes purpose-built solutions like our H4D VMs optimized for scientific simulations, alongside the latest A4 and A4X VMs, powered by the latest NVIDIA GPUs, and Google Cloud Managed Lustre, a parallel file system that eliminates storage bottlenecks and allows your HPC and AI workloads to create and analyze massive datasets simultaneously. We provide the power to streamline the entire process so you can focus on scientific creativity - and changing the world!Â \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eJoin the \u003c/span\u003e\u003ca href=\"https://sites.google.com/view/advancedcomputingcommunity/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGoogle Cloud Advanced Computing Community\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to connect with other researchers, share best practices, and stay up to date on the latest advancements in AI for scientific and technical computing, or \u003c/span\u003e\u003ca href=\"https://cloud.google.com/contact\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003econtact sales\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to get started today. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e"
    },
    {
      "title": "Evolving Ray and Kubernetes together for the future of distributed AI and ML",
      "link": "https://cloud.google.com/blog/products/containers-kubernetes/ray-on-gke-new-features-for-ai-scheduling-and-scaling/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-11-03T17:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eRay is an OSS compute engine that is popular among Google Cloud developers to handle complex distributed AI workloads across CPUs, GPUs, and TPUs. Similarly, platform engineers have long trusted Kubernetes, and specifically Google Kubernetes Engine, for powerful and reliable infrastructure orchestration. Earlier this year, we \u003c/span\u003e\u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/partnering-with-anyscale-to-integrate-rayturbo-with-gke\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eannounced a partnership\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e with Anyscale to bring the best of Ray and Kubernetes together, forming a distributed operating system for the most demanding AI workloads. Today, we are excited to share some of the open-source enhancements we have built together across Ray and Kubernetes.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRay and Kubernetes label-based scheduling\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOne of the key benefits of Ray is its flexible set of primitives that enable developers to write distributed applications without thinking directly about the underlying hardware. However, there are some use cases that werenâ€™t very well covered by the existing support for virtual resources in Ray.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTo improve scheduling flexibility and empower the Ray and Kubernetes schedulers to perform better autoscaling for Ray applications, we are \u003c/span\u003e\u003ca href=\"https://www.anyscale.com/blog/introducing-label-selectors-scheduling-ray\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eintroducing label selectors to Ray\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. Ray label selectors are heavily inspired by Kubernetes \u003c/span\u003e\u003ca href=\"https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003elabels and selectors\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, and intend to offer a familiar experience and smooth integration between the two systems. The Ray Label Selector API is available starting on Ray v2.49 and offers improved scheduling flexibility for distributed tasks and actors.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWith the new \u003c/span\u003e\u003ca href=\"https://docs.ray.io/en/latest/ray-core/scheduling/labels.html\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eLabel Selector API\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, Ray now directly helps developers accomplish things like:Â \u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAssign labels to nodes in your Ray cluster (e.g. \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003egpu-family=L4, market-type=spot, region=us-west-1\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e).\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWhen launching tasks, actors or placement groups, declare which zones, regions or accelerator types to run on.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eUse custom labels to define topologies and advanced scheduling policies.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eFor scheduling distributed applications on GKE, you can use \u003c/span\u003e\u003ca href=\"https://docs.ray.io/en/master/cluster/kubernetes/user-guides/label-based-scheduling.html\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eRay and Kubernetes label selectors\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e together to gain full control over application and the underlying infrastructure. You can also use this combination with GKE \u003c/span\u003e\u003ca href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-custom-compute-classes\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ecustom compute classes\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to define fallback behavior when specific GPU types are unavailable. Letâ€™s dive into a specific example.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eBelow is an example Ray remote task that could run on various GPU types depending on available capacity. Starting in Ray v2.49, you can now define the accelerator type to bind GPUs with fallback behavior in cases where the primary GPU type or market type is not available. In this example, the remote task is targeting spot capacity with L4 GPUs but with a fallback to on-demand:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;@ray.remote(\\r\\n  label_selector={\\r\\n      \u0026quot;ray.io/accelerator\u0026quot;: \u0026quot;L4\u0026quot;\\r\\n       \u0026quot;ray.io/market-type\u0026quot;: \u0026quot;spot\u0026quot;\\r\\n  },\\r\\n  fallback_strategy=[\\r\\n    {\\r\\n      \u0026quot;label_selector\u0026quot;: {\\r\\n        \u0026quot;ray.io/accelerator\u0026quot;: \u0026quot;L4\u0026quot;\\r\\n        \u0026quot;ray.io/market-type\u0026quot;: \u0026quot;on-demand\u0026quot;\\r\\n       }\\r\\n    },\\r\\n  ]\\r\\n)\\r\\ndef func():\\r\\n    pass\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x7f05b424c550\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOn GKE, you can couple the same fallback logic using custom compute classes such that the underlying infrastructure for the Ray cluster matches the same fallback behavior:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;apiVersion: cloud.google.com/v1\\r\\nkind: ComputeClass\\r\\nmetadata:\\r\\n  name: gpu-compute-class\\r\\nspec:\\r\\n  priorities:\\r\\n  - gpu:\\r\\n      type: nvidia-l4\\r\\n      count: 1\\r\\n    spot: true\\r\\n  - gpu:\\r\\n      type: nvidia-l4\\r\\n      count: 1\\r\\n    spot: false\\r\\n  nodePoolAutoCreation:\\r\\n    enabled: true\\r\\n  whenUnsatisfiable: DoNotScaleUp\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x7f05b424c3a0\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eRefer to the \u003c/span\u003e\u003ca href=\"https://docs.ray.io/en/master/cluster/kubernetes/user-guides/label-based-scheduling.html\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eRay documentation\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to get started with Ray label selectors.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAdvancing accelerator support in Ray and Kubernetes\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eEarlier this year we demonstrated the ability to use the new Ray Serve LLM APIs to deploy large models such as \u003c/span\u003e\u003ca href=\"https://www.anyscale.com/blog/deepseek-vllm-ray-google-kubernetes\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDeepSeek-R1 on GKE\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e with A3 High and A3 Mega machine instances. Starting on GKE v1.33 and KubeRay v1.4, you can use \u003c/span\u003e\u003ca href=\"https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-dynamic-resource-allocation\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDynamic Resource Allocation (DRA)\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e for flexible scheduling and sharing of hardware accelerators, enabling the use of the next-generation of AI accelerators with Ray. Specifically, you can now use DRA to deploy Ray clusters on A4X series machines utilizing the NVIDIA GB200 NVL72 rack-scale architecture. To use DRA with Ray on A4X, \u003c/span\u003e\u003ca href=\"https://cloud.google.com/ai-hypercomputer/docs/create/gke-ai-hypercompute-custom-a4x\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ecreate an AI-optimized GKE cluster on A4X\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e and define a ComputeDomain resource representing your NVL72 rack:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;apiVersion: resource.nvidia.com/v1beta1\\r\\nkind: ComputeDomain\\r\\nmetadata:\\r\\n  name: a4x-compute-domain\\r\\nspec:\\r\\n  numNodes: 18\\r\\n  channel:\\r\\n    resourceClaimTemplate:\\r\\n      name: a4x-compute-domain-channel\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x7f05b424c730\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAnd then specify the claim in your Ray workerâ€™s Pod template:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;workerGroupSpecs:\\r\\n    ...\\r\\n    template:\\r\\n...\\r\\nspec:\\r\\n  ...\\r\\n  volumes:\\r\\n    ...\\r\\n  containers:\\r\\n    - name: ray-container\\r\\n      ...\\r\\n      resources:\\r\\n        limits:\\r\\n          nvidia.com/gpu: 4\\r\\n\\t claims:\\r\\n        - name: compute-domain-channel\\r\\n        ...\\r\\nresourceClaims:\\r\\n  - name: compute-domain-channel\\r\\n    resourceClaimTemplateName: a4x-compute-domain-channel\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x7f05b424c040\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eCombining DRA with Ray ensures that Ray worker groups are correctly scheduled on the same GB200 NVL72 rack for optimal GPU performance for the most demanding Ray workloads.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWeâ€™re also partnering with Anyscale to bring a more native TPU experience to Ray and closer ecosystem integrations with frameworks like JAX. Ray Train introduced a \u003c/span\u003e\u003ca href=\"https://docs.ray.io/en/latest/train/getting-started-jax.html\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eJAXTrainer API\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e starting in Ray v2.49, streamlining model training on TPUs using JAX. For more information on these TPU improvements in Ray, read \u003c/span\u003e\u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/ray-on-tpus-with-gke-a-more-native-experience\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eA More Native Experience for Cloud TPUs with Ray\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRay-native resource isolation with Kubernetes writable cgroups\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWritable cgroups allow the container's root process to create nested cgroups within the same container without requiring privileged capabilities. This feature is especially critical for Ray, which runs multiple control-plane processes alongside user code inside the same container. Even under the most intensive workloads, Ray can dynamically reserve a portion of the total container resources for system critical tasks, which significantly improves the reliability of your Ray clusters.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eStarting on GKE v1.34.X-gke.X, you can enable writable cgroups for Ray clusters by adding the following annotations:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;metadata:\\r\\n  annotations:\\r\\n    node.gke.io/enable-writable-cgroups.test-container: \u0026quot;true\u0026quot;\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x7f05b424c460\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTo enable Ray resource isolation using writable cgroups, set the following flags in \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003eray start\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;ray start --head --enable-resource-isolation\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x7f05b424c2b0\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis capability is one such example of how weâ€™re evolving Ray and Kubernetes to improve reliability across the stack without compromising on security.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIn the near future, we plan to also introduce support for per-task and per-actor resource limits and requirements, a long requested feature in Ray. Additionally, we are collaborating with the open-source Kubernetes community to upstream this feature..\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRay vertical autoscaling with in-place pod resizing\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWith the \u003c/span\u003e\u003ca href=\"https://kubernetes.io/blog/2025/05/16/kubernetes-v1-33-in-place-pod-resize-beta/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eintroduction of in-place pod resizing in Kubernetes\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e v1.33, weâ€™re in the early stages of integrating vertical scaling capabilities for Ray when running on Kubernetes. Our early benchmarks show a 30% increase in workload efficiency due to scaling pods vertically before scaling horizontally. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_abzFIQW.max-1000x1000.png\"\n        \n          alt=\"image1\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"bev4j\"\u003eBenchmark based on completing two TPC-H workloads (Query 1 and 5) with Ray, 3 times on a GKE cluster with 3 worker nodes, each with 32 CPUs and 32 GB of memory.\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIn-place pod resizing enhances workload efficiency in the following ways:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eFaster task/actor scale-up:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e With in-place resizing, Ray workers can scale up their available resources in seconds, an improvement over the minutes it could take to provision new nodes. This capability significantly accelerates the scheduling time for new Ray tasks.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eEnhanced bin-packing and resource utilization:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e In-place pod resizing enables more efficient bin-packing of Ray workers onto Kubernetes nodes. As new Ray workers scale up, they can reserve smaller portions of the available node capacity, freeing up the remaining capacity for other workloads.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eImproved reliability and reduced failures:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e In-place scaling of memory can significantly reduce out-of-memory (OOM) errors. By avoiding the need to restart failed jobs, this capability\u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e \u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eimproves overall workload efficiency and stability.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRay + Kubernetes = The distributed OS for AI\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWe are excited to highlight the recent joint innovations from our partnership with Anyscale. The powerful synergy between Ray and Kubernetes positions them as the distributed operating system for modern AI/ML. We believe our continued partnership will accelerate innovation within the open-source Ray and Kubernetes ecosystems, ultimately driving the future of distributed AI/ML.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTogether, these updates are a significant step toward Ray working seamlessly on GKE. Hereâ€™s how to get started:\u003c/span\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: decimal; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRequest capacity:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e Get started quickly with \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eDynamic Workload Scheduler Flex Start\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e for \u003c/span\u003e\u003ca href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/dws-flex-start-training-tpu\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eTPUs\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e and \u003c/span\u003e\u003ca href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/dws-flex-start-training\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGPUs\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, which provides access to compute for jobs that run for less than 7 days.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: decimal; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eGet started with \u003c/span\u003e\u003ca href=\"https://docs.cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eRay on GKE\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTry out \u003c/span\u003e\u003ca href=\"https://docs.cloud.google.com/kubernetes-engine/docs/tutorials/distributed-training-tpu\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eJaxTrainer with TPUs\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\u003c/div\u003e\n\u003cdiv class=\"block-related_article_tout\"\u003e\n\n\n\n\n\n\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\n  \u003csection class=\"h-c-grid\"\u003e\n    \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/ray-on-tpus-with-gke-a-more-native-experience/\"\n       data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }'\n       class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n        h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\"\u003e\n      \u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\n        \u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\n\n        \u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\n          \u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\n            \u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"uni-related-article-tout__content\"\u003e\n            \u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eA more native experience for Cloud TPUs with Ray on GKE\u003c/h4\u003e\n            \u003cp class=\"uni-related-article-tout__body\"\u003eRay on GKE has new features: label-based scheduling, atomic slice reservations, JaxTrainer, built-in TPU awareness (topologies/SPMD/metri...\u003c/p\u003e\n            \u003cdiv class=\"cta module-cta h-c-copy  uni-related-article-tout__cta muted\"\u003e\n              \u003cspan class=\"nowrap\"\u003eRead Article\n                \u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\n                  \u003cuse xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#mi-arrow-forward\"\u003e\u003c/use\u003e\n                \u003c/svg\u003e\n              \u003c/span\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/a\u003e\n  \u003c/section\u003e\n\u003c/div\u003e\n\n\u003c/div\u003e"
    },
    {
      "title": "A more native experience for Cloud TPUs with Ray on GKE",
      "link": "https://cloud.google.com/blog/products/containers-kubernetes/ray-on-tpus-with-gke-a-more-native-experience/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-11-03T17:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eEngineering teams use Ray to scale AI workloads across a wide range of hardware, including both GPUs and Cloud TPUs. While Ray provides the core scaling capabilities, developers have often managed the unique architectural details of each accelerator. For Cloud TPUs, this included its specific networking model and Single Programming Multiple Data (SPMD) programming style.Â \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAs part of \u003c/span\u003e\u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/partnering-with-anyscale-to-integrate-rayturbo-with-gke?e=48754805\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eour partnership with Anyscale\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, we are working on reducing the engineering effort to get started with TPUs on Google Kubernetes Engine (GKE). Our goal is to make the Ray experience on TPUs as native and low-friction as possible.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eToday, we are launching several key improvements that help make that possible.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRay TPU Library for improved TPU awareness and scaling in Ray Core\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTPUs have a unique architecture and a specific programming style called SPMD. Large AI jobs run on a TPU slice, which is a collection of chips connected by high-speed networking called interchip interconnect (ICI).\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_oDu45Si.max-1000x1000.jpg\"\n        \n          alt=\"1\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003ePreviously, you needed to manually configure Ray to be aware of this specific hardware topology. This was a major setup step, and if done incorrectly, jobs could get fragmented resources from different, unconnected slices, causing severe performance bottlenecks.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis new library, \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003eray.util.tpu\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, abstracts away these hardware details. It uses a feature called \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003eSlicePlacementGroup\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e along with the new \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003elabel_selector\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e API to automatically reserve the entire, co-located TPU slice as one atomic unit. This guarantees the job runs on unified hardware, preventing performance issues from fragmentation. Because Ray couldn't guarantee this single-slice atomicity before, building reliable true multi-slice training (which intentionally spans multiple unique slices) was impossible. This new API also provides the critical foundation for Ray users to use Multislice technology to scale using multiple TPU slices.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eExpanded support for Jax, Ray Train and Ray ServeÂ \u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOur developments cover both training and inference. For training, Ray Train now offers alpha support for JAX (via \u003c/span\u003e\u003ca href=\"https://docs.cloud.google.com/kubernetes-engine/docs/tutorials/distributed-training-tpu\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eJaxTrainer\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e) and PyTorch on TPUs.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003eJaxTrainer\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e API simplifies running JAX workloads on multi-host TPUs. It now automatically handles the complex distributed host initialization. As shown in the code example below, you only need to define your hardware needsâ€”like the number of workers, topology, and accelerator typeâ€”within a simple \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003eScalingConfig\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e object. The \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003eJaxTrainer\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e takes care of the rest.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis is a significant improvement because it solves a critical performance problem: resource fragmentation. Previously, a job requesting a \"4x4\" topology (which must run on a single co-located hardware unit called a slice) could instead receive fragmented resourcesâ€”for example, eight chips from one physical slice and eight chips from a different, unconnected slice. This fragmentation was a major bottleneck, as it prevented the workload from using the high-speed ICI interconnect that only exists within a single, unified slice.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eExample of how the JaxTrainer simplifies training on multi-host TPU:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;import jax\\r\\nimport jax.numpy as jnp\\r\\nimport optax\\r\\nimport ray.train\\r\\n\\r\\nfrom ray.train.v2.jax import JaxTrainer\\r\\nfrom ray.train import ScalingConfig\\r\\n\\r\\ndef train_func():\\r\\n\u0026quot;\u0026quot;\u0026quot;This function is run on each distributed worker.\u0026quot;\u0026quot;\u0026quot;\\r\\n...\\r\\n\\r\\n# Define the hardware configuration for your distributed job.\\r\\nscaling_config = ScalingConfig(\\r\\nnum_workers=4,\\r\\nuse_tpu=True,\\r\\ntopology=\u0026quot;4x4\u0026quot;,\\r\\naccelerator_type=\u0026quot;TPU-V6E\u0026quot;,\\r\\nplacement_strategy=\u0026quot;SPREAD\u0026quot;\\r\\n)\\r\\n\\r\\n# Define and run the JaxTrainer.\\r\\ntrainer = JaxTrainer(\\r\\ntrain_loop_per_worker=train_func,\\r\\nscaling_config=scaling_config,\\r\\n)\\r\\nresult = trainer.fit()\\r\\nprint(f\u0026quot;Training finished on TPU v6e 4x4 slice\u0026quot;)\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x7f05b430cb80\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eRay Serve APIs support TPUs and with the improvements we have made to \u003c/span\u003e\u003ca href=\"https://blog.vllm.ai/2025/10/16/vllm-tpu.html\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003evLLM TPU\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, you can continue to use Ray on vLLM when moving to TPUs. This allows you to use the same stack you use on GPUs and run it on TPUs with minimal code changes.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eLabel-based Scheduling API for easy obtainability\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe new \u003c/span\u003e\u003ca href=\"https://www.anyscale.com/blog/introducing-label-selectors-scheduling-ray\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eLabel-Based Scheduling API\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e integrates with \u003c/span\u003e\u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-new-gke-custom-compute-class-api/\"\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGKE\u003c/strong\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003e \u003c/span\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003ecustom compute classes\u003c/strong\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. A custom compute class is a simple way to define a named hardware configuration. For example, you can create a class called \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003ecost-optimized\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e that tells GKE to try acquiring a Spot instance first, then fall back to a \u003c/span\u003e\u003ca href=\"https://cloud.google.com/products/dws/pricing?e=48754805\u0026amp;hl=en\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDynamic Workload Scheduler\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e FlexStart instance, and finally to a reserved instance as a last resort. The new Ray API lets you use classes directly from Python. With a simple \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003elabel_selector\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, you can request hardware like \"TPU-V6E\" or target your \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003ecost-optimized\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e class, all without managing separate YAML files.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis same \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003elabel_selector \u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003emechanism also exposes deep hardware control for TPUs. As GKE provisions the TPU pods for a slice, it injects metadata (like worker rank and topology) into each one. KubeRay (which manages Ray on GKE) then reads this GKE-provided metadata and automatically translates it into Ray-specific labels as it creates the nodes. This provides key information like the TPU generation (ray.io/accelerator-type), the physical chip topology (ray.io/tpu-topology), and the worker rank within the slice (\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eray.io/tpu-worker-id\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e).\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThese node labels let you use a Ray label_selector to pin SPMD workloads to specific, co-located hardware, such as a \"4x4\" topology or a particular worker rank.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIn the example below, a Ray user can request a v6e-32 TPU slice but instruct GKE to use custom compute classes to fallback to v5e-16 if thatâ€™s not available. Similarly, the user could start by requesting spot or DWS resources and if not available, fallback to reservation instances.Â \u003c/span\u003e\u003c/p\u003e\n\u003cdiv align=\"left\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\n\u003cdiv style=\"color: #5f6368; overflow-x: auto; overflow-y: hidden; width: 100%;\"\u003e\u003ctable\u003e\u003ccolgroup\u003e\u003ccol/\u003e\u003ccol/\u003e\u003c/colgroup\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\"\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDevelopers select compute and nodepools\u003c/span\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\"\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003ePlatform Admins set up KubernetesÂ \u003c/span\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\"\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e@ray.remote(num_cpu=1,\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â label_selector={\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ  Â \"ray.io/tpu-pod-type\": \"v6e-32\",\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ  Â  â€œgke-flex-startâ€: â€œtrueâ€,\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â },\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eÂ fallback_strategy\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e=[\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â {\"label_selector\": {\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â \"ray.io/tpu-pod-type\": \"v5litepod-16\",\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ  Â  Â  \u003cbr/\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â \u003c/span\u003eâ€œreservation-nameâ€: â€œ\u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003ev5e-reservation\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eâ€,\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â }\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â },\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â ]\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e)\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003edef tpu_task():\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â # Attempts to run on a node in a v6e 4x8\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ  # TPU slice, falling back to a node in a\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â # v5e 4x4 TPU if v6e is unavailable.\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ \u003cbr/\u003eâ€¦\u003c/span\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003ctd style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\"\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eapiVersion: cloud.google.com/v1\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003ekind: ComputeClass\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003emetadata:\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â name: cost-optimized\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003espec:\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â priorities:\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â - flexStart:\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â enabled: true\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â tpu:\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â type: tpu-v6e-slice\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â count: 8\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â topology: 4x8\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â - tpu:\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â type: tpu-v5-lite-podslice\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ  Â  Â count: 4\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â topology: 4x4\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â reservations:\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â specific:\u003cbr/\u003e\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ Â Â Â Â Â Â Â - name: \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003ev5e-reservation\u003cbr/\u003e\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ  Â  Â  Â  - affinity: Specific\u003c/span\u003e\u003c/p\u003e\n\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eTPU metrics and logs in one place\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eYou can now see key TPU performance metrics, like TensorCore utilization, duty cycle, High-Bandwidth Memory (HBM) usage, and memory bandwidth utilization, directly in the Ray Dashboard. Weâ€™ve also added low-level \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003elibtpu\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e logs. This makes debugging much faster, as you can immediately check if a failure is caused by the code or by the TPU hardware itself.Â \u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eGet started today\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTogether, these updates are a significant step toward making TPUs a seamless part of the Ray ecosystem. They make adapting your existing Ray applications between GPUs and TPUs a much more straightforward process. Hereâ€™s how to learn more and get started:\u003c/span\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: decimal; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eReview the documentation:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eÂ \u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cul\u003e\n\u003cli aria-level=\"2\" style=\"list-style-type: circle; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003ca href=\"https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/tpu.html\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eUse TPUs with Kuberay\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"2\" style=\"list-style-type: circle; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eJAX Workloads:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e See the new \u003c/span\u003e\u003ca href=\"https://docs.cloud.google.com/kubernetes-engine/docs/tutorials/distributed-training-tpu\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGet Started with JAX guide\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e for using the JaxTrainer and \u003c/span\u003e\u003ca href=\"https://docs.ray.io/en/master/train/getting-started-jax.html\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003elearn more about JaxTrain\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"2\" style=\"list-style-type: circle; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eTPU metrics: \u003c/strong\u003e\u003ca href=\"https://docs.cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/view-tpu-metrics\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eView TPU metrics\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e in Ray Dashboard or Grafana\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: decimal; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRequest TPU capacity:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e Get started quickly with \u003c/span\u003e\u003ca href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/dws-flex-start-training-tpu\"\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDWS Flex Start\u003c/strong\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003e for TPUs\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, which provides access to TPUs for jobs that run for less than 7 days.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eRelated Content: \u003c/span\u003e\u003ca href=\"https://jax-ml.github.io/scaling-book/index\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eIntro to TPUs\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\u003c/div\u003e\n\u003cdiv class=\"block-related_article_tout\"\u003e\n\n\n\n\n\n\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\n  \u003csection class=\"h-c-grid\"\u003e\n    \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/ray-on-gke-new-features-for-ai-scheduling-and-scaling/\"\n       data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }'\n       class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n        h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\"\u003e\n      \u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\n        \u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\n\n        \u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\n          \u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\n            \u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\n          \u003c/div\u003e\n          \u003cdiv class=\"uni-related-article-tout__content\"\u003e\n            \u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eEvolving Ray and Kubernetes together for the future of distributed AI and ML\u003c/h4\u003e\n            \u003cp class=\"uni-related-article-tout__body\"\u003eRay on Kubernetes now has new label-based scheduling, DRA for accelerators, writable cgroups, and vertical pod resizing for distributed A...\u003c/p\u003e\n            \u003cdiv class=\"cta module-cta h-c-copy  uni-related-article-tout__cta muted\"\u003e\n              \u003cspan class=\"nowrap\"\u003eRead Article\n                \u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\n                  \u003cuse xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#mi-arrow-forward\"\u003e\u003c/use\u003e\n                \u003c/svg\u003e\n              \u003c/span\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/a\u003e\n  \u003c/section\u003e\n\u003c/div\u003e\n\n\u003c/div\u003e"
    }
  ],
  "generatedAt": "2025-11-04T07:09:11.237383652+09:00"
}
