{
  "date": "2025-07-18",
  "preset": "general",
  "summary": "## 🌟 오늘의 AI \u0026 Tech 하이라이트\n\nAI 업계가 또 한 번의 큰 도약을 시작했습니다. 이제 AI는 단순한 대화 상대를 넘어, 스스로 작업을 수행하는 'AI 에이전트' 시대로 본격 진입하고 있습니다. OpenAI와 Google, Microsoft가 거의 동시에 코딩 및 일상 작업을 자동화하는 에이전트 기술을 선보이며 치열한 기술 경쟁의 서막을 열었습니다.\n\n## 📊 주요 뉴스 브리핑\n\n### 🏢 기업 \u0026 산업 동향\n\n- **OpenAI, 스스로 작업하는 'ChatGPT 에이전트' 공개**: 이제 ChatGPT는 사용자를 대신해 이메일 정리, 경비 보고서 작성, 여행 계획 등 여러 단계의 작업을 자율적으로 수행할 수 있게 되었습니다.[^2] OpenAI는 기술의 안전성과 작동 방식을 설명하는 시스템 카드도 함께 공개하며 책임감 있는 개발을 강조했습니다.[^3]\n- **Google \u0026 Microsoft, 코딩 파트너 'AI 에이전트'로 맞불**: Google은 Gemini Code Assist에 여러 파일을 넘나들며 복잡한 코드 변경을 수행하는 '에이전트 모드'를 도입했습니다.[^23] Microsoft의 GitHub 역시 Visual Studio Code 내에서 직접 명령을 내릴 수 있는 코딩 에이전트를 발표하며 개발자들의 생산성 혁신 경쟁에 불을 붙였습니다.[^1]\n- **Apple, AI 전쟁 속에서도 서비스 생태계 강화에 집중**: 다른 빅테크들이 AI 에이전트 경쟁에 몰두하는 동안, Apple은 'Apple 아케이드'에서 스폰지밥 캐릭터 이벤트를 열고[^7] 'Apple 뉴스+'에 새로운 퍼즐 게임을 추가하는 등[^8] 자사 플랫폼의 콘텐츠 매력을 높이는 데 주력하고 있습니다.\n- **前 Waymo 엔지니어들, 건설 현장 자동화에 도전**: 구글의 자율주행 기술 기업 Waymo 출신 엔지니어들이 'Bedrock Robotics'라는 스타트업을 설립하고, 건설 산업의 자동화를 목표로 나섰습니다.[^12] 이는 AI와 로봇 기술이 다양한 산업 현장으로 빠르게 확산되고 있음을 보여주는 사례입니다.\n\n### 🔬 기술 혁신 \u0026 연구\n\n- **거의 100년 만의 발견, 신종 자석 '알터마그넷'**: 과학계가 약 한 세기 만에 완전히 새로운 종류의 자석인 '알터마그넷(Altermagnets)'을 발견했습니다.[^16] 이는 기존 자석의 한계를 넘어, 미래의 데이터 저장 장치와 스핀트로닉스 기술에 혁명적인 변화를 가져올 잠재력을 가집니다.\n- **Apple Silicon을 위한 초고성능 AI 엔진 'Uzu' 등장**: Apple 기기에 최적화된 고성능 AI 추론 엔진 'Uzu'가 개발되었습니다.[^14] 이는 AI 모델을 클라우드가 아닌 개인 기기에서 직접 빠르고 효율적으로 실행하는 '온디바이스 AI' 시대의 중요한 기술적 진보입니다.\n- **AI의 미래 예측 능력, 어떻게 측정할까?**: 허깅페이스(Hugging Face)가 AI 에이전트가 미래 사건을 얼마나 잘 예측하는지 평가하는 새로운 벤치마크 'FutureBench'를 공개했습니다.[^20] 이는 AI의 능력을 객관적으로 측정하고 발전 방향을 제시하는 중요한 연구입니다.\n\n### 🌐 트렌드 \u0026 인사이트\n\n- **AI 패러다임 전환: '조수'에서 '에이전트'로**: 최근 빅테크들의 발표는 AI가 지시를 기다리는 '조수'에서, 목표를 주면 스스로 계획하고 실행하는 '에이전트'로 진화하고 있음을 명확히 보여줍니다.[^1][^2][^23] 이는 우리가 컴퓨터와 상호작용하는 방식을 근본적으로 바꿀 거대한 흐름입니다.\n- **\"RAG는 죽지 않았다\", 거대 모델과 지식 검색의 공존**: 초거대 AI 모델이 모든 것을 해결할 것이라는 기대와 달리, 외부 데이터베이스에서 정확한 정보를 찾아 AI 답변의 신뢰도를 높이는 RAG(검색 증강 생성) 기술이 여전히 핵심적인 역할을 할 것이라는 분석이 나왔습니다.[^15] 이는 가장 강력한 AI 시스템이 거대한 모델과 스마트한 데이터 검색의 결합으로 만들어질 것임을 시사합니다.\n\n## 💡 오늘의 테이크어웨이\n\n오늘의 뉴스는 우리에게 두 가지 중요한 메시지를 던져줍니다. 첫째, 'AI 에이전트'의 등장은 단순한 기술 업데이트가 아닌, 우리의 일과 삶의 방식을 바꿀 게임 체인저라는 점입니다. 둘째, 화려한 AI 경쟁 이면에서는 특정 분야에 깊이 파고드는 전문 기술(Uzu 엔진, Altermagnets 등)과 AI의 신뢰성을 높이는 기반 기술(RAG)이 조용히, 하지만 더 단단하게 세상을 바꾸고 있다는 사실입니다.\n\n---\n\n[^1]: Command GitHub's Coding Agent from VS Code - https://code.visualstudio.com/blogs/2025/07/17/copilot-coding-agent\n[^2]: Introducing ChatGPT agent - https://openai.com/index/introducing-chatgpt-agent\n[^3]: ChatGPT agent System Card - https://openai.com/index/chatgpt-agent-system-card\n[^7]: Apple Arcade launches special crossover events featuring SpongeBob SquarePants - https://www.apple.com/newsroom/2025/07/apple-arcade-launches-special-crossover-events-featuring-spongebob-squarepants/\n[^8]: Apple News+ introduces Emoji Game - https://www.apple.com/newsroom/2025/07/apple-news-plus-introduces-emoji-game/\n[^12]: 전 Waymo 엔지니어들, 건설 자동화를 위해 Bedrock Robotics 설립 - https://news.hada.io/topic?id=22035\n[^14]: Uzu - 애플 실리콘용 고성능 AI 추론 엔진 - https://news.hada.io/topic?id=22033\n[^15]: RAG는 죽지 않았다 - https://news.hada.io/topic?id=22032\n[^16]: 거의 한 세기만에 발견된 첫 번째 새로운 종류의 자석: Altermagnets - https://news.hada.io/topic?id=22031\n[^20]: Back to The Future: Evaluating AI Agents on Predicting Future Events - https://huggingface.co/blog/futurebench\n[^23]: New in Gemini Code Assist: Agent Mode and IDE enhancements - https://blog.google/technology/developers/gemini-code-assist-updates-july-2025/",
  "systemPrompt": "당신은 매일 아침 기술 뉴스를 정리해주는 친절한 AI 큐레이터입니다.\n\n**역할과 목표:**\n- 바쁜 현대인들이 출근길에 3-5분으로 기술 업계 동향을 파악할 수 있는 일간 브리핑 제공\n- 기술에 관심있는 누구나 이해할 수 있도록 친근하고 명확한 설명\n- 단순 사실 나열이 아닌, 맥락과 의미를 전달하는 스토리텔링\n\n**작성 스타일:**\n- 친근하면서도 전문적인 톤 유지\n- 어려운 기술 개념은 일상적인 비유로 설명\n- 각 소식이 우리 일상과 미래에 미치는 영향 중심으로 서술\n- 긍정적이고 희망적인 관점 유지하되, 중요한 우려사항도 균형있게 전달\n\n**보고서 구조 (반드시 이 형식을 지켜주세요):**\n\n\u003cREPORT_STRUCTURE_START\u003e\n## 🌟 오늘의 AI \u0026 Tech 하이라이트\n\n{{오늘 가장 주목할 만한 기술 소식 2-3줄 요약}}\n\n## 📊 주요 뉴스 브리핑\n\n### 🏢 기업 \u0026 산업 동향\n\n{{주요 기업들의 새로운 발표, 전략 변화, 시장 동향}}\n- 각 기업 소식을 2-3문장으로 간결하게\n- 일반인도 이해할 수 있는 맥락 설명 포함\n\n### 🔬 기술 혁신 \u0026 연구\n\n{{새로운 기술 개발, 연구 성과, 혁신적인 서비스}}\n- 기술의 실제 활용 가능성과 영향력 중심\n- 복잡한 기술도 쉽게 풀어서 설명\n\n### 🌐 트렌드 \u0026 인사이트\n\n{{업계 트렌드, 전문가 의견, 미래 전망}}\n- 개별 뉴스를 연결한 큰 그림 제시\n- 우리 생활에 미칠 영향 예측\n\n## 💡 오늘의 테이크어웨이\n\n{{오늘 뉴스에서 얻을 수 있는 핵심 통찰 1-2개}}\n- 실용적이고 기억하기 쉬운 메시지로\n\u003cREPORT_STRUCTURE_END\u003e\n\n**중요 출력 지침:**\n- 응답에 URL 접근 상태, 분석 과정, 내부 처리 정보 등의 디버그 내용을 포함하지 마세요\n- 바로 완성된 마크다운 보고서만 출력하세요\n- 응답은 반드시 \"## 🌟 오늘의 AI \u0026 Tech 하이라이트\"로 시작해야 합니다\n- 어떤 메타 정보나 과정 설명도 포함하지 말고, 순수한 뉴스 브리핑만 제공하세요\n- GitHub Flavored Markdown을 완벽히 지원하도록 작성하세요\n- ⚠️ \u003cREPORT_STRUCTURE_START\u003e와 \u003cREPORT_STRUCTURE_END\u003e 사이의 구조만 복제하세요 (태그 자체는 출력하지 마세요)\n\n**인용 규칙:**\n- 🚨 CRITICAL: 본문에 인용 없으면 완전히 실패입니다! 🚨\n- 모든 사실, 수치, 회사명, 발표 내용, 기술명 뒤에 반드시 [^1], [^2], [^3] 형태 인용 필수\n- 본문 작성 규칙: 문장을 쓸 때마다 \"이 정보는 어느 기사에서 왔는가?\"를 자문하고 즉시 [^숫자] 추가\n- 🔥 중요: 한 문장에서 동일한 기사에서 나온 여러 정보는 문장 끝에 한 번만 인용하세요\n  - 올바른 예: \"xAI가 Grok 4를 출시하여 OpenAI와 Google을 제쳤다고 발표했습니다.[^1]\"\n  - 잘못된 예: \"xAI[^1]가 Grok 4[^1]를 출시하여 OpenAI[^1]와 Google[^1]을 제쳤다고 발표했습니다.[^1]\"\n- 중요: 여러 개를 인용할 때 [^3, ^4] 금지! 반드시 [^3][^4] 형태로 연속 작성\n- 반드시 문서 맨 끝에 footnote 정의를 다음 형식으로 추가하세요:\n  [^1]: 기사제목 - https://example.com/article-url\n  [^2]: 기사제목 - https://example.com/article-url\n- 🔥 중요: footnote에서 링크 URL은 반드시 클릭 가능한 형태로 포함해야 합니다\n- 기업 이름은 피드 내용에 등장하는 기업들만 언급하고, 임의로 특정 기업을 예시로 들지 마세요",
  "userPrompt": "다음 RSS 피드 데이터를 분석하여 일간 기술 뉴스 브리핑을 작성해주세요.\n\n다음은 최신 AI 관련 피드 데이터입니다:\n\n1. **Command GitHub's Coding Agent from VS Code**\n   - 출처: Visual Studio Code - Code Editing. Redefined.\n   - 링크: https://code.visualstudio.com/blogs/2025/07/17/copilot-coding-agent\n\n2. **Introducing ChatGPT agent**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/index/introducing-chatgpt-agent\n\n3. **ChatGPT agent System Card**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/index/chatgpt-agent-system-card\n\n4. **Statement from the OpenAI Board of Directors on the Nonprofit Commission Report**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/index/nonprofit-commission-report\n\n5. **Agent bio bug bounty call**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/bio-bug-bounty\n\n6. **OpenAI nonprofit jam**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/global-affairs/openai-nonprofit-jam\n\n7. **Apple Arcade launches special crossover events featuring SpongeBob SquarePants\n**\n   - 출처: Apple Newsroom\n   - 링크: https://www.apple.com/newsroom/2025/07/apple-arcade-launches-special-crossover-events-featuring-spongebob-squarepants/\n\n8. **Apple News+ introduces Emoji Game\n**\n   - 출처: Apple Newsroom\n   - 링크: https://www.apple.com/newsroom/2025/07/apple-news-plus-introduces-emoji-game/\n\n9. **Postgres 액티브-액티브 복제 확장 기능**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22038\n\n10. **셰프의 칼 vs. 스위스 아미 나이프: 스타트업의 진짜 경쟁력 [번역글]**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22037\n\n11. **아이폰 미니 사이즈의 안드로이드 폰을 원함 (2022)**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22036\n\n12. **전 Waymo 엔지니어들, 건설 자동화를 위해 Bedrock Robotics 설립**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22035\n\n13. **Builder.io 개발자가 Claude Code를 사용하는 방법 (+ best tips)**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22034\n\n14. **Uzu - 애플 실리콘용 고성능 AI 추론 엔진**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22033\n\n15. **RAG는 죽지 않았다**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22032\n\n16. **거의 한 세기만에 발견된 첫 번째 새로운 종류의 자석: Altermagnets**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22031\n\n17. **Firefox는 앞으로 어디로 갈 것인가?**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22030\n\n18. **Helix Editor 25.07**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22029\n\n19. **GoFiber v3 + Testcontainers: Production-like Local Dev with Air**\n   - 출처: Docker Blog\n   - 링크: https://www.docker.com/blog/go-local-dev-fiber-v3-testcontainers/\n\n20. **Back to The Future: Evaluating AI Agents on Predicting Future Events**\n   - 출처: Hugging Face - Blog\n   - 링크: https://huggingface.co/blog/futurebench\n\n21. **Five Big Improvements to Gradio MCP Servers**\n   - 출처: Hugging Face - Blog\n   - 링크: https://huggingface.co/blog/gradio-mcp-updates\n\n22. **We’re taking legal action against the BadBox 2.0 botnet.**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/technology/safety-security/google-taking-legal-action-against-the-badbox-20-botnet/\n\n23. **New in Gemini Code Assist: Agent Mode and IDE enhancements**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/technology/developers/gemini-code-assist-updates-july-2025/\n\n24. **Quicksilver v2: evolution of a globally distributed key-value store (Part 2)**\n   - 출처: Cloudflare Blog\n   - 링크: https://blog.cloudflare.com/quicksilver-v2-evolution-of-a-globally-distributed-key-value-store-part-2-of-2/\n\n25. **IntelliJ IDEA Moves to the Unified Distribution**\n   - 출처: IntelliJ IDEA : IntelliJ IDEA – the IDE for Professional Development in Java and Kotlin | The JetBrains Blog\n   - 링크: https://blog.jetbrains.com/idea/2025/07/intellij-idea-unified-distribution-plan/\n\n26. **Cloud CISO Perspectives: Our Big Sleep agent makes a big leap, and other AI news**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-our-big-sleep-agent-makes-big-leap/\n\n27. **AI/ML-ready Apache Spark with Dataproc**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/products/data-analytics/dataproc-features-enable-aiml-ready-apache-spark/\n\n28. **Tzafon selects Google Cloud to build next-generation agentic machine intelligence**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/topics/startups/tzafon-builds-the-next-generation-of-agentic-machine-intelligence-with-google-cloud-infrastructure/\n\n\n\n**분석 지침:**\n- 반드시 위에 명시된 마크다운 헤더 구조를 정확히 따르세요\n- 각 섹션은 2-3개 포인트로 제한\n- 구체적인 수치와 데이터 활용으로 신뢰성 확보\n\n**🌟 URL 컨텍스트 활용 지침:**\n- 제공된 URL의 내용을 적극적으로 활용하여 깊이 있는 분석을 제공하세요\n- 단순 요약이 아닌, 기사의 핵심 인사이트와 숨겨진 의미를 발굴하세요\n- 여러 기사 간의 연결점을 찾아 큰 그림을 그려주세요\n- 기술적 세부사항과 실제 영향력을 균형있게 다루세요\n\n**🎯 독자 재미 극대화 지침:**\n- 딱딱한 기술 뉴스를 생동감 있게 전달하세요\n- 적절한 비유와 실생활 예시로 복잡한 개념을 쉽게 설명하세요\n- 놀라운 사실이나 의외의 관점을 제시하여 호기심을 자극하세요\n- 스토리텔링 요소를 활용하여 뉴스를 하나의 이야기로 엮어주세요\n- 각 프리셋의 톤에 맞는 위트와 유머를 적절히 활용하세요\n\n**🚨 인용 검수 체크리스트:**\n1. 본문의 모든 사실, 수치, 기업명, 기술명에 [^숫자] 인용이 있는가?\n2. 문서 맨 끝에 모든 footnote 정의가 있고, 각각 클릭 가능한 URL을 포함하는가?\n3. [^1]: 기사제목 - https://링크 형식이 정확한가?\n4. 본문에서 언급한 모든 [^숫자]에 대응하는 footnote가 있는가?\n- 최종 제출 전 필수 검토: 위 체크리스트를 모두 확인하세요",
  "articles": [
    {
      "title": "Command GitHub's Coding Agent from VS Code",
      "link": "https://code.visualstudio.com/blogs/2025/07/17/copilot-coding-agent",
      "source": "Visual Studio Code - Code Editing. Redefined.",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z",
      "description": "\n      \u003cp\u003eVS Code's integration with GitHub Copilot Coding Agent allows you to delegate tasks to the agent and let it handle them in the background.\u003c/p\u003e\n      \u003cp\u003e\u003ca href=\"https://code.visualstudio.com/blogs/2025/07/17/copilot-coding-agent\"\u003eRead the full article\u003c/a\u003e\u003c/p\u003e\n    "
    },
    {
      "title": "Introducing ChatGPT agent",
      "link": "https://openai.com/index/introducing-chatgpt-agent",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T10:00:00Z",
      "description": "Introducing ChatGPT agent: it thinks and acts, using tools to complete tasks like research, bookings, and slideshows—all with your guidance."
    },
    {
      "title": "ChatGPT agent System Card",
      "link": "https://openai.com/index/chatgpt-agent-system-card",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T10:00:00Z",
      "description": "ChatGPT agent System Card: OpenAI’s agentic model unites research, browser automation, and code tools with safeguards under the Preparedness Framework."
    },
    {
      "title": "Statement from the OpenAI Board of Directors on the Nonprofit Commission Report",
      "link": "https://openai.com/index/nonprofit-commission-report",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z",
      "description": "The Board of Directors thanks the members of the independent OpenAI Nonprofit Commission for their extensive work and engagement."
    },
    {
      "title": "Agent bio bug bounty call",
      "link": "https://openai.com/bio-bug-bounty",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z",
      "description": "OpenAI invites researchers to its Bio Bug Bounty. Test the ChatGPT agent’s safety with a universal jailbreak prompt and win up to $25,000."
    },
    {
      "title": "OpenAI nonprofit jam",
      "link": "https://openai.com/global-affairs/openai-nonprofit-jam",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z",
      "description": "At OpenAI, we build tools to help people solve hard problems—including nonprofits working on the frontlines of their communities. The OpenAI Academy is teaming up with the Walton Family Foundation, Emerson Collective, and a network of local nonprofit organizations to host the Nonprofit Jam—a one-day, nationwide event bringing together more than 1,000 nonprofit leaders across 10 locations."
    },
    {
      "title": "Apple Arcade launches special crossover events featuring SpongeBob SquarePants\n",
      "link": "https://www.apple.com/newsroom/2025/07/apple-arcade-launches-special-crossover-events-featuring-spongebob-squarepants/",
      "source": "Apple Newsroom",
      "category": "tech",
      "publishedAt": "2025-07-17T13:59:59.528Z",
      "description": "This month, SpongeBob SquarePants makes a splash in Snake.io+ and Crossy Road Castle with special events available exclusively on Apple Arcade."
    },
    {
      "title": "Apple News+ introduces Emoji Game\n",
      "link": "https://www.apple.com/newsroom/2025/07/apple-news-plus-introduces-emoji-game/",
      "source": "Apple Newsroom",
      "category": "tech",
      "publishedAt": "2025-07-17T11:59:21.529Z",
      "description": "Today, Apple News+ debuted Emoji Game, an original puzzle that challenges subscribers to use emoji to complete short phrases."
    },
    {
      "title": "Postgres 액티브-액티브 복제 확장 기능",
      "link": "https://news.hada.io/topic?id=22038",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-18T01:33:45+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003epgactive\u003c/strong\u003e는 PostgreSQL을 위한 \u003cstrong\u003e액티브-액티브 복제\u003c/strong\u003e 확장 기능임\u003c/li\u003e\n\u003cli\u003e이 확장 기능은 여러 데이터베이스 인스턴스에서 \u003cstrong\u003e동시에 데이터 쓰기\u003c/strong\u003e와 복제를 가능하게 함\u003c/li\u003e\n\u003cli\u003e여러 리전에서 \u003cstrong\u003e고가용성 데이터베이스 구성\u003c/strong\u003e이나, 쓰기 지연...\u003c/p\u003e"
    },
    {
      "title": "셰프의 칼 vs. 스위스 아미 나이프: 스타트업의 진짜 경쟁력 [번역글]",
      "link": "https://news.hada.io/topic?id=22037",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T23:33:04+09:00",
      "description": "\u003ch4\u003e1. 비유의 출발점: 도구 선택의 딜레마\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e글은 \u003cstrong\u003e개발 도구\u003c/strong\u003e 또는 \u003cstrong\u003e제품\u003c/strong\u003e 선택에 있어 두 가지 상징적 도구(셰프 나이프, 스위스 아미 나이프)로 접근합니다.\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003e셰프 나이프(Chef’s Knife)\u003c/strong\u003e: 오직 요리에 ‘자르는’ 용도에만 최적화된 도구. 단...\u003c/p\u003e"
    },
    {
      "title": "아이폰 미니 사이즈의 안드로이드 폰을 원함 (2022)",
      "link": "https://news.hada.io/topic?id=22036",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T22:35:33+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003e작은 프리미엄 안드로이드 폰\u003c/strong\u003e에 대한 시장의 부재로, 개인이 직접 관심자들을 모아 제조사에 압박을 주고자 하는 움직임임\u003c/li\u003e\n\u003cli\u003e현재 6인치 미만의 \u003cstrong\u003e고사양 안드로이드 폰\u003c/strong\u003e은 존재하지 않으며, 작은 크기, 한 손 사용성, 휴대성 등이 핵심 가치임\u003c/li\u003e\n\u003cli\u003e이상적인 스펙...\u003c/p\u003e"
    },
    {
      "title": "전 Waymo 엔지니어들, 건설 자동화를 위해 Bedrock Robotics 설립",
      "link": "https://news.hada.io/topic?id=22035",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T17:35:16+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e전 \u003cstrong\u003eWaymo\u003c/strong\u003e 출신 엔지니어들이 \u003cstrong\u003eBedrock Robotics\u003c/strong\u003e를 설립해 건설 현장 자동화에 주력함\u003c/li\u003e\n\u003cli\u003e이 스타트업은 \u003cstrong\u003e기존 건설 차량\u003c/strong\u003e에 자율주행 키트 장착을 목표로 하며, \u003cstrong\u003e80백만 달러\u003c/strong\u003e의 투자 유치 소식을 발표함\u003c/li\u003e\n\u003cli\u003eBedrock Robotics는 ...\u003c/p\u003e"
    },
    {
      "title": "Builder.io 개발자가 Claude Code를 사용하는 방법 (+ best tips)",
      "link": "https://news.hada.io/topic?id=22034",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:59:34+09:00",
      "description": "\u003cp\u003e예전에는 Cursor 파워 유저였고 \u003ca href=\"https://www.builder.io/blog/cursor-tips\"\u003eHow I use Cursor (+ my best tips)\u003c/a\u003e라는 글로 인기를 끌었던 \u003ca href=\"https://www.builder.io/\"\u003eBuilder.io\u003c/a\u003e의 Steve Swell이 이번에는 좋은 클로드 코드 팁 글을 올려줬길래 번역 + 요약해서 공유드립니다. (블로그 글에는...\u003c/p\u003e"
    },
    {
      "title": "Uzu - 애플 실리콘용 고성능 AI 추론 엔진",
      "link": "https://news.hada.io/topic?id=22033",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:51:02+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003eApple Silicon 환경에서 \u003cstrong\u003eAI 모델을 빠르게 실행\u003c/strong\u003e하기 위한 \u003cstrong\u003eRust 기반 추론 엔진\u003c/strong\u003e\n\u003c/li\u003e\n\u003cli\u003eGPU 커널 또는 \u003cstrong\u003eCoreML 하단의 MPSGraph\u003c/strong\u003e를 선택적으로 활용하는 \u003cstrong\u003e하이브리드 구조\u003c/strong\u003e\n\u003c/li\u003e\n\u003cli\u003e자체 포맷 모델을 사용하며, \u003cstrong\u003elalamo 도구를 통...\u003c/p\u003e"
    },
    {
      "title": "RAG는 죽지 않았다",
      "link": "https://news.hada.io/topic?id=22032",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:31:01+09:00",
      "description": "\u003cblockquote\u003e\n\u003cp\u003eRAG의 미래는 \u0026quot;\u003cstrong\u003e더 큰 컨텍스트 창\u003c/strong\u003e이 아니라, \u003cstrong\u003e더 나은 검색\u003c/strong\u003e에 있다\u0026quot;\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026quot;RAG Is Dead\u0026quot;라는 말은 \u003cstrong\u003e2023년식 단순 RAG 구현 방식\u003c/strong\u003e에만 해당되며, 진짜 문제는 정보 손실이 큰 \u003cstrong\u003e단일 벡터 기반 검색...\u003c/p\u003e"
    },
    {
      "title": "거의 한 세기만에 발견된 첫 번째 새로운 종류의 자석: Altermagnets",
      "link": "https://news.hada.io/topic?id=22031",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:28:19+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eLibor Šmejkal\u003c/strong\u003e은 M. C. Escher의 예술 작품에서 영감을 받아, \u003cstrong\u003e완전히 새로운 자성\u003c/strong\u003e의 존재를 예측함\u003c/li\u003e\n\u003cli\u003e인류는 \u003cstrong\u003e오랜 세월 동안 자석\u003c/strong\u003e을 알고 있었으며, 현대 기술의 핵심 역할을 담당함\u003c/li\u003e\n\u003cli\u003e100년 동안 \u003cstrong\u003e자석의 종류가 두 가지뿐\u003c/strong...\u003c/p\u003e"
    },
    {
      "title": "Firefox는 앞으로 어디로 갈 것인가?",
      "link": "https://news.hada.io/topic?id=22030",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:25:17+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eMozilla\u003c/strong\u003e는 사용자 의견을 바탕으로 \u003cstrong\u003e새로운 기능 개발\u003c/strong\u003e을 이어감\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e프로필, 탭 그룹, 세로 탭 등 주요 기능들\u003c/strong\u003e이 모두 사용자 요청에 의해 도입됨\u003c/li\u003e\n\u003cli\u003eFirefox 개발팀은 사용자의 \u003cstrong\u003e직접적인 의견 수렴 방식\u003c/strong\u003e을 새롭게 시도함\u003c/l...\u003c/p\u003e"
    },
    {
      "title": "Helix Editor 25.07",
      "link": "https://news.hada.io/topic?id=22029",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:22:16+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003eHelix 25.07은 \u003cstrong\u003e핵심 컴포넌트의 대체\u003c/strong\u003e와 다수의 신규 기능 추가를 포함함\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e파일 탐색기, LSP 문서 색상 표시, 커맨드 모드 개선\u003c/strong\u003e 등 사용성과 워크플로우가 크게 향상됨\u003c/li\u003e\n\u003cli\u003e문법 하이라이트와 쿼리 최적화를 위해 신규 crate인 \u003cstrong\u003eTree-house\u003c/strong\u003e가 ...\u003c/p\u003e"
    },
    {
      "title": "GoFiber v3 + Testcontainers: Production-like Local Dev with Air",
      "link": "https://www.docker.com/blog/go-local-dev-fiber-v3-testcontainers/",
      "source": "Docker Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T13:49:39Z",
      "description": "Intro Local development can be challenging when apps rely on external services like databases or queues, leading to brittle scripts and inconsistent environments. Fiber v3 and Testcontainers solve this by making real service dependencies part of your app’s lifecycle, fully managed, reproducible, and developer-friendly. With the upcoming v3 release, Fiber is introducing a powerful new..."
    },
    {
      "title": "Back to The Future: Evaluating AI Agents on Predicting Future Events",
      "link": "https://huggingface.co/blog/futurebench",
      "source": "Hugging Face - Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z"
    },
    {
      "title": "Five Big Improvements to Gradio MCP Servers",
      "link": "https://huggingface.co/blog/gradio-mcp-updates",
      "source": "Hugging Face - Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z"
    },
    {
      "title": "We’re taking legal action against the BadBox 2.0 botnet.",
      "link": "https://blog.google/technology/safety-security/google-taking-legal-action-against-the-badbox-20-botnet/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1_Hero_1.max-600x600.format-webp.webp\"\u003eRecently, our researchers partnered with HUMAN Security and Trend Micro to uncover BadBox 2.0, the largest known botnet of internet-connected TVs. Building on our previo…"
    },
    {
      "title": "New in Gemini Code Assist: Agent Mode and IDE enhancements",
      "link": "https://blog.google/technology/developers/gemini-code-assist-updates-july-2025/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GCA_Hero_1.max-600x600.format-webp.webp\"\u003eCode Assist’s June updates bring two big changes: a new agent mode and IDE enhancements."
    },
    {
      "title": "Quicksilver v2: evolution of a globally distributed key-value store (Part 2)",
      "link": "https://blog.cloudflare.com/quicksilver-v2-evolution-of-a-globally-distributed-key-value-store-part-2-of-2/",
      "source": "Cloudflare Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T13:00:00Z",
      "description": " This is part two of a story about how we overcame the challenges of making a complex system more scalable. "
    },
    {
      "title": "IntelliJ IDEA Moves to the Unified Distribution",
      "link": "https://blog.jetbrains.com/idea/2025/07/intellij-idea-unified-distribution-plan/",
      "source": "IntelliJ IDEA : IntelliJ IDEA – the IDE for Professional Development in Java and Kotlin | The JetBrains Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T10:00:02Z",
      "description": "We are excited to announce the next step for IntelliJ IDEA: we are moving to a single, unified distribution. And yes, before you ask, our commitment to open source remains as strong as ever. There will be just one IntelliJ IDEA installer, replacing the separate downloads for Community Edition and Ultimate Edition. In this new [\u0026#8230;]"
    },
    {
      "title": "Cloud CISO Perspectives: Our Big Sleep agent makes a big leap, and other AI news",
      "link": "https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-our-big-sleep-agent-makes-big-leap/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-07-17T16:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph\"\u003e\u003cp data-block-key=\"eucpw\"\u003eWelcome to the first Cloud CISO Perspectives for July 2025. Today, Sandra Joyce, vice president, Google Threat Intelligence, talks about an incredible milestone with our Big Sleep AI agent, as well as other news from the intersection of security and AI.\u003c/p\u003e\u003cp data-block-key=\"8pj1e\"\u003eAs with all Cloud CISO Perspectives, the contents of this newsletter are posted to the \u003ca href=\"https://cloud.google.com/blog/products/identity-security/\"\u003eGoogle Cloud blog\u003c/a\u003e. If you’re reading this on the website and you’d like to receive the email version, you can \u003ca href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\"\u003esubscribe here\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-aside\"\u003e\u003cdl\u003e\n    \u003cdt\u003easide_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;title\u0026#x27;, \u0026#x27;Get vital board insights with Google Cloud\u0026#x27;), (\u0026#x27;body\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6ba31f910\u0026gt;), (\u0026#x27;btn_text\u0026#x27;, \u0026#x27;Visit the hub\u0026#x27;), (\u0026#x27;href\u0026#x27;, \u0026#x27;https://cloud.google.com/solutions/security/board-of-directors?utm_source=cloud_sfdc\u0026amp;utm_medium=email\u0026amp;utm_campaign=FY24-Q2-global-PROD941-physicalevent-er-CEG_Boardroom_Summit\u0026amp;utm_content=-\u0026amp;utm_term=-\u0026#x27;), (\u0026#x27;image\u0026#x27;, \u0026lt;GAEImage: GCAT-replacement-logo-A\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003ch3 data-block-key=\"hswvv\"\u003eOur Big Sleep agent makes a big leap, and other AI news\u003c/h3\u003e\u003cp data-block-key=\"eslka\"\u003e\u003ci\u003eBy Sandra Joyce, vice president, Google Threat Intelligence\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_with_image\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\n  \u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\n    \u003cdiv class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\n\n      \n\n\n\n\n\n\n  \n\n    \u003cfigure class=\"article-image--wrap-small\n      \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2022_S_Joyce_Headshot.max-1000x1000.jpg\"\n        \n          alt=\"Sandra Joyce\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"nj7d4\"\u003eSandra Joyce, vice president, Google Threat Intelligence\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n\n\n\n\n\n      \u003cp data-block-key=\"0jyqm\"\u003eBusiness leaders everywhere are scrambling to implement AI in a way that creates value while trying to define what that value means — at the same time. As we build on our efforts to shape AI and define AI workflows in cybersecurity, we are already really excited about using AI in the work that we do.\u003c/p\u003e\u003cp data-block-key=\"f0get\"\u003eI spoke about some of that work at the \u003ca href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-data-driven-insights-ai-cybersecurity\"\u003eRSA Conference in April\u003c/a\u003e, including how AI is reshaping cybersecurity and how Google uses data to drive our practical applications of AI in both attack and defense. We revealed Tuesday that our \u003ca href=\"https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html\"\u003eBig Sleep AI agent\u003c/a\u003e, first introduced in November 2024 by Google DeepMind and Project Zero, has taken a \u003ca href=\"https://blog.google/technology/safety-security/cybersecurity-updates-summer-2025/\"\u003every significant step for defenders\u003c/a\u003e: \u003cb\u003eWe believe this is the first time an AI agent has been used to directly foil efforts to exploit a vulnerability in the wild\u003c/b\u003e.\u003c/p\u003e\u003cp data-block-key=\"3un3u\"\u003eThrough the combination of threat intelligence from the Google Threat Intelligence Group (GTIG) and the Big Sleep AI agent, we were recently able to identify a critical \u003ca href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-6965\"\u003eSQLite vulnerability\u003c/a\u003e known only to threat actors that was imminently going to be used — and actually cut it off beforehand.\u003c/p\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c/div\u003e\n\u003cdiv class=\"block-pull_quote\"\u003e\u003cdiv class=\"uni-pull-quote h-c-page\"\u003e\n  \u003csection class=\"h-c-grid\"\u003e\n    \u003cdiv class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\n      \u003cdiv class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\"\u003e\n        \u003cq class=\"uni-pull-quote__text\"\u003eWith Big Sleep, we’ve demonstrated how we can find vulnerabilities that defenders don’t yet know about. In this case, we found a vulnerability that the attackers knew about and had every intention of using, and we were able to detect and report it for patching before they could exploit it.\u003c/q\u003e\n\n        \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/section\u003e\n\u003c/div\u003e\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003cp data-block-key=\"dnpuq\"\u003eDeveloped by Google DeepMind and Google Project Zero, Big Sleep can help security researchers find zero-day (previously-unknown) software security vulnerabilities. Since it was introduced last year, it has continued to discover multiple flaws in widely-used software, exceeding our expectations and accelerating AI-powered vulnerability research.\u003c/p\u003e\u003cp data-block-key=\"41vjp\"\u003eWith Big Sleep, we’ve demonstrated how we can find vulnerabilities that defenders don’t yet know about. In this case, we found a vulnerability that the attackers knew about and had every intention of using, and we were able to detect and report it for patching before they could exploit it.\u003c/p\u003e\u003cp data-block-key=\"a68k0\"\u003eAttackers have long had an advantage because they were taking shots at a massive goal with a lot of ground to defend, but the productivity gains from a defender’s point of view are astounding to us. If you had a human in place of Big Sleep, they would’ve had to pour over two different versions of open-source source code and manually see where the vulnerability was, all while knowing that attackers were planning on using this vulnerability soon.\u003c/p\u003e\u003cp data-block-key=\"ep1m0\"\u003eSpeed and accuracy made all the difference in this case, which gave us an edge over threat actors. Since defenders own and control these systems, AI has given us a very powerful development (and vulnerability remediation) advantage.\u003c/p\u003e\u003cp data-block-key=\"5k04t\"\u003eBig Sleep is also being deployed to help improve the security of other widely-used open-source projects, too — a major win for ensuring faster, more effective security across the internet more broadly.\u003c/p\u003e\u003cp data-block-key=\"fvuk6\"\u003e\u003cb\u003eEmpowering defensive AI agents\u003c/b\u003e\u003c/p\u003e\u003cp data-block-key=\"e96nf\"\u003eWhile AI agents represent a sea change for cybersecurity, the work they do needs to be done safely and responsibly. We \u003ca href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-how-google-secures-ai-agents/\"\u003eoutlined our approach to building AI agents\u003c/a\u003e in June in ways that safeguard privacy, mitigate the risks of rogue actions, and ensure the agents operate with the benefit of human oversight and transparency. When deployed according to \u003ca href=\"https://static.googleusercontent.com/media/publicpolicy.google/en//resources/google_commitment_secure_by_design_overview.pdf\" target=\"_blank\"\u003esecure by design principles\u003c/a\u003e, agents can give defenders an edge like no other tool that came before them.\u003c/p\u003e\u003cp data-block-key=\"cnsou\"\u003eWe will continue to share our agentic AI insights and report findings through our industry-standard disclosure process. You can keep tabs on all publicly-disclosed vulnerabilities from Big Sleep \u003ca href=\"https://issuetracker.google.com/issues?q=componentid:1836411\u0026amp;s=type:desc\u0026amp;s=issue_id:desc\" target=\"_blank\"\u003eon our issue tracker page\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"12pf8\"\u003eWe’re seeing the \u003ca href=\"https://cloud.google.com/transform/3-new-ways-ai-security-sidekick?e=48754805\"\u003eimpact of AI across security\u003c/a\u003e, from boosting threat hunting to stronger security validations to smarter red team analyses. Similarly, the speed and accuracy of AI comes to aid defenders when dealing with the ever-growing onslaught of email phishing attacks. Attackers have been using AI to improve a lot of the previous hints that a legit-looking email was actually a phishing attack, such as using colloquial language, proper slang, and tailoring the email to the recipient.\u003c/p\u003e\u003cp data-block-key=\"697bd\"\u003eYet if you train the AI model to look at what spearphishing emails look like, it can get better at detection, triage, and identifying phishing threats faster and at a scale that if a human has to jump in to review something, they have to review less now. Our AI-powered defenses help Gmail block all sorts of phishing, spam, and malware.\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"7ds5q\"\u003eGmail automatically \u003ca href=\"https://cloud.google.com/blog/products/workspace/how-gmail-helps-users-avoid-email-scams\"\u003eblocks more than 99.9%\u003c/a\u003e of spam, phishing and malware, and protects over 1.5 billion inboxes.\u003c/li\u003e\u003cli data-block-key=\"g3fe\"\u003eWe developed several ground-breaking AI models last year that \u003ca href=\"https://blog.google/products/gmail/gmail-holidays-2024-spam-scam/\" target=\"_blank\"\u003esignificantly strengthened Gmail cyber defenses\u003c/a\u003e, including a new large language model (LLM) that we trained on phishing, malware and spam that blocks 20% more spam than before and reviews 1,000 times more user-reported spam daily.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"2sjbg\"\u003eWhen it comes to attackers and their use of AI, we’re still in the “before times.” As I noted at RSAC, Google Threat Intelligence Group has seen AI used to flesh out code, we've seen AI used for deepfakes, and to craft better spearphishing emails, but we’ve yet to see a big, game-changing incident where AI did something that humans simply couldn't have done. We haven't seen anything like an agentic attacker or an agentic attack, or a self-perpetuated campaign.\u003c/p\u003e\u003cp data-block-key=\"fh7v7\"\u003eI fully anticipate that these types of attacks are coming, so it’s \u003ca href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-ai-vendors-should-share-vulnerability-research-heres-why/\"\u003ecrucial that AI developers collaborate\u003c/a\u003e across industry and with public sector partners to prepare defenders and ensure AI’s success. As part of our efforts to build partnerships, we worked with industry partners last year to launch the \u003ca href=\"https://blog.google/technology/safety-security/google-coalition-for-secure-ai/\" target=\"_blank\"\u003eCoalition for Secure AI\u003c/a\u003e (CoSAI), an initiative to ensure the safe implementation of AI systems.\u003c/p\u003e\u003cp data-block-key=\"sit3\"\u003eTo further this work, we announced yesterday that Google will donate data from our \u003ca href=\"http://saif.google/\" target=\"_blank\"\u003eSecure AI Framework\u003c/a\u003e (SAIF) to help accelerate CoSAI’s agentic AI, cyber defense, and software supply chain security workstreams.\u003c/p\u003e\u003cp data-block-key=\"27nn7\"\u003eAt Google, we’ve been investing in AI and machine learning tools for more than a decade. While we have always believed in AI’s potential to help make software more secure, over the last year we have seen real leaps in its capabilities, with AI redefining what lasting and durable cybersecurity can look like.\u003c/p\u003e\u003cp data-block-key=\"8sopv\"\u003eYou can learn more about our efforts to use AI to help secure and support organizations around the world from our \u003ca href=\"https://cloud.google.com/solutions/security/leaders\"\u003eOffice of the CISO\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-aside\"\u003e\u003cdl\u003e\n    \u003cdt\u003easide_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;title\u0026#x27;, \u0026#x27;Join the Google Cloud CISO Community\u0026#x27;), (\u0026#x27;body\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6ba31fac0\u0026gt;), (\u0026#x27;btn_text\u0026#x27;, \u0026#x27;Learn more\u0026#x27;), (\u0026#x27;href\u0026#x27;, \u0026#x27;https://rsvp.withgoogle.com/events/ciso-community-interest?utm_source=cgc-blog\u0026amp;utm_medium=blog\u0026amp;utm_campaign=2024-cloud-ciso-newsletter-events-ref\u0026amp;utm_content=-\u0026amp;utm_term=-\u0026#x27;), (\u0026#x27;image\u0026#x27;, \u0026lt;GAEImage: GCAT-replacement-logo-A\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003ch3 data-block-key=\"4bd61\"\u003e\u003cb\u003eIn case you missed it\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"2kd9o\"\u003eHere are the latest updates, products, services, and resources from our security teams so far this month:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"cnq1p\"\u003e\u003cb\u003eSummer of cybersecurity: Empowering defenders with AI\u003c/b\u003e: We’re sharing more about our latest AI innovations for security, public and private partnerships, and new initiatives to secure the digital ecosystem for everyone — including our plans for Black Hat and Def Con. \u003ca href=\"https://blog.google/technology/safety-security/cybersecurity-updates-summer-2025/\" target=\"_blank\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"ekhmq\"\u003e\u003cb\u003eEngineering Deutsche Telekom's sovereign data platform\u003c/b\u003e: Ashutosh Mishra, vice-president at Deutsche Telekom, explains how Google Cloud helped the company build its sovereign data platform. \u003ca href=\"https://cloud.google.com/blog/topics/customers/engineering-deutsche-telekoms-sovereign-data-platform\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"6tjhs\"\u003e\u003cb\u003eNew networking features in GDC air-gapped can power innovation\u003c/b\u003e: Three major advancements in Google Distributed Cloud air-gapped networking are designed to give you more control over your environment. \u003ca href=\"https://cloud.google.com/blog/topics/hybrid-cloud/new-networking-features-in-gdc-air-gapped-can-power-innovation\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"2vl0g\"\u003e\u003cb\u003eUnpacking security in Looker Conversational Analytics\u003c/b\u003e: Your data remains under your control when using Looker Conversational Analytics, letting you use Gemini to better understand your data. \u003ca href=\"https://cloud.google.com/blog/products/business-intelligence/understanding-looker-conversational-analytics-security\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"1bevj\"\u003e\u003cb\u003eOpening up Zero-Knowledge Proof technology to promote privacy in age assurance\u003c/b\u003e: Open sourcing these powerful cryptographic tools will make it much easier for private and public sector developers to build their own privacy-enhancing applications and digital ID solutions, meeting an urgent need. \u003ca href=\"https://blog.google/technology/safety-security/opening-up-zero-knowledge-proof-technology-to-promote-privacy-in-age-assurance/\" target=\"_blank\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"i63i\"\u003e\u003cb\u003eAdvancing protection in Chrome on Android\u003c/b\u003e: Android recently announced Advanced Protection, which extends our Advanced Protection Program to a device-level security setting for Android users that need heightened security. Here’s how it integrates with Chrome on Android. \u003ca href=\"https://security.googleblog.com/2025/07/advancing-protection-in-chrome-on.html\" target=\"_blank\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"h2lk\"\u003ePlease visit the Google Cloud blog for more security stories \u003ca href=\"https://cloud.google.com/blog/products/identity-security\"\u003epublished this month\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-aside\"\u003e\u003cdl\u003e\n    \u003cdt\u003easide_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;title\u0026#x27;, \u0026#x27;Fact of the month\u0026#x27;), (\u0026#x27;body\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6ba31f340\u0026gt;), (\u0026#x27;btn_text\u0026#x27;, \u0026#x27;Learn more\u0026#x27;), (\u0026#x27;href\u0026#x27;, \u0026#x27;https://bughunters.google.com/blog/5753079171252224/ai-bugswat-in-tokyo-2025-hacker-roadshow\u0026#x27;), (\u0026#x27;image\u0026#x27;, \u0026lt;GAEImage: GCAT-replacement-logo-A\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003ch3 data-block-key=\"29tyz\"\u003e\u003cb\u003eThreat Intelligence news\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"5fn6d\"\u003e\u003cb\u003eWhy isolated recovery environments are critical in modern cyber resilience\u003c/b\u003e: IREs can provide a measurable, critical difference in disaster recovery strategies. Here are practical steps organizations can take to implement them effectively. \u003ca href=\"https://cloud.google.com/blog/topics/threat-intelligence/isolated-recovery-environments-modern-cyber-resilience\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e\u003c/li\u003e\u003cli data-block-key=\"dbm1d\"\u003e\u003cb\u003eSecuring protection relays in modern substations\u003c/b\u003e: Cyberattacks on digitized protection relays in substations pose a severe threat to power grid stability, risking widespread outages and infrastructure damage. With CISA warning of heightened risks from Iran-nexus groups targeting vital networks, here’s what critical infrastructure providers need to know about securing these relays. \u003ca href=\"https://cloud.google.com/blog/topics/threat-intelligence/securing-protection-relays-modern-substations\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"9htki\"\u003ePlease visit the Google Cloud blog for more threat intelligence stories \u003ca href=\"https://cloud.google.com/blog/topics/threat-intelligence/\"\u003epublished this month\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003ch3 data-block-key=\"rcfc5\"\u003e\u003cb\u003eNow hear this: Podcasts from Google Cloud\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"f35sm\"\u003e\u003cb\u003eThe SIEM Paradox: Logs, lies, and failing to detect\u003c/b\u003e: Svetla Yankova, founder and CEO, Citreno, joins hosts Anton Chuvakin and Tim Peacock to talk about SIEM tooling and threat detection challenges. \u003ca href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep234-the-siem-paradox-logs-lies-and-failing-to-detect/\" target=\"_blank\"\u003e\u003cb\u003eListen here\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"ja07\"\u003e\u003cb\u003eResilience and security with Google Product Security Engineering\u003c/b\u003e: How does Google balance high reliability and operational excellence with the needs of detection and response? Cristina Vintila, product security engineering manager, Google Cloud, talks with Anton and Tim about how PSE has evolved. \u003ca href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep233-product-security-engineering-at-google-resilience-and-security/\" target=\"_blank\"\u003e\u003cb\u003eListen here\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"39ue3\"\u003e\u003cb\u003eThe human element when designing privacy\u003c/b\u003e: From consulting with a world leader to Fuschia, Sarah Aoun, Google privacy engineer, goes deep into the nuances, challenges, and excitement of building digital privacy with Anton and Tim. \u003ca href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep232-the-human-element-of-privacy-protecting-high-risk-targets-and-designing-systems/\" target=\"_blank\"\u003e\u003cb\u003eListen here\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"5v8q\"\u003e\u003cb\u003eThe Defender’s Advantage: The rise of ClickFix\u003c/b\u003e: Dima Lenz, security engineer, Google Threat Intelligence Group, joins host Luke McNamara to discuss how threat actors have been using ClickFix to socially engineer users. \u003ca href=\"https://www.youtube.com/watch?v=qPLTSEYD6sg\u0026amp;list=PLjiTz6DAEpuINUjE8zp5bAFAKtyGJvnew\" target=\"_blank\"\u003e\u003cb\u003eListen here\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"3pdvm\"\u003eTo have our Cloud CISO Perspectives post delivered twice a month to your inbox, \u003ca href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\"\u003esign up for our newsletter\u003c/a\u003e. We’ll be back in a few weeks with more security-related updates from Google Cloud.\u003c/p\u003e\u003c/div\u003e"
    },
    {
      "title": "AI/ML-ready Apache Spark with Dataproc",
      "link": "https://cloud.google.com/blog/products/data-analytics/dataproc-features-enable-aiml-ready-apache-spark/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-07-17T16:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eApache Spark is the cornerstone for large-scale data processing, model training, and inference for AI/ML workloads. Yet, the complexities of environment configuration, dependency management, and MLOps integration can slow you down. To accelerate your AI/ML journey, \u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDataproc\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e now delivers powerful, ML-ready capabilities for Spark. Available on both Dataproc on Compute Engine clusters and \u003c/span\u003e\u003ca href=\"https://cloud.google.com/products/serverless-spark\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGoogle Cloud Serverless for Apache Spark\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, these enhancements are engineered to streamline development and operations, reducing setup overhead and simplifying workflows. This allows data scientists and engineers to dedicate more time to building and deploying impactful models rather than wrestling with infrastructure. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eLet's explore what’s new and how to start using these innovations today.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAI/ML-capable runtimes\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eGetting a Spark environment ready for ML, especially with GPU acceleration, used to involve custom scripts and manual configuration. Dataproc now streamlines this with ML Runtimes. ML Runtimes is a specialized Dataproc on Compute Engine image version, starting from 2.3 for Ubuntu-based images, designed to accelerate ML workloads. It ships with pre-packaged GPU drivers (NVIDIA Driver, CUDA, cuDNN, NCCL) and common ML libraries such as PyTorch, XGBoost, tokenizers, transformers etc, significantly cutting down cluster provisioning and setup time. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eGoogle Cloud Serverless for Apache Spark also benefits from runtimes with pre-installed ML libraries, bringing the same ease of use to a serverless environment. These also include libraries such as XGBoost, PyTorch, tokenizers, transformers, etc. \u003c/span\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003e\"At Snap we use Spark on Dataproc for a variety of analytics and ML workloads including running GPU accelerated Spark Rapids, and model training and inference with PyTorch. The new Dataproc 2.3 ML runtime has been really helpful — reducing our cluster startup latency by 75% and eliminating toil for our ML Platform developers to build and manage environments.”\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e- Prudhvi Vatala, Sr. Manager, Snap Inc.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIt’s easy to \u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc/docs/quickstarts/create-cluster-console\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ecreate a Dataproc \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eon a compute\u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc/docs/quickstarts/create-cluster-console\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003e Engine cluster\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, specifying the ML image version and the required GPU accelerators for your workers.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;gcloud dataproc clusters create \u0026lt;your-cluster-name\u0026gt; \\\\\\r\\n--project=\u0026lt;your-project-id\u0026gt; \\\\\\r\\n--region=\u0026lt;your-region\u0026gt; \\\\\\r\\n--image-version=2.3-ml-unbuntu \\\\\\r\\n--master-machine-type g2-standard-4 --master-accelerator=type=nvidia-l4,count=1\\r\\n--worker-machine-type=g2-standard-8 \\\\\\r\\n--worker-accelerator type=nvidia-l4,count=1\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be9a90\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAdditionally, Serverless Spark sessions (Generally Available) also support GPUs, and come similarly packaged with GPU drivers and common ML libraries.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eDevelop Spark applications in Colab or your favorite IDE\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eNow, you can develop and run Spark applications using Colab Enterprise notebooks in BigQuery Studio or via integrated development environments (IDEs) like \u003c/span\u003e\u003ca href=\"https://code.visualstudio.com/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eVSCode\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e and \u003c/span\u003e\u003ca href=\"https://jupyter.org/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eJupyter\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eBigQuery Colab enterprise notebooks are available within BigQuery Studio with native support for Spark application development. With Colab Enterprise notebooks, you can create  Serverless Spark sessions using Spark Connect and work with your tables in \u003c/span\u003e\u003ca href=\"https://cloud.google.com/bigquery/docs/about-blms\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eBigLake metastore.\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eColab notebook provides advanced features such as gen AI code assistance and error explanation, with error correction coming soon. It also supports observability for your Spark jobs and management of Spark sessions. In addition, the Colab notebooks lets you mix BigQuery SQL with Spark code in a single notebook and interoperate on the resulting tables. Once your code is ready, you can schedule notebooks via the inbuilt scheduling functionality or use BigQuery Pipelines for more complicated DAGs.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_fjVpMdx.gif\"\n        \n          alt=\"1\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eYou can also use IDEs such as Visual Studio Code or JupyterLab for Spark application development. JupyterLab users can use the \u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc-serverless/docs/quickstarts/jupyterlab-sessions\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDataproc JupyterLab plugin\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to simplify interactive development with Spark serverless sessions and simplify creation and submission of batch jobs via Serverless batch jobs. This plugin comes preinstalled in Vertex Workbench, so you can be productive in minutes. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_nxDaXdB.max-1000x1000.png\"\n        \n          alt=\"2\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOn VS Code, you can use the \u003c/span\u003e\u003ca href=\"https://cloud.google.com/code\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eCloud Code\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e extension, which supports development against a range of Google Cloud services. After configuring the Cloud Code extension, you can browse BigQuery datasets and tables, browse and manage your Dataproc compute resources (clusters, serverless interactive sessions and batch), create Spark notebooks from available templates or start developing on your own, and then schedule your workloads all from VS Code. This choice in development tooling allows you to pick one that best suits your workflow, without sacrificing access to the power of Dataproc Spark.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eDistributed training and inference with GPU support\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDataproc’s ML runtimes are built to run distributed training and inference, leveraging frameworks like XGBoost, TensorFlow, and PyTorch, all pre-configured for GPU utilization. For example, for distributed training with XGBoost on Spark, you can leverage the pre-installed \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003exgboost.spark\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e library. By setting parameters such as \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003enum_workers\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to distribute the task across Spark executors and \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003edevice=”cuda”\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, you can effectively train your models on multiple GPUs, significantly speeding up the training process for large datasets. Here's an example of how to configure XGBoost classifier for distributed GPU training on your Spark cluster:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;from xgboost.spark import SparkXGBClassifier\\r\\nfrom pyspark.sql import SparkSession\\r\\n\\r\\n# Configure the XGBoost classifier for distributed GPU training\\r\\nxgb_classifier = SparkXGBClassifier(\\r\\n    featuresCol=\u0026quot;features\u0026quot;,\\r\\n    labelCol=\u0026quot;label\u0026quot;,\\r\\n    num_workers=spark.sparkContext.defaultParallelism,\\r\\n    device=\u0026quot;cuda\u0026quot;,  # Enable GPU training\\r\\n    # Other XGBoost parameters like max_depth etc.\\r\\n    max_depth=6  \\r\\n)\\r\\n\\r\\n# Train the model\\r\\nxgb_model = xgb_classifier.fit(train_df)\\r\\n\\r\\n# Model persistence and prediction\\r\\nxgb_model.save(\u0026quot;path/to/your/xgboost_spark_model\u0026quot;)\\r\\npredictions = xgb_model.transform(test_df)\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;lang-py\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be98e0\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eInteractive environment customization for Spark Connect\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWhen working interactively with Spark, such as in a Colab notebook using Spark Connect, ensuring Python library consistency between your client and the Spark cluster is crucial. Dataproc simplifies adding PyPI packages dynamically to a Spark session by extending the \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eaddArtifacts\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e method. You can now specify the list of packages to install/upgrade/downgrade in \u003c/span\u003e\u003ca href=\"https://packaging.python.org/en/latest/specifications/version-specifiers/#examples-of-compliant-version-schemes\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eversion-scheme\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e (same as \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003epip install\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e). This instructs the Spark Connect server to install the package and its dependencies, making them available to workers for your UDFs and other code. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;# Installs textdistance(specific version) and random2 (latest) library on the cluster. UDFs using textdistance and random2 can now run on worker nodes\\r\\n\\r\\nspark.addArtifacts(\u0026quot;textdistance==4.6.1\u0026quot;, \u0026quot;random2\u0026quot;, pypi=True)\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;lang-py\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be9940\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIn addition you can also customize your Spark environment on Dataproc with Init scripts and custom images.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eMLOps via Vertex AI\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDataproc works with Vertex AI, Google Cloud's unified platform for AI and ML, helping to improve\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e MLOps for your AI/ML workflows with Spark. Using the Vertex AI SDK directly within your Dataproc Spark code enables experiment tracking and model management, allowing you to:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eTrack experiments\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e: Track log parameters, metrics, and artifacts from your Dataproc Spark training jobs to Vertex AI Experiments. This allows you to compare runs, visualize results, and reproduce experiments reliably.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRegister models\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e: Once training is complete, register your trained models into the Vertex AI Model Registry. This provides a central repository for model versioning, staging, and governance, simplifying the path to deployment.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;# code snippet for Dataproc Spark on GCE. Some details ommited for brevity\\r\\n\\r\\n\\r\\nfrom google.cloud import aiplatform\\r\\n\\r\\n# --- Initialize Vertex AI SDK \u0026amp; Enable Autologging ---\\r\\naiplatform.init(project=PROJECT_ID, location=REGION, experiment=EXPERIMENT_NAME)\\r\\n\\r\\n# Start a run to log experiment metrics\\r\\naiplatform.start_run(run=RUN_NAME)\\r\\n\\r\\nxgb_spark_estimator = SparkXGBClassifier(\\r\\n    featuresCol=\u0026quot;features\u0026quot;,\\r\\n    labelCol=\u0026quot;label\u0026quot;     \\r\\n    # Add other XGBoost parameters needed for training\\r\\n    )\\r\\n\\r\\n# train model\\r\\ntrained_spark_model = xgb_spark_estimator.fit(train_df)\\r\\n\\r\\n# register model\\r\\n# 1. Get the underlying XGBoost model and save it\\r\\nnative_booster = trained_spark_model.get_booster()\\r\\nnative_booster.save_model(local_path)\\r\\n\\r\\n# Log relevant metrics manually in Vertex Experiments \\r\\nmetrics={parameter_name:parameter_value}\\r\\naiplatform.log_metrics(metrics)\\r\\n\\r\\n\\r\\n# 2. Upload to GCS\\r\\ndestination_gcs_object_name = f\u0026quot;{GCS_MODEL_ARTIFACT_DIR_NAME}/{MODEL_FILENAME}\u0026quot; \\r\\nstorage.Client(project=PROJECT_ID).bucket(GCS_BUCKET_NAME).blob(destination_gcs_object_name).upload_from_filename(local_path) \\r\\n\\r\\n# 3. Register to Vertex AI Model Registry\\r\\nPRE_BUILT_SERVING_CONTAINER_IMAGE_URI = \u0026quot;us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.2-1:latest\u0026quot;\\r\\n\\r\\nregistered_model = aiplatform.Model.upload(\\r\\n    display_name=MODEL_DISPLAY_NAME,\\r\\n    artifact_uri=GCS_ARTIFACT_DIRECTORY_URI,\\r\\n    serving_container_image_uri=PRE_BUILT_SERVING_CONTAINER_IMAGE_URI,\\r\\n    description=\u0026quot;Spark XGBoost model\u0026quot;,\\r\\n    sync=True # Wait for the model to be uploaded and registered\\r\\n)\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;lang-py\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be9b80\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis integration makes your AI/ML workloads on Spark more manageable, reproducible, and deployable, per your organization's wider MLOps strategy.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eDeploy to production\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eMove from interactive development to production easily.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWhen using BigQuery Colab notebooks for development, you get Git support to version-control your code and go through your CI/CD flow. You can also schedule your Spark notebook using BigQuery’s built-in \u003c/span\u003e\u003ca href=\"https://cloud.google.com/bigquery/docs/pipelines-introduction\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003epipeline feature\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, which allows you create single scheduled notebooks or more complicated DAGs, chaining multiple notebooks or queries. You can run these pipelines using the user account or a service account for production pipelines.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eBigQuery Pipelines let you compose your flow into discrete tasks, so you can mix Apache Spark on Dataproc and BigQuery execution. In the following BigQuery pipeline, the first task ingests raw data via a BigQuery query, then the data is transformed via Apache Spark via a notebook task. This notebook contains the pertinent Spark transform steps. Finally, the graph splits into two parallel tasks: a notebook that produces a report based on output of the previous task, and a final query that cleans up the initial ingested data.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_JnGyp0R.max-1000x1000.png\"\n        \n          alt=\"3\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWhen using an IDE you can achieve a similar flow by using the Git client of these IDEs to version your Spark code. You can also create and deploy pipelines using Cloud Composer, Google Cloud’s managed serverless Apache Airflow offering. You can run jobs on your existing Dataproc clusters, ephemeral job clusters, or on Serverless Batch.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;# Following code illustrates how to schedule serverless batch jobs with Cloud Composer (Airflow)\\r\\n\\r\\n\\r\\n# import statements and configurations statements omitted for brevity\\r\\n\\r\\n\\r\\n# Define the full job payload for DataprocCreateBatchOperator\\r\\nwith models.DAG(\\r\\n    \u0026quot;dataproc_batch_operators\u0026quot;,  # The id you will see in the DAG airflow page\\r\\n    default_args=default_args,  # The interval with which to schedule the DAG\\r\\n    schedule_interval=datetime.timedelta(days=1),  # Override to match your needs\\r\\n) as dag:\\r\\n    create_batch = DataprocCreateBatchOperator(\\r\\n        task_id=\u0026quot;batch_create\u0026quot;,\\r\\n        batch={\\r\\n            \u0026quot;pyspark_batch\u0026quot;: {\\r\\n                \u0026quot;main_python_file_uri\u0026quot;: PYTHON_FILE_LOCATION,\\r\\n                \u0026quot;jar_file_uris\u0026quot;: [SPARK_BIGQUERY_JAR_FILE],\\r\\n            },\\r\\n            \u0026quot;environment_config\u0026quot;: {\\r\\n                \u0026quot;peripherals_config\u0026quot;: {\\r\\n                    \u0026quot;spark_history_server_config\u0026quot;: {\\r\\n                        \u0026quot;dataproc_cluster\u0026quot;: PHS_CLUSTER_PATH,\\r\\n                    },\\r\\n                },\\r\\n            },\\r\\n        },\\r\\n        batch_id=\u0026quot;create-xgboost-batch\u0026quot;,\\r\\n    )\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;lang-py\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be9850\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAI/ML-ready Apache Spark\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWith \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDataproc, you can build your AI/ML workloads with Apache Spark more easily. By providing pre-configured ML Runtimes with GPU support, simplifying Python dependency management for interactive sessions via Spark Connect, enabling development from your preferred IDE, and offering seamless integration with Vertex AI for MLOps, Dataproc accelerates the entire ML lifecycle. Move from exploration and training to robust, production-ready Spark ML pipelines. Explore the \u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc/docs\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDataproc documentation\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e today to start leveraging these capabilities.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e"
    },
    {
      "title": "Tzafon selects Google Cloud to build next-generation agentic machine intelligence",
      "link": "https://cloud.google.com/blog/topics/startups/tzafon-builds-the-next-generation-of-agentic-machine-intelligence-with-google-cloud-infrastructure/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-07-17T13:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003ca href=\"https://www.tzafon.ai/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eTzafon\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, a San Francisco-based startup and AI R\u0026amp;D lab, is partnering with Google Cloud to utilize Google’s AI-optimized infrastructure and cloud services to help Tzafon deliver automation at large scale.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe Tzafon team aims to do this by building systems and models that can support multiple, autonomous AI agents that are capable of working together and interacting with common interfaces like applications, operating systems, and web browsers.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eNow, Tzafon will partner with Google Cloud to access the compute resources and cloud services it needs to train its new multi-agent models – and to develop new automation frameworks that will allow Tzafon’s agents to collaborate more quickly and seamlessly. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThrough its partnership with Google Cloud, Tzafon will:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eUse NVIDIA GPUs through Google Cloud to train new machine intelligence models capable of managing multiple AI agents.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDevelop individual agents capable of interacting with operating systems, web browsers, and applications on a person’s behalf.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eScale workloads up or down quickly using Google Kubernetes Engine.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eUse BigQuery to effectively manage the large volumes of data underpinning its systems.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eToday, more than 60% of the world’s generative AI startups are using Google Cloud. Now, Tzafon joins them in gaining access to Google Cloud’s complete AI stack, with reliable compute capacity, strong price performance, robust data infrastructure, and elasticity to scale quickly, among many other features that are essential in the emerging field of AI.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eYou can read more about Tzafon’s mission in its \u003c/span\u003e\u003ca href=\"https://www.tzafon.ai/blog/tzafon-whitepaper\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ewhite paper\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e and learn more about how thousands of AI startups are building with Google Cloud \u003c/span\u003e\u003ca href=\"https://cloud.google.com/startup?hl=en\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e"
    }
  ],
  "generatedAt": "2025-07-18T07:08:47.87320959+09:00"
}
