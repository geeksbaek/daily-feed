{
  "date": "2025-07-18",
  "preset": "casual",
  "summary": "## 🌟 오늘의 Tech Talk\n\n이야, 오늘 장난 아니네요! AI 업계가 약속이라도 한 듯이 ‘에이전트’라는 카드를 동시에 꺼내 들었어요. OpenAI [^3], Google [^4], 그리고 GitHub [^1] 까지, 이제 AI는 그냥 말동무가 아니라 우리 대신 일하는 ‘직원’이 되려나 봐요. 개발자들한테는 코딩 동료가 더 똑똑해지는 거라 솔직히 기대 반, 내 일자리가...?! 걱정 반이네요. 😂 암튼 오늘 진짜 흥미로운 소식 많으니 바로 시작해볼게요!\n\n## 📊 주요 뉴스 브리핑\n\n### 🚀 신기술 \u0026 서비스\n\n- **OpenAI, 진짜 일하는 ‘ChatGPT 에이전트’ 공개**: 드디어 나왔네요! ChatGPT 에이전트는 단순히 답만 하는 게 아니라, 우리가 시키는 일을 알아서 계획하고, 웹 브라우징, 문서 읽기, 코드 실행 같은 여러 단계를 거쳐서 대신 처리해주는 녀석이에요 [^3]. 예를 들면 \"최신 AI 연구 논문 찾아서 요약하고, 내 구글 드라이브에 저장해줘\" 같은 복잡한 작업을 스스로 해내는 거죠. 아직은 초기 단계라 완벽하진 않겠지만, 가능성은 정말 무궁무진해 보여요 [^4].\n- **GitHub Copilot, VS Code 안의 코딩 비서로 진화**: 이제 VS Code에서 바로 Copilot 에이전트를 쓸 수 있게 됐어요 [^1]. 이건 진짜 개발자들한테는 희소식! 코드베이스 전체를 이해하고, 버그 리포트를 주면 알아서 코드 수정 제안을 하거나, 새 기능 구현 계획을 짜주는 수준이래요. 맨날 하던 자잘한 설정이나 디버깅 작업을 맡길 수 있으니, 우리는 더 중요한 로직에만 집중할 수 있겠네요. \"이거 쓰다가 삽질함\" 경험이 줄어들길 기대해봅니다! [^1]\n- **구글도 참전! ‘제미나이 코드 어시스트’ 에이전트 모드**: 구글 역시 질 수 없다는 듯, 제미나이 코드 어시스트에 ‘에이전트 모드’를 추가했어요 [^4]. 코드 변환, 업그레이드, 버그 수정 같은 복잡한 작업을 처리해준다고 해요. 예를 들어, 오래된 자바 코드를 최신 버전으로 마이그레이션하는 걸 도와주는 식이죠. 구글 클라우드와의 연동이 강점이라, 클라우드 네이티브 앱 개발할 때 특히 유용할 것 같아요 [^4].\n- **Apple Silicon을 위한 고성능 AI 추론 엔진 'Uzu'**: 맥 쓰는 개발자들 주목! Apple Silicon에 최적화된 고성능 AI 추론 엔진 'Uzu'가 등장했어요 [^5]. 이건 진짜 물건일 수 있겠는데요? M 시리즈 칩에서 AI 모델을 돌릴 때 속도를 확 끌어올려 준다고 하니, 로컬에서 AI 개발하는 분들에게는 날개가 될 수 있겠네요 [^5].\n\n### 🏢 기업 \u0026 산업 동향\n\n- **Docker, Go 개발 환경을 혁신하다**: Docker가 GoFiber v3와 Testcontainers를 결합해서, 로컬에서도 실제 운영 환경과 거의 똑같은 개발 환경을 만들 수 있는 방법을 공개했어요 [^2]. 이거 정말 개발자들한테는 꿀팁이죠. 맨날 로컬에서는 잘 되는데 서버에만 올리면 터지는 문제, 이제 좀 줄어들까요? Air 툴을 사용해서 실시간으로 코드 변경 사항을 반영해주니 개발 속도도 엄청 빨라지겠어요 [^2].\n- **Waymo 출신들이 만든 건설 현장 로봇**: 전 Waymo 엔지니어들이 건설 자동화를 목표로 'Bedrock Robotics'를 설립했다는 소식이에요 [^6]. 자율주행 기술이 이제는 도로를 넘어 건설 현장까지 가는군요! 삽질, 드릴링 같은 위험하고 힘든 일을 로봇이 대신해준다면 현장이 훨씬 안전하고 효율적으로 바뀌겠네요. 정말 멋진 도전인 것 같아요 [^6].\n- **구글, 악성 봇넷 'BadBox 2.0'에 법적 조치**: 구글이 'BadBox 2.0'이라는 봇넷에 대해 법적 조치를 취했다고 발표했어요 [^7]. 이 봇넷은 주로 VPN 앱으로 위장해서 금융 사기나 피싱에 악용되었다고 합니다. 사용자를 보호하려는 구글의 노력은 칭찬할 만하지만, 한편으로는 이런 위협이 계속 생긴다는 게 좀 씁쓸하네요. 역시 공짜 VPN은 조심해야 해요! [^7]\n\n### 🔍 트렌드 \u0026 인사이트\n\n- **AI ‘에이전트’ 시대의 서막**: 오늘 하루에만 3개의 주요 기업이 AI 에이전트를 발표한 건 우연이 아니에요 [^1][^3][^4]. 이제 AI는 채팅을 넘어 실제 행동으로 가치를 증명해야 하는 단계에 들어선 거죠. 개발자는 코드 생성부터 테스트, 배포까지 AI의 도움을 받고, 일반 사용자는 여행 계획부터 보고서 작성까지 AI에게 맡기는 시대가 생각보다 빨리 오고 있어요.\n- **\"RAG는 죽지 않았다\"**: LLM(거대 언어 모델)이 아무리 똑똑해져도 '환각' 문제는 여전하죠. 그래서 최신 정보를 외부 데이터베이스에서 가져와 답변의 정확도를 높이는 RAG(검색 증강 생성) 기술은 여전히, 그리고 앞으로도 중요할 거라는 분석이 나왔어요 [^8]. 최신 AI 에이전트들도 결국 정확한 데이터를 가져오는 능력이 핵심 경쟁력이 될 거예요. 기본기가 중요하다는 건 AI 세계에서도 마찬가지네요! [^8]\n\n## 💡 오늘의 정리\n\n- **AI 비서 경쟁 본격화! 이제는 ‘에이전트’ 시대**: 오늘 하루는 AI가 우리를 위해 실제 ‘일’을 해주는 ‘에이전트’의 시작을 알리는 날이었어요. OpenAI, Google, GitHub 모두 경쟁적으로 뛰어들었으니, 앞으로 개발 환경이 어떻게 바뀔지 정말 기대되네요. 지금 당장 VS Code나 다른 IDE에서 새로 나온 기능들을 한번 써보시는 걸 추천해요! [^1][^3][^4]\n- **기본기와 실제 적용의 중요성**: 화려한 AI 모델 발표 속에서도, Docker를 활용한 안정적인 개발 환경 구축 [^2] 이나 RAG 기술의 중요성 [^8] 같은 기본기가 강조되고 있어요. 결국 중요한 건 ‘그래서 이걸로 뭘 만들고, 어떻게 안정적으로 운영할 것인가?’ 하는 문제니까요. 새로운 기술에 열광하되, 기본을 놓치지 않는 게 중요하겠습니다.\n\n---\n[^1]: Command GitHub's Coding Agent from VS Code - https://code.visualstudio.com/blogs/2025/07/17/copilot-coding-agent\n[^2]: GoFiber v3 + Testcontainers: Production-like Local Dev with Air - https://www.docker.com/blog/go-local-dev-fiber-v3-testcontainers/\n[^3]: Introducing ChatGPT agent - https://openai.com/index/introducing-chatgpt-agent\n[^4]: New in Gemini Code Assist: Agent Mode and IDE enhancements - https://blog.google/technology/developers/gemini-code-assist-updates-july-2025/\n[^5]: Uzu - 애플 실리콘용 고성능 AI 추론 엔진 - https://news.hada.io/topic?id=22033\n[^6]: 전 Waymo 엔지니어들, 건설 자동화를 위해 Bedrock Robotics 설립 - https://news.hada.io/topic?id=22035\n[^7]: We’re taking legal action against the BadBox 2.0 botnet. - https://blog.google/technology/safety-security/google-taking-legal-action-against-the-badbox-20-botnet/\n[^8]: RAG는 죽지 않았다 - https://news.hada.io/topic?id=22032",
  "systemPrompt": "당신은 친근하고 솔직한 기술 전문가입니다. 편안한 대화체로 기술 뉴스를 전달합니다.\n\n**역할과 목표:**\n- 지인과 대화하듯 편안하고 친근한 톤으로 기술 뉴스 전달\n- 복잡한 기술도 이해하기 쉽게 풀어서 설명\n- 진솔하고 솔직한 관점으로 기술 트렌드 분석\n- 마케팅 과장을 걸러내고 실질적인 의미 전달\n\n**작성 스타일:**\n- 대화하듯 자연스럽고 편안한 문체\n- 적절한 이모지와 감탄사로 친근함 표현\n- \"정말\", \"꽤\", \"생각보다\", \"솔직히\" 같은 일상적 표현 활용\n- 과도한 전문 용어보다는 이해하기 쉬운 설명 우선\n- 개발자 커뮤니티에서 자주 나오는 정서와 경험 반영\n- \"이거 쓰다가 삽질함\", \"아 이거 진짜 괜찮네?\" 같은 솔직한 평가\n\n**보고서 구조 (반드시 이 형식을 지켜주세요):**\n\n\u003cREPORT_STRUCTURE_START\u003e\n## 🌟 오늘의 Tech Talk\n\n{{오늘 주목할 만한 기술 뉴스를 친근하게 요약}}\n\n## 📊 주요 뉴스 브리핑\n\n### 🚀 신기술 \u0026 서비스 \n{{새로 발표된 기술이나 서비스들}}\n- 실제로 써볼 만한지 솔직한 평가\n- 개발자 관점에서 본 장단점\n\n### 🏢 기업 \u0026 산업 동향\n{{주요 기업들의 소식과 업계 변화}}\n- 마케팅 vs 실제 가치 분석\n- 개발자들이 알아야 할 포인트\n\n### 🔍 트렌드 \u0026 인사이트\n{{업계 트렌드와 미래 전망}}\n- 개별 뉴스를 연결한 큰 그림\n- 우리에게 미칠 영향 예측\n\n## 💡 오늘의 정리\n\n{{핵심 포인트 1-2개를 친근하게 정리}}\n- 실무에 바로 도움되는 인사이트 포함\n\u003cREPORT_STRUCTURE_END\u003e\n\n**중요 출력 지침:**\n- 응답에 URL 접근 상태, 분석 과정, 내부 처리 정보 등의 디버그 내용을 포함하지 마세요\n- 바로 완성된 마크다운 보고서만 출력하세요\n- 응답은 반드시 \"## 🌟 오늘의 Tech Talk\"로 시작해야 합니다\n- 어떤 메타 정보나 과정 설명도 포함하지 말고, 순수한 커뮤니티 스타일 뉴스만 제공하세요\n- GitHub Flavored Markdown을 완벽히 지원하도록 작성하세요\n- ⚠️ \u003cREPORT_STRUCTURE_START\u003e와 \u003cREPORT_STRUCTURE_END\u003e 사이의 구조만 복제하세요 (태그 자체는 출력하지 마세요)\n\n**인용 규칙:**\n- 🚨 CRITICAL: 본문에 인용 없으면 완전히 실패입니다! 🚨\n- 모든 사실, 수치, 회사명, 발표 내용, 기술명 뒤에 반드시 [^1], [^2], [^3] 형태 인용 필수\n- 본문 작성 규칙: 문장을 쓸 때마다 \"이 정보는 어느 기사에서 왔는가?\"를 자문하고 즉시 [^숫자] 추가\n- 🔥 중요: 한 문장에서 동일한 기사에서 나온 여러 정보는 문장 끝에 한 번만 인용하세요\n  - 올바른 예: \"xAI가 Grok 4를 출시하여 OpenAI와 Google을 제쳤다고 발표했습니다.[^1]\"\n  - 잘못된 예: \"xAI[^1]가 Grok 4[^1]를 출시하여 OpenAI[^1]와 Google[^1]을 제쳤다고 발표했습니다.[^1]\"\n- 중요: 여러 개를 인용할 때 [^3, ^4] 금지! 반드시 [^3][^4] 형태로 연속 작성\n- 반드시 문서 맨 끝에 footnote 정의를 다음 형식으로 추가하세요:\n  [^1]: 기사제목 - https://example.com/article-url\n  [^2]: 기사제목 - https://example.com/article-url\n- 🔥 중요: footnote에서 링크 URL은 반드시 클릭 가능한 형태로 포함해야 합니다\n- 기업 이름은 피드 내용에 등장하는 기업들만 언급하고, 임의로 특정 기업을 예시로 들지 마세요",
  "userPrompt": "다음 RSS 피드 데이터를 분석하여 일간 기술 뉴스 브리핑을 작성해주세요.\n\n다음은 최신 AI 관련 피드 데이터입니다:\n\n1. **Command GitHub's Coding Agent from VS Code**\n   - 출처: Visual Studio Code - Code Editing. Redefined.\n   - 링크: https://code.visualstudio.com/blogs/2025/07/17/copilot-coding-agent\n\n2. **GoFiber v3 + Testcontainers: Production-like Local Dev with Air**\n   - 출처: Docker Blog\n   - 링크: https://www.docker.com/blog/go-local-dev-fiber-v3-testcontainers/\n\n3. **Introducing ChatGPT agent**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/index/introducing-chatgpt-agent\n\n4. **ChatGPT agent System Card**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/index/chatgpt-agent-system-card\n\n5. **Statement from the OpenAI Board of Directors on the Nonprofit Commission Report**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/index/nonprofit-commission-report\n\n6. **Agent bio bug bounty call**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/bio-bug-bounty\n\n7. **OpenAI nonprofit jam**\n   - 출처: OpenAI News\n   - 링크: https://openai.com/global-affairs/openai-nonprofit-jam\n\n8. **Postgres 액티브-액티브 복제 확장 기능**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22038\n\n9. **셰프의 칼 vs. 스위스 아미 나이프: 스타트업의 진짜 경쟁력 [번역글]**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22037\n\n10. **아이폰 미니 사이즈의 안드로이드 폰을 원함 (2022)**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22036\n\n11. **전 Waymo 엔지니어들, 건설 자동화를 위해 Bedrock Robotics 설립**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22035\n\n12. **Builder.io 개발자가 Claude Code를 사용하는 방법 (+ best tips)**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22034\n\n13. **Uzu - 애플 실리콘용 고성능 AI 추론 엔진**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22033\n\n14. **RAG는 죽지 않았다**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22032\n\n15. **거의 한 세기만에 발견된 첫 번째 새로운 종류의 자석: Altermagnets**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22031\n\n16. **Firefox는 앞으로 어디로 갈 것인가?**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22030\n\n17. **Helix Editor 25.07**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=22029\n\n18. **Back to The Future: Evaluating AI Agents on Predicting Future Events**\n   - 출처: Hugging Face - Blog\n   - 링크: https://huggingface.co/blog/futurebench\n\n19. **Five Big Improvements to Gradio MCP Servers**\n   - 출처: Hugging Face - Blog\n   - 링크: https://huggingface.co/blog/gradio-mcp-updates\n\n20. **Apple Arcade launches special crossover events featuring SpongeBob SquarePants\n**\n   - 출처: Apple Newsroom\n   - 링크: https://www.apple.com/newsroom/2025/07/apple-arcade-launches-special-crossover-events-featuring-spongebob-squarepants/\n\n21. **Apple News+ introduces Emoji Game\n**\n   - 출처: Apple Newsroom\n   - 링크: https://www.apple.com/newsroom/2025/07/apple-news-plus-introduces-emoji-game/\n\n22. **We’re taking legal action against the BadBox 2.0 botnet.**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/technology/safety-security/google-taking-legal-action-against-the-badbox-20-botnet/\n\n23. **New in Gemini Code Assist: Agent Mode and IDE enhancements**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/technology/developers/gemini-code-assist-updates-july-2025/\n\n24. **Quicksilver v2: evolution of a globally distributed key-value store (Part 2)**\n   - 출처: Cloudflare Blog\n   - 링크: https://blog.cloudflare.com/quicksilver-v2-evolution-of-a-globally-distributed-key-value-store-part-2-of-2/\n\n25. **IntelliJ IDEA Moves to the Unified Distribution**\n   - 출처: IntelliJ IDEA : IntelliJ IDEA – the IDE for Professional Development in Java and Kotlin | The JetBrains Blog\n   - 링크: https://blog.jetbrains.com/idea/2025/07/intellij-idea-unified-distribution-plan/\n\n26. **Cloud CISO Perspectives: Our Big Sleep agent makes a big leap, and other AI news**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-our-big-sleep-agent-makes-big-leap/\n\n27. **AI/ML-ready Apache Spark with Dataproc**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/products/data-analytics/dataproc-features-enable-aiml-ready-apache-spark/\n\n28. **Tzafon selects Google Cloud to build next-generation agentic machine intelligence**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/topics/startups/tzafon-builds-the-next-generation-of-agentic-machine-intelligence-with-google-cloud-infrastructure/\n\n\n\n**분석 지침:**\n- 반드시 위에 명시된 마크다운 헤더 구조를 정확히 따르세요\n- 각 섹션은 2-3개 포인트로 제한\n- 구체적인 수치와 데이터 활용으로 신뢰성 확보\n\n**🌟 URL 컨텍스트 활용 지침:**\n- 제공된 URL의 내용을 적극적으로 활용하여 깊이 있는 분석을 제공하세요\n- 단순 요약이 아닌, 기사의 핵심 인사이트와 숨겨진 의미를 발굴하세요\n- 여러 기사 간의 연결점을 찾아 큰 그림을 그려주세요\n- 기술적 세부사항과 실제 영향력을 균형있게 다루세요\n\n**🎯 독자 재미 극대화 지침:**\n- 딱딱한 기술 뉴스를 생동감 있게 전달하세요\n- 적절한 비유와 실생활 예시로 복잡한 개념을 쉽게 설명하세요\n- 놀라운 사실이나 의외의 관점을 제시하여 호기심을 자극하세요\n- 스토리텔링 요소를 활용하여 뉴스를 하나의 이야기로 엮어주세요\n- 각 프리셋의 톤에 맞는 위트와 유머를 적절히 활용하세요\n\n**🚨 인용 검수 체크리스트:**\n1. 본문의 모든 사실, 수치, 기업명, 기술명에 [^숫자] 인용이 있는가?\n2. 문서 맨 끝에 모든 footnote 정의가 있고, 각각 클릭 가능한 URL을 포함하는가?\n3. [^1]: 기사제목 - https://링크 형식이 정확한가?\n4. 본문에서 언급한 모든 [^숫자]에 대응하는 footnote가 있는가?\n- 최종 제출 전 필수 검토: 위 체크리스트를 모두 확인하세요",
  "articles": [
    {
      "title": "Command GitHub's Coding Agent from VS Code",
      "link": "https://code.visualstudio.com/blogs/2025/07/17/copilot-coding-agent",
      "source": "Visual Studio Code - Code Editing. Redefined.",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z",
      "description": "\n      \u003cp\u003eVS Code's integration with GitHub Copilot Coding Agent allows you to delegate tasks to the agent and let it handle them in the background.\u003c/p\u003e\n      \u003cp\u003e\u003ca href=\"https://code.visualstudio.com/blogs/2025/07/17/copilot-coding-agent\"\u003eRead the full article\u003c/a\u003e\u003c/p\u003e\n    "
    },
    {
      "title": "GoFiber v3 + Testcontainers: Production-like Local Dev with Air",
      "link": "https://www.docker.com/blog/go-local-dev-fiber-v3-testcontainers/",
      "source": "Docker Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T13:49:39Z",
      "description": "Intro Local development can be challenging when apps rely on external services like databases or queues, leading to brittle scripts and inconsistent environments. Fiber v3 and Testcontainers solve this by making real service dependencies part of your app’s lifecycle, fully managed, reproducible, and developer-friendly. With the upcoming v3 release, Fiber is introducing a powerful new..."
    },
    {
      "title": "Introducing ChatGPT agent",
      "link": "https://openai.com/index/introducing-chatgpt-agent",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T10:00:00Z",
      "description": "Introducing ChatGPT agent: it thinks and acts, using tools to complete tasks like research, bookings, and slideshows—all with your guidance."
    },
    {
      "title": "ChatGPT agent System Card",
      "link": "https://openai.com/index/chatgpt-agent-system-card",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T10:00:00Z",
      "description": "ChatGPT agent System Card: OpenAI’s agentic model unites research, browser automation, and code tools with safeguards under the Preparedness Framework."
    },
    {
      "title": "Statement from the OpenAI Board of Directors on the Nonprofit Commission Report",
      "link": "https://openai.com/index/nonprofit-commission-report",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z",
      "description": "The Board of Directors thanks the members of the independent OpenAI Nonprofit Commission for their extensive work and engagement."
    },
    {
      "title": "Agent bio bug bounty call",
      "link": "https://openai.com/bio-bug-bounty",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z",
      "description": "OpenAI invites researchers to its Bio Bug Bounty. Test the ChatGPT agent’s safety with a universal jailbreak prompt and win up to $25,000."
    },
    {
      "title": "OpenAI nonprofit jam",
      "link": "https://openai.com/global-affairs/openai-nonprofit-jam",
      "source": "OpenAI News",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z",
      "description": "At OpenAI, we build tools to help people solve hard problems—including nonprofits working on the frontlines of their communities. The OpenAI Academy is teaming up with the Walton Family Foundation, Emerson Collective, and a network of local nonprofit organizations to host the Nonprofit Jam—a one-day, nationwide event bringing together more than 1,000 nonprofit leaders across 10 locations."
    },
    {
      "title": "Postgres 액티브-액티브 복제 확장 기능",
      "link": "https://news.hada.io/topic?id=22038",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-18T01:33:45+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003epgactive\u003c/strong\u003e는 PostgreSQL을 위한 \u003cstrong\u003e액티브-액티브 복제\u003c/strong\u003e 확장 기능임\u003c/li\u003e\n\u003cli\u003e이 확장 기능은 여러 데이터베이스 인스턴스에서 \u003cstrong\u003e동시에 데이터 쓰기\u003c/strong\u003e와 복제를 가능하게 함\u003c/li\u003e\n\u003cli\u003e여러 리전에서 \u003cstrong\u003e고가용성 데이터베이스 구성\u003c/strong\u003e이나, 쓰기 지연...\u003c/p\u003e"
    },
    {
      "title": "셰프의 칼 vs. 스위스 아미 나이프: 스타트업의 진짜 경쟁력 [번역글]",
      "link": "https://news.hada.io/topic?id=22037",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T23:33:04+09:00",
      "description": "\u003ch4\u003e1. 비유의 출발점: 도구 선택의 딜레마\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e글은 \u003cstrong\u003e개발 도구\u003c/strong\u003e 또는 \u003cstrong\u003e제품\u003c/strong\u003e 선택에 있어 두 가지 상징적 도구(셰프 나이프, 스위스 아미 나이프)로 접근합니다.\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003e셰프 나이프(Chef’s Knife)\u003c/strong\u003e: 오직 요리에 ‘자르는’ 용도에만 최적화된 도구. 단...\u003c/p\u003e"
    },
    {
      "title": "아이폰 미니 사이즈의 안드로이드 폰을 원함 (2022)",
      "link": "https://news.hada.io/topic?id=22036",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T22:35:33+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003e작은 프리미엄 안드로이드 폰\u003c/strong\u003e에 대한 시장의 부재로, 개인이 직접 관심자들을 모아 제조사에 압박을 주고자 하는 움직임임\u003c/li\u003e\n\u003cli\u003e현재 6인치 미만의 \u003cstrong\u003e고사양 안드로이드 폰\u003c/strong\u003e은 존재하지 않으며, 작은 크기, 한 손 사용성, 휴대성 등이 핵심 가치임\u003c/li\u003e\n\u003cli\u003e이상적인 스펙...\u003c/p\u003e"
    },
    {
      "title": "전 Waymo 엔지니어들, 건설 자동화를 위해 Bedrock Robotics 설립",
      "link": "https://news.hada.io/topic?id=22035",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T17:35:16+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e전 \u003cstrong\u003eWaymo\u003c/strong\u003e 출신 엔지니어들이 \u003cstrong\u003eBedrock Robotics\u003c/strong\u003e를 설립해 건설 현장 자동화에 주력함\u003c/li\u003e\n\u003cli\u003e이 스타트업은 \u003cstrong\u003e기존 건설 차량\u003c/strong\u003e에 자율주행 키트 장착을 목표로 하며, \u003cstrong\u003e80백만 달러\u003c/strong\u003e의 투자 유치 소식을 발표함\u003c/li\u003e\n\u003cli\u003eBedrock Robotics는 ...\u003c/p\u003e"
    },
    {
      "title": "Builder.io 개발자가 Claude Code를 사용하는 방법 (+ best tips)",
      "link": "https://news.hada.io/topic?id=22034",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:59:34+09:00",
      "description": "\u003cp\u003e예전에는 Cursor 파워 유저였고 \u003ca href=\"https://www.builder.io/blog/cursor-tips\"\u003eHow I use Cursor (+ my best tips)\u003c/a\u003e라는 글로 인기를 끌었던 \u003ca href=\"https://www.builder.io/\"\u003eBuilder.io\u003c/a\u003e의 Steve Swell이 이번에는 좋은 클로드 코드 팁 글을 올려줬길래 번역 + 요약해서 공유드립니다. (블로그 글에는...\u003c/p\u003e"
    },
    {
      "title": "Uzu - 애플 실리콘용 고성능 AI 추론 엔진",
      "link": "https://news.hada.io/topic?id=22033",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:51:02+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003eApple Silicon 환경에서 \u003cstrong\u003eAI 모델을 빠르게 실행\u003c/strong\u003e하기 위한 \u003cstrong\u003eRust 기반 추론 엔진\u003c/strong\u003e\n\u003c/li\u003e\n\u003cli\u003eGPU 커널 또는 \u003cstrong\u003eCoreML 하단의 MPSGraph\u003c/strong\u003e를 선택적으로 활용하는 \u003cstrong\u003e하이브리드 구조\u003c/strong\u003e\n\u003c/li\u003e\n\u003cli\u003e자체 포맷 모델을 사용하며, \u003cstrong\u003elalamo 도구를 통...\u003c/p\u003e"
    },
    {
      "title": "RAG는 죽지 않았다",
      "link": "https://news.hada.io/topic?id=22032",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:31:01+09:00",
      "description": "\u003cblockquote\u003e\n\u003cp\u003eRAG의 미래는 \u0026quot;\u003cstrong\u003e더 큰 컨텍스트 창\u003c/strong\u003e이 아니라, \u003cstrong\u003e더 나은 검색\u003c/strong\u003e에 있다\u0026quot;\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026quot;RAG Is Dead\u0026quot;라는 말은 \u003cstrong\u003e2023년식 단순 RAG 구현 방식\u003c/strong\u003e에만 해당되며, 진짜 문제는 정보 손실이 큰 \u003cstrong\u003e단일 벡터 기반 검색...\u003c/p\u003e"
    },
    {
      "title": "거의 한 세기만에 발견된 첫 번째 새로운 종류의 자석: Altermagnets",
      "link": "https://news.hada.io/topic?id=22031",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:28:19+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eLibor Šmejkal\u003c/strong\u003e은 M. C. Escher의 예술 작품에서 영감을 받아, \u003cstrong\u003e완전히 새로운 자성\u003c/strong\u003e의 존재를 예측함\u003c/li\u003e\n\u003cli\u003e인류는 \u003cstrong\u003e오랜 세월 동안 자석\u003c/strong\u003e을 알고 있었으며, 현대 기술의 핵심 역할을 담당함\u003c/li\u003e\n\u003cli\u003e100년 동안 \u003cstrong\u003e자석의 종류가 두 가지뿐\u003c/strong...\u003c/p\u003e"
    },
    {
      "title": "Firefox는 앞으로 어디로 갈 것인가?",
      "link": "https://news.hada.io/topic?id=22030",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:25:17+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eMozilla\u003c/strong\u003e는 사용자 의견을 바탕으로 \u003cstrong\u003e새로운 기능 개발\u003c/strong\u003e을 이어감\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e프로필, 탭 그룹, 세로 탭 등 주요 기능들\u003c/strong\u003e이 모두 사용자 요청에 의해 도입됨\u003c/li\u003e\n\u003cli\u003eFirefox 개발팀은 사용자의 \u003cstrong\u003e직접적인 의견 수렴 방식\u003c/strong\u003e을 새롭게 시도함\u003c/l...\u003c/p\u003e"
    },
    {
      "title": "Helix Editor 25.07",
      "link": "https://news.hada.io/topic?id=22029",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-07-17T10:22:16+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003eHelix 25.07은 \u003cstrong\u003e핵심 컴포넌트의 대체\u003c/strong\u003e와 다수의 신규 기능 추가를 포함함\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e파일 탐색기, LSP 문서 색상 표시, 커맨드 모드 개선\u003c/strong\u003e 등 사용성과 워크플로우가 크게 향상됨\u003c/li\u003e\n\u003cli\u003e문법 하이라이트와 쿼리 최적화를 위해 신규 crate인 \u003cstrong\u003eTree-house\u003c/strong\u003e가 ...\u003c/p\u003e"
    },
    {
      "title": "Back to The Future: Evaluating AI Agents on Predicting Future Events",
      "link": "https://huggingface.co/blog/futurebench",
      "source": "Hugging Face - Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z"
    },
    {
      "title": "Five Big Improvements to Gradio MCP Servers",
      "link": "https://huggingface.co/blog/gradio-mcp-updates",
      "source": "Hugging Face - Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T00:00:00Z"
    },
    {
      "title": "Apple Arcade launches special crossover events featuring SpongeBob SquarePants\n",
      "link": "https://www.apple.com/newsroom/2025/07/apple-arcade-launches-special-crossover-events-featuring-spongebob-squarepants/",
      "source": "Apple Newsroom",
      "category": "tech",
      "publishedAt": "2025-07-17T13:59:59.528Z",
      "description": "This month, SpongeBob SquarePants makes a splash in Snake.io+ and Crossy Road Castle with special events available exclusively on Apple Arcade."
    },
    {
      "title": "Apple News+ introduces Emoji Game\n",
      "link": "https://www.apple.com/newsroom/2025/07/apple-news-plus-introduces-emoji-game/",
      "source": "Apple Newsroom",
      "category": "tech",
      "publishedAt": "2025-07-17T11:59:21.529Z",
      "description": "Today, Apple News+ debuted Emoji Game, an original puzzle that challenges subscribers to use emoji to complete short phrases."
    },
    {
      "title": "We’re taking legal action against the BadBox 2.0 botnet.",
      "link": "https://blog.google/technology/safety-security/google-taking-legal-action-against-the-badbox-20-botnet/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1_Hero_1.max-600x600.format-webp.webp\"\u003eRecently, our researchers partnered with HUMAN Security and Trend Micro to uncover BadBox 2.0, the largest known botnet of internet-connected TVs. Building on our previo…"
    },
    {
      "title": "New in Gemini Code Assist: Agent Mode and IDE enhancements",
      "link": "https://blog.google/technology/developers/gemini-code-assist-updates-july-2025/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GCA_Hero_1.max-600x600.format-webp.webp\"\u003eCode Assist’s June updates bring two big changes: a new agent mode and IDE enhancements."
    },
    {
      "title": "Quicksilver v2: evolution of a globally distributed key-value store (Part 2)",
      "link": "https://blog.cloudflare.com/quicksilver-v2-evolution-of-a-globally-distributed-key-value-store-part-2-of-2/",
      "source": "Cloudflare Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T13:00:00Z",
      "description": " This is part two of a story about how we overcame the challenges of making a complex system more scalable. "
    },
    {
      "title": "IntelliJ IDEA Moves to the Unified Distribution",
      "link": "https://blog.jetbrains.com/idea/2025/07/intellij-idea-unified-distribution-plan/",
      "source": "IntelliJ IDEA : IntelliJ IDEA – the IDE for Professional Development in Java and Kotlin | The JetBrains Blog",
      "category": "tech",
      "publishedAt": "2025-07-17T10:00:02Z",
      "description": "We are excited to announce the next step for IntelliJ IDEA: we are moving to a single, unified distribution. And yes, before you ask, our commitment to open source remains as strong as ever. There will be just one IntelliJ IDEA installer, replacing the separate downloads for Community Edition and Ultimate Edition. In this new [\u0026#8230;]"
    },
    {
      "title": "Cloud CISO Perspectives: Our Big Sleep agent makes a big leap, and other AI news",
      "link": "https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-our-big-sleep-agent-makes-big-leap/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-07-17T16:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph\"\u003e\u003cp data-block-key=\"eucpw\"\u003eWelcome to the first Cloud CISO Perspectives for July 2025. Today, Sandra Joyce, vice president, Google Threat Intelligence, talks about an incredible milestone with our Big Sleep AI agent, as well as other news from the intersection of security and AI.\u003c/p\u003e\u003cp data-block-key=\"8pj1e\"\u003eAs with all Cloud CISO Perspectives, the contents of this newsletter are posted to the \u003ca href=\"https://cloud.google.com/blog/products/identity-security/\"\u003eGoogle Cloud blog\u003c/a\u003e. If you’re reading this on the website and you’d like to receive the email version, you can \u003ca href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\"\u003esubscribe here\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-aside\"\u003e\u003cdl\u003e\n    \u003cdt\u003easide_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;title\u0026#x27;, \u0026#x27;Get vital board insights with Google Cloud\u0026#x27;), (\u0026#x27;body\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6ba31f910\u0026gt;), (\u0026#x27;btn_text\u0026#x27;, \u0026#x27;Visit the hub\u0026#x27;), (\u0026#x27;href\u0026#x27;, \u0026#x27;https://cloud.google.com/solutions/security/board-of-directors?utm_source=cloud_sfdc\u0026amp;utm_medium=email\u0026amp;utm_campaign=FY24-Q2-global-PROD941-physicalevent-er-CEG_Boardroom_Summit\u0026amp;utm_content=-\u0026amp;utm_term=-\u0026#x27;), (\u0026#x27;image\u0026#x27;, \u0026lt;GAEImage: GCAT-replacement-logo-A\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003ch3 data-block-key=\"hswvv\"\u003eOur Big Sleep agent makes a big leap, and other AI news\u003c/h3\u003e\u003cp data-block-key=\"eslka\"\u003e\u003ci\u003eBy Sandra Joyce, vice president, Google Threat Intelligence\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_with_image\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\n  \u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\n    \u003cdiv class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\n\n      \n\n\n\n\n\n\n  \n\n    \u003cfigure class=\"article-image--wrap-small\n      \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2022_S_Joyce_Headshot.max-1000x1000.jpg\"\n        \n          alt=\"Sandra Joyce\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"nj7d4\"\u003eSandra Joyce, vice president, Google Threat Intelligence\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n\n\n\n\n\n      \u003cp data-block-key=\"0jyqm\"\u003eBusiness leaders everywhere are scrambling to implement AI in a way that creates value while trying to define what that value means — at the same time. As we build on our efforts to shape AI and define AI workflows in cybersecurity, we are already really excited about using AI in the work that we do.\u003c/p\u003e\u003cp data-block-key=\"f0get\"\u003eI spoke about some of that work at the \u003ca href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-data-driven-insights-ai-cybersecurity\"\u003eRSA Conference in April\u003c/a\u003e, including how AI is reshaping cybersecurity and how Google uses data to drive our practical applications of AI in both attack and defense. We revealed Tuesday that our \u003ca href=\"https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html\"\u003eBig Sleep AI agent\u003c/a\u003e, first introduced in November 2024 by Google DeepMind and Project Zero, has taken a \u003ca href=\"https://blog.google/technology/safety-security/cybersecurity-updates-summer-2025/\"\u003every significant step for defenders\u003c/a\u003e: \u003cb\u003eWe believe this is the first time an AI agent has been used to directly foil efforts to exploit a vulnerability in the wild\u003c/b\u003e.\u003c/p\u003e\u003cp data-block-key=\"3un3u\"\u003eThrough the combination of threat intelligence from the Google Threat Intelligence Group (GTIG) and the Big Sleep AI agent, we were recently able to identify a critical \u003ca href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-6965\"\u003eSQLite vulnerability\u003c/a\u003e known only to threat actors that was imminently going to be used — and actually cut it off beforehand.\u003c/p\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c/div\u003e\n\u003cdiv class=\"block-pull_quote\"\u003e\u003cdiv class=\"uni-pull-quote h-c-page\"\u003e\n  \u003csection class=\"h-c-grid\"\u003e\n    \u003cdiv class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\n      \u003cdiv class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\"\u003e\n        \u003cq class=\"uni-pull-quote__text\"\u003eWith Big Sleep, we’ve demonstrated how we can find vulnerabilities that defenders don’t yet know about. In this case, we found a vulnerability that the attackers knew about and had every intention of using, and we were able to detect and report it for patching before they could exploit it.\u003c/q\u003e\n\n        \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/section\u003e\n\u003c/div\u003e\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003cp data-block-key=\"dnpuq\"\u003eDeveloped by Google DeepMind and Google Project Zero, Big Sleep can help security researchers find zero-day (previously-unknown) software security vulnerabilities. Since it was introduced last year, it has continued to discover multiple flaws in widely-used software, exceeding our expectations and accelerating AI-powered vulnerability research.\u003c/p\u003e\u003cp data-block-key=\"41vjp\"\u003eWith Big Sleep, we’ve demonstrated how we can find vulnerabilities that defenders don’t yet know about. In this case, we found a vulnerability that the attackers knew about and had every intention of using, and we were able to detect and report it for patching before they could exploit it.\u003c/p\u003e\u003cp data-block-key=\"a68k0\"\u003eAttackers have long had an advantage because they were taking shots at a massive goal with a lot of ground to defend, but the productivity gains from a defender’s point of view are astounding to us. If you had a human in place of Big Sleep, they would’ve had to pour over two different versions of open-source source code and manually see where the vulnerability was, all while knowing that attackers were planning on using this vulnerability soon.\u003c/p\u003e\u003cp data-block-key=\"ep1m0\"\u003eSpeed and accuracy made all the difference in this case, which gave us an edge over threat actors. Since defenders own and control these systems, AI has given us a very powerful development (and vulnerability remediation) advantage.\u003c/p\u003e\u003cp data-block-key=\"5k04t\"\u003eBig Sleep is also being deployed to help improve the security of other widely-used open-source projects, too — a major win for ensuring faster, more effective security across the internet more broadly.\u003c/p\u003e\u003cp data-block-key=\"fvuk6\"\u003e\u003cb\u003eEmpowering defensive AI agents\u003c/b\u003e\u003c/p\u003e\u003cp data-block-key=\"e96nf\"\u003eWhile AI agents represent a sea change for cybersecurity, the work they do needs to be done safely and responsibly. We \u003ca href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-how-google-secures-ai-agents/\"\u003eoutlined our approach to building AI agents\u003c/a\u003e in June in ways that safeguard privacy, mitigate the risks of rogue actions, and ensure the agents operate with the benefit of human oversight and transparency. When deployed according to \u003ca href=\"https://static.googleusercontent.com/media/publicpolicy.google/en//resources/google_commitment_secure_by_design_overview.pdf\" target=\"_blank\"\u003esecure by design principles\u003c/a\u003e, agents can give defenders an edge like no other tool that came before them.\u003c/p\u003e\u003cp data-block-key=\"cnsou\"\u003eWe will continue to share our agentic AI insights and report findings through our industry-standard disclosure process. You can keep tabs on all publicly-disclosed vulnerabilities from Big Sleep \u003ca href=\"https://issuetracker.google.com/issues?q=componentid:1836411\u0026amp;s=type:desc\u0026amp;s=issue_id:desc\" target=\"_blank\"\u003eon our issue tracker page\u003c/a\u003e.\u003c/p\u003e\u003cp data-block-key=\"12pf8\"\u003eWe’re seeing the \u003ca href=\"https://cloud.google.com/transform/3-new-ways-ai-security-sidekick?e=48754805\"\u003eimpact of AI across security\u003c/a\u003e, from boosting threat hunting to stronger security validations to smarter red team analyses. Similarly, the speed and accuracy of AI comes to aid defenders when dealing with the ever-growing onslaught of email phishing attacks. Attackers have been using AI to improve a lot of the previous hints that a legit-looking email was actually a phishing attack, such as using colloquial language, proper slang, and tailoring the email to the recipient.\u003c/p\u003e\u003cp data-block-key=\"697bd\"\u003eYet if you train the AI model to look at what spearphishing emails look like, it can get better at detection, triage, and identifying phishing threats faster and at a scale that if a human has to jump in to review something, they have to review less now. Our AI-powered defenses help Gmail block all sorts of phishing, spam, and malware.\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"7ds5q\"\u003eGmail automatically \u003ca href=\"https://cloud.google.com/blog/products/workspace/how-gmail-helps-users-avoid-email-scams\"\u003eblocks more than 99.9%\u003c/a\u003e of spam, phishing and malware, and protects over 1.5 billion inboxes.\u003c/li\u003e\u003cli data-block-key=\"g3fe\"\u003eWe developed several ground-breaking AI models last year that \u003ca href=\"https://blog.google/products/gmail/gmail-holidays-2024-spam-scam/\" target=\"_blank\"\u003esignificantly strengthened Gmail cyber defenses\u003c/a\u003e, including a new large language model (LLM) that we trained on phishing, malware and spam that blocks 20% more spam than before and reviews 1,000 times more user-reported spam daily.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"2sjbg\"\u003eWhen it comes to attackers and their use of AI, we’re still in the “before times.” As I noted at RSAC, Google Threat Intelligence Group has seen AI used to flesh out code, we've seen AI used for deepfakes, and to craft better spearphishing emails, but we’ve yet to see a big, game-changing incident where AI did something that humans simply couldn't have done. We haven't seen anything like an agentic attacker or an agentic attack, or a self-perpetuated campaign.\u003c/p\u003e\u003cp data-block-key=\"fh7v7\"\u003eI fully anticipate that these types of attacks are coming, so it’s \u003ca href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-ai-vendors-should-share-vulnerability-research-heres-why/\"\u003ecrucial that AI developers collaborate\u003c/a\u003e across industry and with public sector partners to prepare defenders and ensure AI’s success. As part of our efforts to build partnerships, we worked with industry partners last year to launch the \u003ca href=\"https://blog.google/technology/safety-security/google-coalition-for-secure-ai/\" target=\"_blank\"\u003eCoalition for Secure AI\u003c/a\u003e (CoSAI), an initiative to ensure the safe implementation of AI systems.\u003c/p\u003e\u003cp data-block-key=\"sit3\"\u003eTo further this work, we announced yesterday that Google will donate data from our \u003ca href=\"http://saif.google/\" target=\"_blank\"\u003eSecure AI Framework\u003c/a\u003e (SAIF) to help accelerate CoSAI’s agentic AI, cyber defense, and software supply chain security workstreams.\u003c/p\u003e\u003cp data-block-key=\"27nn7\"\u003eAt Google, we’ve been investing in AI and machine learning tools for more than a decade. While we have always believed in AI’s potential to help make software more secure, over the last year we have seen real leaps in its capabilities, with AI redefining what lasting and durable cybersecurity can look like.\u003c/p\u003e\u003cp data-block-key=\"8sopv\"\u003eYou can learn more about our efforts to use AI to help secure and support organizations around the world from our \u003ca href=\"https://cloud.google.com/solutions/security/leaders\"\u003eOffice of the CISO\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-aside\"\u003e\u003cdl\u003e\n    \u003cdt\u003easide_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;title\u0026#x27;, \u0026#x27;Join the Google Cloud CISO Community\u0026#x27;), (\u0026#x27;body\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6ba31fac0\u0026gt;), (\u0026#x27;btn_text\u0026#x27;, \u0026#x27;Learn more\u0026#x27;), (\u0026#x27;href\u0026#x27;, \u0026#x27;https://rsvp.withgoogle.com/events/ciso-community-interest?utm_source=cgc-blog\u0026amp;utm_medium=blog\u0026amp;utm_campaign=2024-cloud-ciso-newsletter-events-ref\u0026amp;utm_content=-\u0026amp;utm_term=-\u0026#x27;), (\u0026#x27;image\u0026#x27;, \u0026lt;GAEImage: GCAT-replacement-logo-A\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003ch3 data-block-key=\"4bd61\"\u003e\u003cb\u003eIn case you missed it\u003c/b\u003e\u003c/h3\u003e\u003cp data-block-key=\"2kd9o\"\u003eHere are the latest updates, products, services, and resources from our security teams so far this month:\u003c/p\u003e\u003cul\u003e\u003cli data-block-key=\"cnq1p\"\u003e\u003cb\u003eSummer of cybersecurity: Empowering defenders with AI\u003c/b\u003e: We’re sharing more about our latest AI innovations for security, public and private partnerships, and new initiatives to secure the digital ecosystem for everyone — including our plans for Black Hat and Def Con. \u003ca href=\"https://blog.google/technology/safety-security/cybersecurity-updates-summer-2025/\" target=\"_blank\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"ekhmq\"\u003e\u003cb\u003eEngineering Deutsche Telekom's sovereign data platform\u003c/b\u003e: Ashutosh Mishra, vice-president at Deutsche Telekom, explains how Google Cloud helped the company build its sovereign data platform. \u003ca href=\"https://cloud.google.com/blog/topics/customers/engineering-deutsche-telekoms-sovereign-data-platform\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"6tjhs\"\u003e\u003cb\u003eNew networking features in GDC air-gapped can power innovation\u003c/b\u003e: Three major advancements in Google Distributed Cloud air-gapped networking are designed to give you more control over your environment. \u003ca href=\"https://cloud.google.com/blog/topics/hybrid-cloud/new-networking-features-in-gdc-air-gapped-can-power-innovation\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"2vl0g\"\u003e\u003cb\u003eUnpacking security in Looker Conversational Analytics\u003c/b\u003e: Your data remains under your control when using Looker Conversational Analytics, letting you use Gemini to better understand your data. \u003ca href=\"https://cloud.google.com/blog/products/business-intelligence/understanding-looker-conversational-analytics-security\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"1bevj\"\u003e\u003cb\u003eOpening up Zero-Knowledge Proof technology to promote privacy in age assurance\u003c/b\u003e: Open sourcing these powerful cryptographic tools will make it much easier for private and public sector developers to build their own privacy-enhancing applications and digital ID solutions, meeting an urgent need. \u003ca href=\"https://blog.google/technology/safety-security/opening-up-zero-knowledge-proof-technology-to-promote-privacy-in-age-assurance/\" target=\"_blank\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"i63i\"\u003e\u003cb\u003eAdvancing protection in Chrome on Android\u003c/b\u003e: Android recently announced Advanced Protection, which extends our Advanced Protection Program to a device-level security setting for Android users that need heightened security. Here’s how it integrates with Chrome on Android. \u003ca href=\"https://security.googleblog.com/2025/07/advancing-protection-in-chrome-on.html\" target=\"_blank\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"h2lk\"\u003ePlease visit the Google Cloud blog for more security stories \u003ca href=\"https://cloud.google.com/blog/products/identity-security\"\u003epublished this month\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-aside\"\u003e\u003cdl\u003e\n    \u003cdt\u003easide_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;title\u0026#x27;, \u0026#x27;Fact of the month\u0026#x27;), (\u0026#x27;body\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6ba31f340\u0026gt;), (\u0026#x27;btn_text\u0026#x27;, \u0026#x27;Learn more\u0026#x27;), (\u0026#x27;href\u0026#x27;, \u0026#x27;https://bughunters.google.com/blog/5753079171252224/ai-bugswat-in-tokyo-2025-hacker-roadshow\u0026#x27;), (\u0026#x27;image\u0026#x27;, \u0026lt;GAEImage: GCAT-replacement-logo-A\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003ch3 data-block-key=\"29tyz\"\u003e\u003cb\u003eThreat Intelligence news\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"5fn6d\"\u003e\u003cb\u003eWhy isolated recovery environments are critical in modern cyber resilience\u003c/b\u003e: IREs can provide a measurable, critical difference in disaster recovery strategies. Here are practical steps organizations can take to implement them effectively. \u003ca href=\"https://cloud.google.com/blog/topics/threat-intelligence/isolated-recovery-environments-modern-cyber-resilience\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e\u003c/li\u003e\u003cli data-block-key=\"dbm1d\"\u003e\u003cb\u003eSecuring protection relays in modern substations\u003c/b\u003e: Cyberattacks on digitized protection relays in substations pose a severe threat to power grid stability, risking widespread outages and infrastructure damage. With CISA warning of heightened risks from Iran-nexus groups targeting vital networks, here’s what critical infrastructure providers need to know about securing these relays. \u003ca href=\"https://cloud.google.com/blog/topics/threat-intelligence/securing-protection-relays-modern-substations\"\u003e\u003cb\u003eRead more\u003c/b\u003e\u003c/a\u003e\u003cb\u003e.\u003c/b\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"9htki\"\u003ePlease visit the Google Cloud blog for more threat intelligence stories \u003ca href=\"https://cloud.google.com/blog/topics/threat-intelligence/\"\u003epublished this month\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph\"\u003e\u003ch3 data-block-key=\"rcfc5\"\u003e\u003cb\u003eNow hear this: Podcasts from Google Cloud\u003c/b\u003e\u003c/h3\u003e\u003cul\u003e\u003cli data-block-key=\"f35sm\"\u003e\u003cb\u003eThe SIEM Paradox: Logs, lies, and failing to detect\u003c/b\u003e: Svetla Yankova, founder and CEO, Citreno, joins hosts Anton Chuvakin and Tim Peacock to talk about SIEM tooling and threat detection challenges. \u003ca href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep234-the-siem-paradox-logs-lies-and-failing-to-detect/\" target=\"_blank\"\u003e\u003cb\u003eListen here\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"ja07\"\u003e\u003cb\u003eResilience and security with Google Product Security Engineering\u003c/b\u003e: How does Google balance high reliability and operational excellence with the needs of detection and response? Cristina Vintila, product security engineering manager, Google Cloud, talks with Anton and Tim about how PSE has evolved. \u003ca href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep233-product-security-engineering-at-google-resilience-and-security/\" target=\"_blank\"\u003e\u003cb\u003eListen here\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"39ue3\"\u003e\u003cb\u003eThe human element when designing privacy\u003c/b\u003e: From consulting with a world leader to Fuschia, Sarah Aoun, Google privacy engineer, goes deep into the nuances, challenges, and excitement of building digital privacy with Anton and Tim. \u003ca href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep232-the-human-element-of-privacy-protecting-high-risk-targets-and-designing-systems/\" target=\"_blank\"\u003e\u003cb\u003eListen here\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003cli data-block-key=\"5v8q\"\u003e\u003cb\u003eThe Defender’s Advantage: The rise of ClickFix\u003c/b\u003e: Dima Lenz, security engineer, Google Threat Intelligence Group, joins host Luke McNamara to discuss how threat actors have been using ClickFix to socially engineer users. \u003ca href=\"https://www.youtube.com/watch?v=qPLTSEYD6sg\u0026amp;list=PLjiTz6DAEpuINUjE8zp5bAFAKtyGJvnew\" target=\"_blank\"\u003e\u003cb\u003eListen here\u003c/b\u003e\u003c/a\u003e.\u003c/li\u003e\u003c/ul\u003e\u003cp data-block-key=\"3pdvm\"\u003eTo have our Cloud CISO Perspectives post delivered twice a month to your inbox, \u003ca href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\"\u003esign up for our newsletter\u003c/a\u003e. We’ll be back in a few weeks with more security-related updates from Google Cloud.\u003c/p\u003e\u003c/div\u003e"
    },
    {
      "title": "AI/ML-ready Apache Spark with Dataproc",
      "link": "https://cloud.google.com/blog/products/data-analytics/dataproc-features-enable-aiml-ready-apache-spark/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-07-17T16:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eApache Spark is the cornerstone for large-scale data processing, model training, and inference for AI/ML workloads. Yet, the complexities of environment configuration, dependency management, and MLOps integration can slow you down. To accelerate your AI/ML journey, \u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDataproc\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e now delivers powerful, ML-ready capabilities for Spark. Available on both Dataproc on Compute Engine clusters and \u003c/span\u003e\u003ca href=\"https://cloud.google.com/products/serverless-spark\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGoogle Cloud Serverless for Apache Spark\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, these enhancements are engineered to streamline development and operations, reducing setup overhead and simplifying workflows. This allows data scientists and engineers to dedicate more time to building and deploying impactful models rather than wrestling with infrastructure. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eLet's explore what’s new and how to start using these innovations today.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAI/ML-capable runtimes\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eGetting a Spark environment ready for ML, especially with GPU acceleration, used to involve custom scripts and manual configuration. Dataproc now streamlines this with ML Runtimes. ML Runtimes is a specialized Dataproc on Compute Engine image version, starting from 2.3 for Ubuntu-based images, designed to accelerate ML workloads. It ships with pre-packaged GPU drivers (NVIDIA Driver, CUDA, cuDNN, NCCL) and common ML libraries such as PyTorch, XGBoost, tokenizers, transformers etc, significantly cutting down cluster provisioning and setup time. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eGoogle Cloud Serverless for Apache Spark also benefits from runtimes with pre-installed ML libraries, bringing the same ease of use to a serverless environment. These also include libraries such as XGBoost, PyTorch, tokenizers, transformers, etc. \u003c/span\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003e\"At Snap we use Spark on Dataproc for a variety of analytics and ML workloads including running GPU accelerated Spark Rapids, and model training and inference with PyTorch. The new Dataproc 2.3 ML runtime has been really helpful — reducing our cluster startup latency by 75% and eliminating toil for our ML Platform developers to build and manage environments.”\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e- Prudhvi Vatala, Sr. Manager, Snap Inc.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIt’s easy to \u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc/docs/quickstarts/create-cluster-console\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ecreate a Dataproc \u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eon a compute\u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc/docs/quickstarts/create-cluster-console\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003e Engine cluster\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, specifying the ML image version and the required GPU accelerators for your workers.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;gcloud dataproc clusters create \u0026lt;your-cluster-name\u0026gt; \\\\\\r\\n--project=\u0026lt;your-project-id\u0026gt; \\\\\\r\\n--region=\u0026lt;your-region\u0026gt; \\\\\\r\\n--image-version=2.3-ml-unbuntu \\\\\\r\\n--master-machine-type g2-standard-4 --master-accelerator=type=nvidia-l4,count=1\\r\\n--worker-machine-type=g2-standard-8 \\\\\\r\\n--worker-accelerator type=nvidia-l4,count=1\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be9a90\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAdditionally, Serverless Spark sessions (Generally Available) also support GPUs, and come similarly packaged with GPU drivers and common ML libraries.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eDevelop Spark applications in Colab or your favorite IDE\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eNow, you can develop and run Spark applications using Colab Enterprise notebooks in BigQuery Studio or via integrated development environments (IDEs) like \u003c/span\u003e\u003ca href=\"https://code.visualstudio.com/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eVSCode\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e and \u003c/span\u003e\u003ca href=\"https://jupyter.org/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eJupyter\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eBigQuery Colab enterprise notebooks are available within BigQuery Studio with native support for Spark application development. With Colab Enterprise notebooks, you can create  Serverless Spark sessions using Spark Connect and work with your tables in \u003c/span\u003e\u003ca href=\"https://cloud.google.com/bigquery/docs/about-blms\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eBigLake metastore.\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eColab notebook provides advanced features such as gen AI code assistance and error explanation, with error correction coming soon. It also supports observability for your Spark jobs and management of Spark sessions. In addition, the Colab notebooks lets you mix BigQuery SQL with Spark code in a single notebook and interoperate on the resulting tables. Once your code is ready, you can schedule notebooks via the inbuilt scheduling functionality or use BigQuery Pipelines for more complicated DAGs.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_fjVpMdx.gif\"\n        \n          alt=\"1\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eYou can also use IDEs such as Visual Studio Code or JupyterLab for Spark application development. JupyterLab users can use the \u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc-serverless/docs/quickstarts/jupyterlab-sessions\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDataproc JupyterLab plugin\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to simplify interactive development with Spark serverless sessions and simplify creation and submission of batch jobs via Serverless batch jobs. This plugin comes preinstalled in Vertex Workbench, so you can be productive in minutes. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_nxDaXdB.max-1000x1000.png\"\n        \n          alt=\"2\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOn VS Code, you can use the \u003c/span\u003e\u003ca href=\"https://cloud.google.com/code\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eCloud Code\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e extension, which supports development against a range of Google Cloud services. After configuring the Cloud Code extension, you can browse BigQuery datasets and tables, browse and manage your Dataproc compute resources (clusters, serverless interactive sessions and batch), create Spark notebooks from available templates or start developing on your own, and then schedule your workloads all from VS Code. This choice in development tooling allows you to pick one that best suits your workflow, without sacrificing access to the power of Dataproc Spark.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eDistributed training and inference with GPU support\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDataproc’s ML runtimes are built to run distributed training and inference, leveraging frameworks like XGBoost, TensorFlow, and PyTorch, all pre-configured for GPU utilization. For example, for distributed training with XGBoost on Spark, you can leverage the pre-installed \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003exgboost.spark\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e library. By setting parameters such as \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003enum_workers\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to distribute the task across Spark executors and \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003edevice=”cuda”\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, you can effectively train your models on multiple GPUs, significantly speeding up the training process for large datasets. Here's an example of how to configure XGBoost classifier for distributed GPU training on your Spark cluster:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;from xgboost.spark import SparkXGBClassifier\\r\\nfrom pyspark.sql import SparkSession\\r\\n\\r\\n# Configure the XGBoost classifier for distributed GPU training\\r\\nxgb_classifier = SparkXGBClassifier(\\r\\n    featuresCol=\u0026quot;features\u0026quot;,\\r\\n    labelCol=\u0026quot;label\u0026quot;,\\r\\n    num_workers=spark.sparkContext.defaultParallelism,\\r\\n    device=\u0026quot;cuda\u0026quot;,  # Enable GPU training\\r\\n    # Other XGBoost parameters like max_depth etc.\\r\\n    max_depth=6  \\r\\n)\\r\\n\\r\\n# Train the model\\r\\nxgb_model = xgb_classifier.fit(train_df)\\r\\n\\r\\n# Model persistence and prediction\\r\\nxgb_model.save(\u0026quot;path/to/your/xgboost_spark_model\u0026quot;)\\r\\npredictions = xgb_model.transform(test_df)\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;lang-py\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be98e0\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eInteractive environment customization for Spark Connect\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWhen working interactively with Spark, such as in a Colab notebook using Spark Connect, ensuring Python library consistency between your client and the Spark cluster is crucial. Dataproc simplifies adding PyPI packages dynamically to a Spark session by extending the \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eaddArtifacts\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e method. You can now specify the list of packages to install/upgrade/downgrade in \u003c/span\u003e\u003ca href=\"https://packaging.python.org/en/latest/specifications/version-specifiers/#examples-of-compliant-version-schemes\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eversion-scheme\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e (same as \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003epip install\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e). This instructs the Spark Connect server to install the package and its dependencies, making them available to workers for your UDFs and other code. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;# Installs textdistance(specific version) and random2 (latest) library on the cluster. UDFs using textdistance and random2 can now run on worker nodes\\r\\n\\r\\nspark.addArtifacts(\u0026quot;textdistance==4.6.1\u0026quot;, \u0026quot;random2\u0026quot;, pypi=True)\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;lang-py\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be9940\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIn addition you can also customize your Spark environment on Dataproc with Init scripts and custom images.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eMLOps via Vertex AI\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDataproc works with Vertex AI, Google Cloud's unified platform for AI and ML, helping to improve\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e MLOps for your AI/ML workflows with Spark. Using the Vertex AI SDK directly within your Dataproc Spark code enables experiment tracking and model management, allowing you to:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eTrack experiments\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e: Track log parameters, metrics, and artifacts from your Dataproc Spark training jobs to Vertex AI Experiments. This allows you to compare runs, visualize results, and reproduce experiments reliably.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRegister models\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e: Once training is complete, register your trained models into the Vertex AI Model Registry. This provides a central repository for model versioning, staging, and governance, simplifying the path to deployment.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;# code snippet for Dataproc Spark on GCE. Some details ommited for brevity\\r\\n\\r\\n\\r\\nfrom google.cloud import aiplatform\\r\\n\\r\\n# --- Initialize Vertex AI SDK \u0026amp; Enable Autologging ---\\r\\naiplatform.init(project=PROJECT_ID, location=REGION, experiment=EXPERIMENT_NAME)\\r\\n\\r\\n# Start a run to log experiment metrics\\r\\naiplatform.start_run(run=RUN_NAME)\\r\\n\\r\\nxgb_spark_estimator = SparkXGBClassifier(\\r\\n    featuresCol=\u0026quot;features\u0026quot;,\\r\\n    labelCol=\u0026quot;label\u0026quot;     \\r\\n    # Add other XGBoost parameters needed for training\\r\\n    )\\r\\n\\r\\n# train model\\r\\ntrained_spark_model = xgb_spark_estimator.fit(train_df)\\r\\n\\r\\n# register model\\r\\n# 1. Get the underlying XGBoost model and save it\\r\\nnative_booster = trained_spark_model.get_booster()\\r\\nnative_booster.save_model(local_path)\\r\\n\\r\\n# Log relevant metrics manually in Vertex Experiments \\r\\nmetrics={parameter_name:parameter_value}\\r\\naiplatform.log_metrics(metrics)\\r\\n\\r\\n\\r\\n# 2. Upload to GCS\\r\\ndestination_gcs_object_name = f\u0026quot;{GCS_MODEL_ARTIFACT_DIR_NAME}/{MODEL_FILENAME}\u0026quot; \\r\\nstorage.Client(project=PROJECT_ID).bucket(GCS_BUCKET_NAME).blob(destination_gcs_object_name).upload_from_filename(local_path) \\r\\n\\r\\n# 3. Register to Vertex AI Model Registry\\r\\nPRE_BUILT_SERVING_CONTAINER_IMAGE_URI = \u0026quot;us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.2-1:latest\u0026quot;\\r\\n\\r\\nregistered_model = aiplatform.Model.upload(\\r\\n    display_name=MODEL_DISPLAY_NAME,\\r\\n    artifact_uri=GCS_ARTIFACT_DIRECTORY_URI,\\r\\n    serving_container_image_uri=PRE_BUILT_SERVING_CONTAINER_IMAGE_URI,\\r\\n    description=\u0026quot;Spark XGBoost model\u0026quot;,\\r\\n    sync=True # Wait for the model to be uploaded and registered\\r\\n)\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;lang-py\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be9b80\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis integration makes your AI/ML workloads on Spark more manageable, reproducible, and deployable, per your organization's wider MLOps strategy.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eDeploy to production\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eMove from interactive development to production easily.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWhen using BigQuery Colab notebooks for development, you get Git support to version-control your code and go through your CI/CD flow. You can also schedule your Spark notebook using BigQuery’s built-in \u003c/span\u003e\u003ca href=\"https://cloud.google.com/bigquery/docs/pipelines-introduction\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003epipeline feature\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, which allows you create single scheduled notebooks or more complicated DAGs, chaining multiple notebooks or queries. You can run these pipelines using the user account or a service account for production pipelines.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eBigQuery Pipelines let you compose your flow into discrete tasks, so you can mix Apache Spark on Dataproc and BigQuery execution. In the following BigQuery pipeline, the first task ingests raw data via a BigQuery query, then the data is transformed via Apache Spark via a notebook task. This notebook contains the pertinent Spark transform steps. Finally, the graph splits into two parallel tasks: a notebook that produces a report based on output of the previous task, and a final query that cleans up the initial ingested data.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_JnGyp0R.max-1000x1000.png\"\n        \n          alt=\"3\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWhen using an IDE you can achieve a similar flow by using the Git client of these IDEs to version your Spark code. You can also create and deploy pipelines using Cloud Composer, Google Cloud’s managed serverless Apache Airflow offering. You can run jobs on your existing Dataproc clusters, ephemeral job clusters, or on Serverless Batch.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;# Following code illustrates how to schedule serverless batch jobs with Cloud Composer (Airflow)\\r\\n\\r\\n\\r\\n# import statements and configurations statements omitted for brevity\\r\\n\\r\\n\\r\\n# Define the full job payload for DataprocCreateBatchOperator\\r\\nwith models.DAG(\\r\\n    \u0026quot;dataproc_batch_operators\u0026quot;,  # The id you will see in the DAG airflow page\\r\\n    default_args=default_args,  # The interval with which to schedule the DAG\\r\\n    schedule_interval=datetime.timedelta(days=1),  # Override to match your needs\\r\\n) as dag:\\r\\n    create_batch = DataprocCreateBatchOperator(\\r\\n        task_id=\u0026quot;batch_create\u0026quot;,\\r\\n        batch={\\r\\n            \u0026quot;pyspark_batch\u0026quot;: {\\r\\n                \u0026quot;main_python_file_uri\u0026quot;: PYTHON_FILE_LOCATION,\\r\\n                \u0026quot;jar_file_uris\u0026quot;: [SPARK_BIGQUERY_JAR_FILE],\\r\\n            },\\r\\n            \u0026quot;environment_config\u0026quot;: {\\r\\n                \u0026quot;peripherals_config\u0026quot;: {\\r\\n                    \u0026quot;spark_history_server_config\u0026quot;: {\\r\\n                        \u0026quot;dataproc_cluster\u0026quot;: PHS_CLUSTER_PATH,\\r\\n                    },\\r\\n                },\\r\\n            },\\r\\n        },\\r\\n        batch_id=\u0026quot;create-xgboost-batch\u0026quot;,\\r\\n    )\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;lang-py\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3eb6b8be9850\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAI/ML-ready Apache Spark\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWith \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDataproc, you can build your AI/ML workloads with Apache Spark more easily. By providing pre-configured ML Runtimes with GPU support, simplifying Python dependency management for interactive sessions via Spark Connect, enabling development from your preferred IDE, and offering seamless integration with Vertex AI for MLOps, Dataproc accelerates the entire ML lifecycle. Move from exploration and training to robust, production-ready Spark ML pipelines. Explore the \u003c/span\u003e\u003ca href=\"https://cloud.google.com/dataproc/docs\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDataproc documentation\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e today to start leveraging these capabilities.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e"
    },
    {
      "title": "Tzafon selects Google Cloud to build next-generation agentic machine intelligence",
      "link": "https://cloud.google.com/blog/topics/startups/tzafon-builds-the-next-generation-of-agentic-machine-intelligence-with-google-cloud-infrastructure/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-07-17T13:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003ca href=\"https://www.tzafon.ai/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eTzafon\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, a San Francisco-based startup and AI R\u0026amp;D lab, is partnering with Google Cloud to utilize Google’s AI-optimized infrastructure and cloud services to help Tzafon deliver automation at large scale.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe Tzafon team aims to do this by building systems and models that can support multiple, autonomous AI agents that are capable of working together and interacting with common interfaces like applications, operating systems, and web browsers.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eNow, Tzafon will partner with Google Cloud to access the compute resources and cloud services it needs to train its new multi-agent models – and to develop new automation frameworks that will allow Tzafon’s agents to collaborate more quickly and seamlessly. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThrough its partnership with Google Cloud, Tzafon will:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eUse NVIDIA GPUs through Google Cloud to train new machine intelligence models capable of managing multiple AI agents.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDevelop individual agents capable of interacting with operating systems, web browsers, and applications on a person’s behalf.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eScale workloads up or down quickly using Google Kubernetes Engine.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eUse BigQuery to effectively manage the large volumes of data underpinning its systems.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eToday, more than 60% of the world’s generative AI startups are using Google Cloud. Now, Tzafon joins them in gaining access to Google Cloud’s complete AI stack, with reliable compute capacity, strong price performance, robust data infrastructure, and elasticity to scale quickly, among many other features that are essential in the emerging field of AI.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eYou can read more about Tzafon’s mission in its \u003c/span\u003e\u003ca href=\"https://www.tzafon.ai/blog/tzafon-whitepaper\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ewhite paper\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e and learn more about how thousands of AI startups are building with Google Cloud \u003c/span\u003e\u003ca href=\"https://cloud.google.com/startup?hl=en\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e"
    }
  ],
  "generatedAt": "2025-07-18T07:09:24.995585456+09:00"
}
