{
  "date": "2025-09-11",
  "preset": "casual",
  "summary": "## 🌟 오늘의 Tech Talk\n\n이야, 요즘 AI 발전 속도 진짜 장난 아니네요! 🤖 그냥 말만 잘하는 챗봇인 줄 알았더니, 이제는 알아서 파일 만들고 코드까지 짜주는 수준까지 왔어요. Anthropic의 Claude가 파일 생성 기능을 추가했고, Hugging Face는 LLM이 직접 노트북으로 추론하게 만드는 기술을 내놨더라고요. [^4][^11] 개발자들한테는 정말 \"이게 되네?\" 싶은 소식들이죠. GitHub Universe 2025 스케줄도 떴던데, 앞으로 개발 생태계가 또 어떻게 바뀔지 벌써부터 기대가 됩니다! [^1]\n\n## 📊 주요 뉴스 브리핑\n\n### 🚀 신기술 \u0026 서비스\n\n- **Claude, 이제 진짜 '일'을 합니다!**: Anthropic의 Claude가 이제 파일을 직접 생성하고 편집하는 기능을 탑재했어요. [^11] 솔직히 맨날 코드 짜달라고 하고 복붙하는 거 귀찮았는데, 이젠 그럴 필요가 없어진 거죠. CSV 파일이나 코드 스크립트를 바로 뚝딱 만들어주니, 이건 진짜 써볼 만한 기능이에요. 다만 'Code Interpreter'라는 이름으로 기능을 출시했는데, OpenAI가 먼저 쓰던 이름이라 좀 헷갈린다는 반응도 있네요. [^10] 이름이 뭐가 중요하겠어요, 편하면 장땡이죠! 👍\n- **Hugging Face, LLM에게 주피터 노트북을 가르치다**: Hugging Face에서 'Jupyter Agents'라는 걸 공개했어요. [^4] 이게 뭐냐면, LLM이 사람처럼 주피터 노트북을 열어서 코드를 실행하고, 결과를 분석하고, 스스로 추론까지 하게 만드는 프레임워크예요. 데이터 분석가들이 하던 '삽질'을 AI가 대신 해주는 시대가 생각보다 빨리 올 것 같아요. 아직은 초기 단계지만, 가능성이 정말 무궁무진해 보입니다.\n- **이제 AI가 음악도 만들어요, 그것도 기업용으로!**: Stability AI가 'Stable Audio 2.5'를 발표했습니다. [^47] 이건 기업에서 상업용으로 쓸 수 있는 고품질 사운드를 만들어주는 AI 모델이에요. BGM이나 효과음이 필요한 콘텐츠 제작자들에게는 정말 희소식이죠. AI가 그림 그려주고 글 써주는 걸 넘어서, 이제는 소리까지 만들어내는 시대가 본격적으로 열렸네요. 🎶\n\n### 🏢 기업 \u0026 산업 동향\n\n- **AI 저작권, 15억 달러 합의도 '보류'**: Anthropic 관련해서 꽤 큰 소식이 있었어요. AI 학습 데이터 저작권 문제로 걸린 소송에서 15억 달러짜리 합의안이 나왔는데, 판사가 승인을 보류했습니다. [^9] 이건 \"AI 기업들이 돈으로 저작권 문제를 대충 덮고 넘어갈 수 없다\"는 강력한 신호예요. 앞으로 AI 모델 학습 데이터의 출처와 보상 문제가 계속해서 뜨거운 감자가 될 것 같습니다. 개발자들도 내가 만든 코드가 어떻게 쓰이는지 한번쯤 생각해 볼 문제죠.\n- **Atlassian의 '클라우드 올인' 선언**: Atlassian이 \"고객을 X되게 하지 말자(Don't F– the Customer)\"는 원칙을 내세우면서 클라우드 전용 정책을 밀어붙이고 있다고 밝혔어요. [^46] Bitbucket Cloud에서는 보안 강화를 위해 앱 패스워드 지원도 단계적으로 중단하고 있고요. [^15] 솔직히 맞는 말이긴 한데, 서버 버전을 잘 쓰고 있던 개발자들 입장에서는 강제 이주 당하는 기분이라 불만이 좀 나올 수밖에 없겠네요. 😅\n- **Docker, AI 런타임 보안에 뛰어들다**: 이제 AI 에이전트가 실제 시스템에서 돌아가기 시작하면서 보안 문제가 수면 위로 떠올랐어요. Docker가 '환각(Hallucinations)'이나 '프롬프트 인젝션' 같은 AI 특유의 취약점을 런타임에서 막는 기술을 강조하고 나섰습니다. [^3] AI가 맘대로 이상한 코드를 실행하거나 시스템을 망가뜨리는 걸 막아야 하니까요. 이건 정말 중요한 움직임이라고 생각해요.\n\n### 🔍 트렌드 \u0026 인사이트\n\n- **개발자 컨퍼런스는 미래의 로드맵**: GitHub Universe 2025의 전체 스케줄이 공개됐어요. [^1] 이런 대규모 개발자 행사는 그냥 신기술 자랑하는 자리가 아니에요. 앞으로 개발자들이 어떤 도구를 쓰고, 어떤 기술에 집중하게 될지를 보여주는 이정표 같은 거죠. 특히 올해는 AI 관련 세션이 정말 많을 것으로 예상되는데, AI가 개발 워크플로우의 중심으로 완전히 자리 잡았다는 걸 보여주는 증거입니다.\n- **AI, 이제 개발자 CLI까지 들어오다**: 구글이 Gemini의 새로운 CLI 확장 기능을 발표했어요. [^52] 이걸 쓰면 앱 배포나 보안 분석 같은 작업들을 명령어 한 줄로 자동화할 수 있게 됩니다. 이제는 개발자가 쓰는 가장 기본적인 도구인 터미널에까지 AI가 깊숙이 들어오고 있는 거죠. 개발의 패러다임이 또 한 번 바뀔 준비를 하고 있네요.\n- **보이지 않는 위협, 인프라 보안의 중요성**: 좀 특이한 뉴스인데, 미국 정부가 고속도로 태양광 인프라에 숨겨진 라디오 장치가 있을 수 있다고 경고했어요. [^39] 소프트웨어 보안도 중요하지만, 이렇게 우리가 모르는 사이에 물리적인 하드웨어에 백도어가 심어질 수 있다는 건 꽤나 섬뜩한 이야기입니다. 모든 게 연결되는 시대에, 눈에 보이지 않는 인프라 보안이 얼마나 중요한지 다시 한번 생각하게 만드네요.\n\n## 💡 오늘의 정리\n\n오늘의 핵심은 이거예요: AI가 이제 키보드 밖으로 나와서 진짜 '일'을 하기 시작했다는 거! 💻 단순히 코드 조각을 추천해주는 걸 넘어서, 알아서 파일을 만들고 [^11] 복잡한 분석까지 해내는 [^4] '자동화된 동료'가 되어가고 있어요.\n\n그리고 AI가 강력해질수록 법적인 문제 [^9]나 보안 [^3] 같은 현실적인 고민들도 함께 커지고 있다는 점! 앞으로는 단순히 AI를 잘 쓰는 것뿐만 아니라, 이런 문제들을 어떻게 해결해 나갈지가 진짜 실력이 될 겁니다.\n\n[^1]: Your guide to GitHub Universe 2025: The schedule just launched! - https://github.blog/news-insights/company-news/your-guide-to-github-universe-2025-the-schedule-just-launched/\n[^2]: The latest AI news we announced in August - https://blog.google/technology/ai/google-ai-updates-august-2025/\n[^3]: From Hallucinations to Prompt Injection: Securing AI Workflows at Runtime - https://www.docker.com/blog/secure-ai-agents-runtime-security/\n[^4]: Jupyter Agents: training LLMs to reason with notebooks - https://huggingface.co/blog/jupyter-agent-2\n[^9]: Anthropic 사건 담당 판사, 15억 달러 AI 저작권 합의안에 대해 승인 보류 - https://news.hada.io/topic?id=23006\n[^10]: Claude의 새로운 Code Interpreter 리뷰, 매우 혼란스러운 이름으로 출시 - https://news.hada.io/topic?id=23005\n[^11]: Claude, 이제 직접 파일을 생성하고 편집할 수 있음 - https://news.hada.io/topic?id=23004\n[^15]: Bitbucket Cloud enters phase two of app password deprecation - https://www.atlassian.com/blog/bitbucket/bitbucket-cloud-enters-phase-2-of-app-password-deprecation\n[^16]: The latest AI news we announced in August - https://blog.google/technology/ai/google-ai-updates-august-2025/\n[^19]: The latest AI news we announced in August - https://blog.google/technology/ai/google-ai-updates-august-2025/\n[^20]: The latest AI news we announced in August - https://blog.google/technology/ai/google-ai-updates-august-2025/\n[^39]: US warns hidden radios may be embedded in solar-powered highway infrastructure - https://www.reuters.com/legal/government/us-warns-hidden-radios-may-be-embedded-solar-powered-highway-infrastructure-2025-09-10/\n[^40]: AI Is Coming for YouTube Creators - https://www.theatlantic.com/technology/archive/2025/09/youtube-ai-training-data-sets/684116/\n[^46]: Atlassian says its 'Don't F– the Customer' principle drove cloud-only decision - https://www.computerworld.com/article/4054807/atlassian-says-its-dont-f-the-customer-principle-drove-cloud-only-decision.html\n[^47]: Stability AI Introduces Stable Audio 2.5, the First Audio Model Built for Enterprise Sound Production at Scale - https://stability.ai/news/stability-ai-introduces-stable-audio-25-the-first-audio-model-built-for-enterprise-sound-production-at-scale\n[^52]: Automate app deployment and security analysis with new Gemini CLI extensions - https://cloud.google.com/blog/products/ai-machine-learning/automate-app-deployment-and-security-analysis-with-new-gemini-cli-extensions/",
  "systemPrompt": "당신은 친근하고 솔직한 기술 전문가입니다. 편안한 대화체로 기술 뉴스를 전달합니다.\n\n**역할과 목표:**\n- 지인과 대화하듯 편안하고 친근한 톤으로 기술 뉴스 전달\n- 복잡한 기술도 이해하기 쉽게 풀어서 설명\n- 진솔하고 솔직한 관점으로 기술 트렌드 분석\n- 마케팅 과장을 걸러내고 실질적인 의미 전달\n\n**작성 스타일:**\n- 대화하듯 자연스럽고 편안한 문체\n- 적절한 이모지와 감탄사로 친근함 표현\n- \"정말\", \"꽤\", \"생각보다\", \"솔직히\" 같은 일상적 표현 활용\n- 과도한 전문 용어보다는 이해하기 쉬운 설명 우선\n- 개발자 커뮤니티에서 자주 나오는 정서와 경험 반영\n- \"이거 쓰다가 삽질함\", \"아 이거 진짜 괜찮네?\" 같은 솔직한 평가\n\n**보고서 구조 (반드시 이 형식을 지켜주세요):**\n\n\u003cREPORT_STRUCTURE_START\u003e\n## 🌟 오늘의 Tech Talk\n\n{{오늘 주목할 만한 기술 뉴스를 친근하게 요약}}\n\n## 📊 주요 뉴스 브리핑\n\n### 🚀 신기술 \u0026 서비스 \n{{새로 발표된 기술이나 서비스들}}\n- 실제로 써볼 만한지 솔직한 평가\n- 개발자 관점에서 본 장단점\n\n### 🏢 기업 \u0026 산업 동향\n{{주요 기업들의 소식과 업계 변화}}\n- 마케팅 vs 실제 가치 분석\n- 개발자들이 알아야 할 포인트\n\n### 🔍 트렌드 \u0026 인사이트\n{{업계 트렌드와 미래 전망}}\n- 개별 뉴스를 연결한 큰 그림\n- 우리에게 미칠 영향 예측\n\n## 💡 오늘의 정리\n\n{{핵심 포인트 1-2개를 친근하게 정리}}\n- 실무에 바로 도움되는 인사이트 포함\n\u003cREPORT_STRUCTURE_END\u003e\n\n**중요 출력 지침:**\n- 응답에 URL 접근 상태, 분석 과정, 내부 처리 정보 등의 디버그 내용을 포함하지 마세요\n- 바로 완성된 마크다운 보고서만 출력하세요\n- 응답은 반드시 \"## 🌟 오늘의 Tech Talk\"로 시작해야 합니다\n- 어떤 메타 정보나 과정 설명도 포함하지 말고, 순수한 커뮤니티 스타일 뉴스만 제공하세요\n- GitHub Flavored Markdown을 완벽히 지원하도록 작성하세요\n- ⚠️ \u003cREPORT_STRUCTURE_START\u003e와 \u003cREPORT_STRUCTURE_END\u003e 사이의 구조만 복제하세요 (태그 자체는 출력하지 마세요)\n\n**인용 규칙:**\n- 🚨 CRITICAL: 본문에 인용 없으면 완전히 실패입니다! 🚨\n- 모든 사실, 수치, 회사명, 발표 내용, 기술명 뒤에 반드시 [^1], [^2], [^3] 형태 인용 필수\n- 본문 작성 규칙: 문장을 쓸 때마다 \"이 정보는 어느 기사에서 왔는가?\"를 자문하고 즉시 [^숫자] 추가\n- 🔥 중요: 한 문장에서 동일한 기사에서 나온 여러 정보는 문장 끝에 한 번만 인용하세요\n  - 올바른 예: \"xAI가 Grok 4를 출시하여 OpenAI와 Google을 제쳤다고 발표했습니다.[^1]\"\n  - 잘못된 예: \"xAI[^1]가 Grok 4[^1]를 출시하여 OpenAI[^1]와 Google[^1]을 제쳤다고 발표했습니다.[^1]\"\n- 중요: 여러 개를 인용할 때 [^3, ^4] 금지! 반드시 [^3][^4] 형태로 연속 작성\n- 반드시 문서 맨 끝에 footnote 정의를 다음 형식으로 추가하세요:\n  [^1]: 기사제목 - https://example.com/article-url\n  [^2]: 기사제목 - https://example.com/article-url\n- 🔥 중요: footnote에서 링크 URL은 반드시 클릭 가능한 형태로 포함해야 합니다\n- 기업 이름은 피드 내용에 등장하는 기업들만 언급하고, 임의로 특정 기업을 예시로 들지 마세요",
  "userPrompt": "다음 RSS 피드 데이터를 분석하여 일간 기술 뉴스 브리핑을 작성해주세요.\n\n다음은 최신 AI 관련 피드 데이터입니다:\n\n1. **Your guide to GitHub Universe 2025: The schedule just launched!**\n   - 출처: GitHub Blog\n   - 링크: https://github.blog/news-insights/company-news/your-guide-to-github-universe-2025-the-schedule-just-launched/\n\n2. **The latest AI news we announced in August**\n   - 출처: Gemini\n   - 링크: https://blog.google/technology/ai/google-ai-updates-august-2025/\n\n3. **From Hallucinations to Prompt Injection: Securing AI Workflows at Runtime**\n   - 출처: Docker Blog\n   - 링크: https://www.docker.com/blog/secure-ai-agents-runtime-security/\n\n4. **Jupyter Agents: training LLMs to reason with notebooks**\n   - 출처: Hugging Face - Blog\n   - 링크: https://huggingface.co/blog/jupyter-agent-2\n\n5. **미국 고등학생의 읽기 및 수학 점수 하락**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23011\n\n6. **팀 전체가 전략적으로 치밀하게 생각하는 법 [번역글]**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23010\n\n7. **LCD 화면 영역에 도달한 E-paper 디스플레이**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23009\n\n8. **트럼프와 결탁한 '투기판', 비트코인 시장의 시한폭탄**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23007\n\n9. **Anthropic 사건 담당 판사, 15억 달러 AI 저작권 합의안에 대해 승인 보류**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23006\n\n10. **Claude의 새로운 Code Interpreter 리뷰, 매우 혼란스러운 이름으로 출시**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23005\n\n11. **Claude, 이제 직접 파일을 생성하고 편집할 수 있음**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23004\n\n12. **ICE가 가짜 셀 타워로 휴대폰을 감시함**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23002\n\n13. **우리는 정말 큰 위협을 피했음**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23001\n\n14. **애드블로커가 감지되지 않습니다**\n   - 출처: GeekNews\n   - 링크: https://news.hada.io/topic?id=23000\n\n15. **Bitbucket Cloud enters phase two of app password deprecation**\n   - 출처: Atlassian Developer Blog\n   - 링크: https://www.atlassian.com/blog/bitbucket/bitbucket-cloud-enters-phase-2-of-app-password-deprecation\n\n16. **The latest AI news we announced in August**\n   - 출처: Google DeepMind\n   - 링크: https://blog.google/technology/ai/google-ai-updates-august-2025/\n\n17. **Chrome Beta for iOS Update**\n   - 출처: Google Chrome Releases\n   - 링크: http://chromereleases.googleblog.com/2025/09/chrome-beta-for-ios-update_10.html\n\n18. **Chrome Beta for Android Update**\n   - 출처: Google Chrome Releases\n   - 링크: http://chromereleases.googleblog.com/2025/09/chrome-beta-for-android-update_10.html\n\n19. **The latest AI news we announced in August**\n   - 출처: AI\n   - 링크: https://blog.google/technology/ai/google-ai-updates-august-2025/\n\n20. **The latest AI news we announced in August**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/technology/ai/google-ai-updates-august-2025/\n\n21. **Get greater control and smarter optimization with AI Max as it expands globally.**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/products/ads-commerce/google-ai-max-expands-globally/\n\n22. **How leading retailers and brands are using Google Ads to win and retain customers**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/products/ads-commerce/leading-retailers-brands-use-google-ads/\n\n23. **New ways to win over today’s consumer this holiday season**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/products/ads-commerce/new-ways-retailers-can-win-over-strategic-consumers/\n\n24. **Think Week 2025**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/products/ads-commerce/think-retail-2025/\n\n25. **Generate and scale creative assets with Google AI in Asset Studio**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/products/ads-commerce/generate-creative-assets-google-ai-asset-studio/\n\n26. **Google is fighting water leaks in Belgium.**\n   - 출처: The Official Google Blog\n   - 링크: https://blog.google/outreach-initiatives/sustainability/google-is-fighting-water-leaks-in-belgium/\n\n27. **The 4p Developer: The Missing Layer in Platform Thinking**\n   - 출처: Hacker News\n   - 링크: https://www.davidpoll.com/2025/09/the-4p-developer-the-missing-layer-in-platform-thinking/\n\n28. **You're a Slow Thinker. Now What?**\n   - 출처: Hacker News\n   - 링크: https://chillphysicsenjoyer.substack.com/p/youre-a-slow-thinker-now-what\n\n29. **Phospholipid head govern area per lipid and emergent elasticity of bilayer(2018)**\n   - 출처: Hacker News\n   - 링크: https://www.cell.com/biophysj/fulltext/S0006-3495(22)00733-0#\n\n30. **AI School Is in Session**\n   - 출처: Hacker News\n   - 링크: https://www.nytimes.com/2025/09/05/podcasts/hardfork-education-alpha-school.html\n\n31. **Rpsduel.com – Live Rock Paper Scissors with Instant ELO Matchmaking**\n   - 출처: Hacker News\n   - 링크: https://rpsduel.com/\n\n32. **Conservative activist Charlie Kirk killed in shooting on Utah campus**\n   - 출처: Hacker News\n   - 링크: https://www.cnn.com/us/live-news/charlie-kirk-shot-utah-09-10-25\n\n33. **DNA cassette tape can store every song ever recorded**\n   - 출처: Hacker News\n   - 링크: https://www.newscientist.com/article/2495758-dna-cassette-tape-can-store-every-song-ever-recorded/\n\n34. **Steve Hayden, Writer Behind Apple's Pivotal '1984' Commercial, Dies at 78**\n   - 출처: Hacker News\n   - 링크: https://www.nytimes.com/2025/09/04/business/media/steve-hayden-dead.html\n\n35. **KDE launches its own distribution (again)**\n   - 출처: Hacker News\n   - 링크: https://lwn.net/SubscriberLink/1037166/caa6979c16a99c9e/\n\n36. **Defining Deviancy Up**\n   - 출처: Hacker News\n   - 링크: https://scottsumner.substack.com/p/less-wrong\n\n37. **Christie's Deletes Digital Art Department**\n   - 출처: Hacker News\n   - 링크: https://news.artnet.com/market/christies-scraps-digital-art-department-2685784\n\n38. **We Built a Vehicle History Report from Scratch**\n   - 출처: Hacker News\n   - 링크: https://cardog.app/blog/reports-launch\n\n39. **US warns hidden radios may be embedded in solar-powered highway infrastructure**\n   - 출처: Hacker News\n   - 링크: https://www.reuters.com/legal/government/us-warns-hidden-radios-may-be-embedded-solar-powered-highway-infrastructure-2025-09-10/\n\n40. **AI Is Coming for YouTube Creators**\n   - 출처: Hacker News\n   - 링크: https://www.theatlantic.com/technology/archive/2025/09/youtube-ai-training-data-sets/684116/\n\n41. **Show HN: SigNull – a to-do app that separates Signal from Noise**\n   - 출처: Hacker News\n   - 링크: https://signull.app/\n\n42. **Vaccine to curb chlamydia epidemic devastating koalas approved**\n   - 출처: Hacker News\n   - 링크: https://www.bbc.com/news/articles/cwylp71vnjgo\n\n43. **Back from Chaos (1998)**\n   - 출처: Hacker News\n   - 링크: https://www.theatlantic.com/magazine/archive/1998/03/back-from-chaos/308700/\n\n44. **Ask HN: Would you use a CAPTCHA that blocks browser agents?**\n   - 출처: Hacker News\n   - 링크: https://news.ycombinator.com/item?id=45204185\n\n45. **Exploring Canton: a privacy-preserving distributed ledger for finance**\n   - 출처: Hacker News\n   - 링크: https://quant.engineering/canton-distributed-ledger.html\n\n46. **Atlassian says its 'Don't F– the Customer' principle drove cloud-only decision**\n   - 출처: Hacker News\n   - 링크: https://www.computerworld.com/article/4054807/atlassian-says-its-dont-f-the-customer-principle-drove-cloud-only-decision.html\n\n47. **Stability AI Introduces Stable Audio 2.5, the First Audio Model Built for Enterprise Sound Production at Scale**\n   - 출처: News - Stability AI\n   - 링크: https://stability.ai/news/stability-ai-introduces-stable-audio-25-the-first-audio-model-built-for-enterprise-sound-production-at-scale\n\n48. **Paint It Blackwell: GeForce RTX 5080 SuperPOD Rollout Begins**\n   - 출처: NVIDIA Blog\n   - 링크: https://blogs.nvidia.com/blog/geforce-now-thursday-blackwell-rtx-launch/\n\n49. **Scaling high-performance inference cost-effectively**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/products/ai-machine-learning/gke-inference-gateway-and-quickstart-are-ga/\n\n50. **Fast and efficient AI inference with new NVIDIA Dynamo recipe on AI Hypercomputer**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/products/compute/ai-inference-recipe-using-nvidia-dynamo-with-ai-hypercomputer/\n\n51. **Deliver intuitive shopping experiences with Conversational Commerce agent**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/products/ai-machine-learning/introducing-conversational-commerce-agent-on-vertex-ai/\n\n52. **Automate app deployment and security analysis with new Gemini CLI extensions**\n   - 출처: AI \u0026 Machine Learning\n   - 링크: https://cloud.google.com/blog/products/ai-machine-learning/automate-app-deployment-and-security-analysis-with-new-gemini-cli-extensions/\n\n\n\n**분석 지침:**\n- 반드시 위에 명시된 마크다운 헤더 구조를 정확히 따르세요\n- 각 섹션은 2-3개 포인트로 제한\n- 구체적인 수치와 데이터 활용으로 신뢰성 확보\n\n**🌟 URL 컨텍스트 활용 지침:**\n- 제공된 URL의 내용을 적극적으로 활용하여 깊이 있는 분석을 제공하세요\n- 단순 요약이 아닌, 기사의 핵심 인사이트와 숨겨진 의미를 발굴하세요\n- 여러 기사 간의 연결점을 찾아 큰 그림을 그려주세요\n- 기술적 세부사항과 실제 영향력을 균형있게 다루세요\n\n**🎯 독자 재미 극대화 지침:**\n- 딱딱한 기술 뉴스를 생동감 있게 전달하세요\n- 적절한 비유와 실생활 예시로 복잡한 개념을 쉽게 설명하세요\n- 놀라운 사실이나 의외의 관점을 제시하여 호기심을 자극하세요\n- 스토리텔링 요소를 활용하여 뉴스를 하나의 이야기로 엮어주세요\n- 각 프리셋의 톤에 맞는 위트와 유머를 적절히 활용하세요\n\n**🚨 인용 검수 체크리스트:**\n1. 본문의 모든 사실, 수치, 기업명, 기술명에 [^숫자] 인용이 있는가?\n2. 문서 맨 끝에 모든 footnote 정의가 있고, 각각 클릭 가능한 URL을 포함하는가?\n3. [^1]: 기사제목 - https://링크 형식이 정확한가?\n4. 본문에서 언급한 모든 [^숫자]에 대응하는 footnote가 있는가?\n- 최종 제출 전 필수 검토: 위 체크리스트를 모두 확인하세요",
  "articles": [
    {
      "title": "Your guide to GitHub Universe 2025: The schedule just launched!",
      "link": "https://github.blog/news-insights/company-news/your-guide-to-github-universe-2025-the-schedule-just-launched/",
      "source": "GitHub Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T20:52:28Z",
      "description": "\u003cp\u003eCreate your own agenda of favorites, sign up for one-on-on mentoring sessions, and register if you haven’t already. We’ll see you there!\u003c/p\u003e\n\u003cp\u003eThe post \u003ca href=\"https://github.blog/news-insights/company-news/your-guide-to-github-universe-2025-the-schedule-just-launched/\"\u003eYour guide to GitHub Universe 2025: The schedule just launched!\u003c/a\u003e appeared first on \u003ca href=\"https://github.blog\"\u003eThe GitHub Blog\u003c/a\u003e.\u003c/p\u003e\n"
    },
    {
      "title": "The latest AI news we announced in August",
      "link": "https://blog.google/technology/ai/google-ai-updates-august-2025/",
      "source": "Gemini",
      "category": "tech",
      "publishedAt": "2025-09-10T16:15:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/August_latest_AI_News.max-600x600.format-webp.webp\"\u003eHere are Google’s latest AI updates from August 2025"
    },
    {
      "title": "From Hallucinations to Prompt Injection: Securing AI Workflows at Runtime",
      "link": "https://www.docker.com/blog/secure-ai-agents-runtime-security/",
      "source": "Docker Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T13:00:00Z",
      "description": "How developers are embedding runtime security to safely build with AI agents Introduction: When AI Workflows Become Attack Surfaces The AI tools we use today are powerful, but also unpredictable and exploitable. You prompt an LLM and it generates a Dockerfile. It looks correct. A shell script? Reasonable. You run it in dev. Then something..."
    },
    {
      "title": "Jupyter Agents: training LLMs to reason with notebooks",
      "link": "https://huggingface.co/blog/jupyter-agent-2",
      "source": "Hugging Face - Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T00:00:00Z"
    },
    {
      "title": "미국 고등학생의 읽기 및 수학 점수 하락",
      "link": "https://news.hada.io/topic?id=23011",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-11T05:38:18+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e최근 발표된 \u003cstrong\u003eNAEP(미국 국가 교육 진단 평가)\u003c/strong\u003e 결과에 따르면, 고등학생들의 읽기와 \u003cstrong\u003e수학 능력이 20년 만에 최저 수준\u003c/strong\u003e으로 떨어졌음\u003c/li\u003e\n\u003cli\u003e이러한 하락은 \u003cstrong\u003e코로나19 팬데믹\u003c/strong\u003e의 영향도 있지만, 이미 10년 넘게 이어진 장기적 문제임\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e기초...\u003c/p\u003e"
    },
    {
      "title": "팀 전체가 전략적으로 치밀하게 생각하는 법 [번역글]",
      "link": "https://news.hada.io/topic?id=23010",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T23:23:22+09:00",
      "description": "\u003ch2\u003e1. \u003cstrong\u003e치밀한 사고란?\u003c/strong\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e전략적으로 중요한 질문을 던지고, 체계적으로 의사결정을 내리는 사고 방식입니다.[1]\u003c/li\u003e\n\u003cli\u003e아이디어를 즉시 실행하기보다 먼저 분해하고, 논리와 근거를 검증해 실수를 줄입니다.\u003c/li\u003e\n\u003cli\u003e조직 내 영향력과 팀원 주인의식, 기업가정신이 향상됩니다.\u003c/li\u003e\n...\u003c/p\u003e"
    },
    {
      "title": "LCD 화면 영역에 도달한 E-paper 디스플레이",
      "link": "https://news.hada.io/topic?id=23009",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T22:33:53+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003eE-paper 디스플레이\u003c/strong\u003e가 최근 \u003cstrong\u003eLCD 수준의 빠른 재생률\u003c/strong\u003e을 달성함\u003c/li\u003e\n\u003cli\u003e새로운 기술 발전 덕분에 \u003cstrong\u003ee-paper가 동영상 재생 등 다양한 용도\u003c/strong\u003e에 활용될 가능성 증가함\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e초저전력, 눈의 피로 감소\u003c/strong\u003e 같은 기존 e-paper의 장점이 유지됨...\u003c/p\u003e"
    },
    {
      "title": "트럼프와 결탁한 '투기판', 비트코인 시장의 시한폭탄",
      "link": "https://news.hada.io/topic?id=23007",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T13:19:56+09:00",
      "description": "\u003ch3\u003e암호화폐 시장의 근본적 취약성\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cstrong\u003e투자 기반의 취약성\u003c/strong\u003e: 비트코인 시장은 '가치 투자'에 기반한 근본적 분석이 부재하고, 오직 '기술적 분석'에 의존. 이는 시장의 본질적인 가치가 아닌 타인의 거래 행위를 추적하는 투기적 행태.\u003c/li\u003e\n\u003cli\u003e\n\u003cstrong\u003e자기지시적 가격 형성\u003c/strong\u003e: ...\u003c/p\u003e"
    },
    {
      "title": "Anthropic 사건 담당 판사, 15억 달러 AI 저작권 합의안에 대해 승인 보류",
      "link": "https://news.hada.io/topic?id=23006",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T10:56:17+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e미국 \u003cstrong\u003e연방법원 판사\u003c/strong\u003e가 Anthropic의 15억 달러 규모 \u003cstrong\u003eAI 저작권 집단소송 합의안\u003c/strong\u003e에 대해 \u003cstrong\u003e예비 승인을 보류\u003c/strong\u003e하기로 결정하고, \u003cstrong\u003e클레임 절차와 통지 방식\u003c/strong\u003e 등 핵심 설계를 추가로 제시할 것을 요구함\u003c/li\u003e\n\u003cli\u003e담당 판사는 합의가 \u003cstrong\u003e“완료...\u003c/p\u003e"
    },
    {
      "title": "Claude의 새로운 Code Interpreter 리뷰, 매우 혼란스러운 이름으로 출시",
      "link": "https://news.hada.io/topic?id=23005",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T10:54:01+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003eAnthropic의 \u003cstrong\u003e“Upgraded file creation and analysis”\u003c/strong\u003e 기능을 실제로 사용해본 결과를 바탕으로, \u003cstrong\u003e코드 실행형 분석 도구\u003c/strong\u003e로서의 성격을 짚는 리뷰 by \u003cstrong\u003eSimon Willison\u003c/strong\u003e\n\u003c/li\u003e\n\u003cli\u003e이 신규 기능은 \u003cstrong\u003e서버 사이드 컨테이너에서 Python·Node.js 코드 실행...\u003c/p\u003e"
    },
    {
      "title": "Claude, 이제 직접 파일을 생성하고 편집할 수 있음",
      "link": "https://news.hada.io/topic?id=23004",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T10:08:10+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003eClaude는 이제 \u003cstrong\u003eExcel 스프레드시트, 문서, PowerPoint, PDF\u003c/strong\u003e를 직접 생성·편집할 수 있으며, 단순 텍스트 응답을 넘어 \u003cstrong\u003e실제 작업 산출물\u003c/strong\u003e을 만들어 제공함\u003c/li\u003e\n\u003cli\u003e이를 통해 \u003cstrong\u003e데이터 분석·재무 모델링·프로젝트 관리 대시보드·예산 추적\u003c/strong\u003e 등 고급 업무를 대화...\u003c/p\u003e"
    },
    {
      "title": "ICE가 가짜 셀 타워로 휴대폰을 감시함",
      "link": "https://news.hada.io/topic?id=23002",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T10:02:07+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e미국 \u003cstrong\u003eICE(Immigration and Customs Enforcement)\u003c/strong\u003e 가 가짜 셀 타워(스팅레이) 기술을 활용해 \u003cstrong\u003e불법 체류자 추적\u003c/strong\u003e 작업을 수행함\u003c/li\u003e\n\u003cli\u003e스팅레이는 휴대폰을 속여 가짜 기지국에 연결시키고 \u003cstrong\u003e휴대폰 위치를 정확히 탐지\u003c/strong\u003e하는 장비임\u003c/li\u003e\n\u003cli\u003e이 방법은 대상자...\u003c/p\u003e"
    },
    {
      "title": "우리는 정말 큰 위협을 피했음",
      "link": "https://news.hada.io/topic?id=23001",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T09:59:06+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e최근 \u003cstrong\u003eNPM 패키지 생태계\u003c/strong\u003e에서 발생한 공급망 공격이 실제로는 더 큰 피해를 야기할 수 있었음\u003c/li\u003e\n\u003cli\u003e공격자는 인기 있는 라이브러리를 악용해 \u003cstrong\u003e암호화폐 지갑 주소를 변경\u003c/strong\u003e하는 방향으로만 악성코드를 사용함\u003c/li\u003e\n\u003cli\u003e이 공격은 \u003cstrong\u003e정교한 피싱 이메일\u003c/strong\u003e을 통해...\u003c/p\u003e"
    },
    {
      "title": "애드블로커가 감지되지 않습니다",
      "link": "https://news.hada.io/topic?id=23000",
      "source": "GeekNews",
      "category": "tech",
      "publishedAt": "2025-09-10T09:56:04+09:00",
      "description": "\u003cul\u003e\n\u003cli\u003e이 블로그는 \u003cstrong\u003e광고 차단 기능이 감지되지 않을 때\u003c/strong\u003e, 방문자에게 uBlock Origin 같은 \u003cstrong\u003e신뢰할 수 있는 광고 차단기\u003c/strong\u003e를 설치하도록 권장함\u003c/li\u003e\n\u003cli\u003e이 권장 메시지는 \u003cstrong\u003e사용자 경험을 방해하지 않도록\u003c/strong\u003e 설계되었고, 한 번 닫으면 다시 나타나지 않음\u003c/li\u003e\n\u003cli\u003e구현...\u003c/p\u003e"
    },
    {
      "title": "Bitbucket Cloud enters phase two of app password deprecation",
      "link": "https://www.atlassian.com/blog/bitbucket/bitbucket-cloud-enters-phase-2-of-app-password-deprecation",
      "source": "Atlassian Developer Blog",
      "category": "tech",
      "publishedAt": "2025-09-09T23:52:16Z",
      "description": "\u003cp\u003eSecurity in the developer ecosystem is constantly evolving, and we’re committed to ensuring Bitbucket Cloud continues to provide safe, modern,...\u003c/p\u003e\n\u003cp\u003eThe post \u003ca href=\"https://www.atlassian.com/blog/bitbucket/bitbucket-cloud-enters-phase-2-of-app-password-deprecation\"\u003eBitbucket Cloud enters phase two of app password deprecation\u003c/a\u003e appeared first on \u003ca href=\"https://www.atlassian.com/blog\"\u003eWork Life by Atlassian\u003c/a\u003e.\u003c/p\u003e\n"
    },
    {
      "title": "The latest AI news we announced in August",
      "link": "https://blog.google/technology/ai/google-ai-updates-august-2025/",
      "source": "Google DeepMind",
      "category": "tech",
      "publishedAt": "2025-09-10T16:15:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/August_latest_AI_News.max-600x600.format-webp.webp\"\u003eHere are Google’s latest AI updates from August 2025"
    },
    {
      "title": "Chrome Beta for iOS Update",
      "link": "http://chromereleases.googleblog.com/2025/09/chrome-beta-for-ios-update_10.html",
      "source": "Google Chrome Releases",
      "category": "tech",
      "publishedAt": "2025-09-10T07:28:00.001-07:00",
      "description": "\u003cp\u003eHi everyone! We've just released Chrome Beta 141 (141.0.7390.14) for iOS; it'll become available on App Store in the next few days.\u003c/p\u003e\u003cp\u003eYou can see a partial list of the changes in the \u003ca href=\"https://chromium.googlesource.com/chromium/src/+log/141.0.7390.4..141.0.7390.14?pretty=fuller\u0026amp;n=10000\"\u003eGit log\u003c/a\u003e. If you find a new issue, please let us know by \u003ca href=\"https://code.google.com/p/chromium/issues/entry?template=iOS%20Issue\"\u003efiling a bug\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eChrome Release Team\u003cbr /\u003e\u003ca href=\"https://www.google.com/chrome\"\u003e\u003c/a\u003e\u003ca href=\"https://www.google.com/chrome\"\u003eGoogle Chrome\u003c/a\u003e\u003c/p\u003e"
    },
    {
      "title": "Chrome Beta for Android Update",
      "link": "http://chromereleases.googleblog.com/2025/09/chrome-beta-for-android-update_10.html",
      "source": "Google Chrome Releases",
      "category": "tech",
      "publishedAt": "2025-09-10T06:43:00.001-07:00",
      "description": "\u003cp\u003eHi everyone! We've just released Chrome Beta 141 (141.0.7390.17) for Android. It's now available on \u003ca href=\"https://play.google.com/store/apps/details?id=com.chrome.beta\"\u003eGoogle Play\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eYou can see a partial list of the changes in the \u003ca href=\"https://chromium.googlesource.com/chromium/src/+log/141.0.7390.5..141.0.7390.17?pretty=fuller\u0026amp;n=10000\"\u003eGit log\u003c/a\u003e. For details on new features, check out the \u003ca href=\"https://blog.chromium.org\"\u003eChromium blog\u003c/a\u003e, and for details on web platform updates, check \u003ca href=\"https://www.chromestatus.com/features#milestone%3D141\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you find a new issue, please let us know by \u003ca href=\"https://code.google.com/p/chromium/issues/entry?template=Android%20Issue\"\u003efiling a bug\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eChrome Release Team\u003cbr /\u003e\u003ca href=\"https://www.google.com/chrome\"\u003e\u003c/a\u003e\u003ca href=\"https://www.google.com/chrome\"\u003eGoogle Chrome\u003c/a\u003e\u003c/p\u003e"
    },
    {
      "title": "The latest AI news we announced in August",
      "link": "https://blog.google/technology/ai/google-ai-updates-august-2025/",
      "source": "AI",
      "category": "tech",
      "publishedAt": "2025-09-10T16:15:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/August_latest_AI_News.max-600x600.format-webp.webp\"\u003eHere are Google’s latest AI updates from August 2025"
    },
    {
      "title": "The latest AI news we announced in August",
      "link": "https://blog.google/technology/ai/google-ai-updates-august-2025/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T16:15:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/August_latest_AI_News.max-600x600.format-webp.webp\"\u003eHere are Google’s latest AI updates from August 2025"
    },
    {
      "title": "Get greater control and smarter optimization with AI Max as it expands globally.",
      "link": "https://blog.google/products/ads-commerce/google-ai-max-expands-globally/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AIMax_SocialShare.max-600x600.format-webp.webp\"\u003eAll advertisers globally can now use AI Max for Search campaigns, a one-click solution that brings the best of Google AI into your Search campaigns. It's now available i…"
    },
    {
      "title": "How leading retailers and brands are using Google Ads to win and retain customers",
      "link": "https://blog.google/products/ads-commerce/leading-retailers-brands-use-google-ads/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/LeadingRetailer_Hero.max-600x600.format-webp.webp\"\u003eA look at how innovative retailers are using Google Ads to win and retain customers."
    },
    {
      "title": "New ways to win over today’s consumer this holiday season",
      "link": "https://blog.google/products/ads-commerce/new-ways-retailers-can-win-over-strategic-consumers/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ThinkRetail_Hero.max-600x600.format-webp.webp\"\u003eAn overview of how retailers can turn strategic consumers into customers."
    },
    {
      "title": "Think Week 2025",
      "link": "https://blog.google/products/ads-commerce/think-retail-2025/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ThinkWeek_CollectionHeader.max-600x600.format-webp.webp\"\u003eAt Think Retail 2025, we shared our next-gen AI-powered solutions to help retailers connect with their customers."
    },
    {
      "title": "Generate and scale creative assets with Google AI in Asset Studio",
      "link": "https://blog.google/products/ads-commerce/generate-creative-assets-google-ai-asset-studio/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T16:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GenerateThink_Social.max-600x600.format-webp.webp\"\u003eBring your creative vision to life with Asset Studio, Google Ads’ one-stop-shop for creative tools and AI-powered assets."
    },
    {
      "title": "Google is fighting water leaks in Belgium.",
      "link": "https://blog.google/outreach-initiatives/sustainability/google-is-fighting-water-leaks-in-belgium/",
      "source": "The Official Google Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T04:00:00Z",
      "description": "\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/image_7_dHwLXVL.max-600x600.format-webp.webp\"\u003eUsing technology to identify and address leaks means less water waste, lower costs for universities, schools and public buildings and a more sustainable future in our da…"
    },
    {
      "title": "The 4p Developer: The Missing Layer in Platform Thinking",
      "link": "https://www.davidpoll.com/2025/09/the-4p-developer-the-missing-layer-in-platform-thinking/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T22:04:48Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.davidpoll.com/2025/09/the-4p-developer-the-missing-layer-in-platform-thinking/\"\u003ehttps://www.davidpoll.com/2025/09/the-4p-developer-the-missing-layer-in-platform-thinking/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204616\"\u003ehttps://news.ycombinator.com/item?id=45204616\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "You're a Slow Thinker. Now What?",
      "link": "https://chillphysicsenjoyer.substack.com/p/youre-a-slow-thinker-now-what",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T22:01:45Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://chillphysicsenjoyer.substack.com/p/youre-a-slow-thinker-now-what\"\u003ehttps://chillphysicsenjoyer.substack.com/p/youre-a-slow-thinker-now-what\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204587\"\u003ehttps://news.ycombinator.com/item?id=45204587\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Phospholipid head govern area per lipid and emergent elasticity of bilayer(2018)",
      "link": "https://www.cell.com/biophysj/fulltext/S0006-3495(22)00733-0#",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T22:01:34Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.cell.com/biophysj/fulltext/S0006-3495(22)00733-0#\"\u003ehttps://www.cell.com/biophysj/fulltext/S0006-3495(22)00733-0#\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204585\"\u003ehttps://news.ycombinator.com/item?id=45204585\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "AI School Is in Session",
      "link": "https://www.nytimes.com/2025/09/05/podcasts/hardfork-education-alpha-school.html",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T22:01:23Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.nytimes.com/2025/09/05/podcasts/hardfork-education-alpha-school.html\"\u003ehttps://www.nytimes.com/2025/09/05/podcasts/hardfork-education-alpha-school.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204580\"\u003ehttps://news.ycombinator.com/item?id=45204580\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "Rpsduel.com – Live Rock Paper Scissors with Instant ELO Matchmaking",
      "link": "https://rpsduel.com/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T22:00:28Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://rpsduel.com/\"\u003ehttps://rpsduel.com/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204567\"\u003ehttps://news.ycombinator.com/item?id=45204567\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "Conservative activist Charlie Kirk killed in shooting on Utah campus",
      "link": "https://www.cnn.com/us/live-news/charlie-kirk-shot-utah-09-10-25",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:54:09Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.cnn.com/us/live-news/charlie-kirk-shot-utah-09-10-25\"\u003ehttps://www.cnn.com/us/live-news/charlie-kirk-shot-utah-09-10-25\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204469\"\u003ehttps://news.ycombinator.com/item?id=45204469\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 4\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "DNA cassette tape can store every song ever recorded",
      "link": "https://www.newscientist.com/article/2495758-dna-cassette-tape-can-store-every-song-ever-recorded/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:54:00Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.newscientist.com/article/2495758-dna-cassette-tape-can-store-every-song-ever-recorded/\"\u003ehttps://www.newscientist.com/article/2495758-dna-cassette-tape-can-store-every-song-ever-recorded/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204466\"\u003ehttps://news.ycombinator.com/item?id=45204466\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Steve Hayden, Writer Behind Apple's Pivotal '1984' Commercial, Dies at 78",
      "link": "https://www.nytimes.com/2025/09/04/business/media/steve-hayden-dead.html",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:52:50Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.nytimes.com/2025/09/04/business/media/steve-hayden-dead.html\"\u003ehttps://www.nytimes.com/2025/09/04/business/media/steve-hayden-dead.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204443\"\u003ehttps://news.ycombinator.com/item?id=45204443\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 3\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "KDE launches its own distribution (again)",
      "link": "https://lwn.net/SubscriberLink/1037166/caa6979c16a99c9e/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:49:36Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://lwn.net/SubscriberLink/1037166/caa6979c16a99c9e/\"\u003ehttps://lwn.net/SubscriberLink/1037166/caa6979c16a99c9e/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204393\"\u003ehttps://news.ycombinator.com/item?id=45204393\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 3\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Defining Deviancy Up",
      "link": "https://scottsumner.substack.com/p/less-wrong",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:46:53Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://scottsumner.substack.com/p/less-wrong\"\u003ehttps://scottsumner.substack.com/p/less-wrong\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204354\"\u003ehttps://news.ycombinator.com/item?id=45204354\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "Christie's Deletes Digital Art Department",
      "link": "https://news.artnet.com/market/christies-scraps-digital-art-department-2685784",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:43:47Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://news.artnet.com/market/christies-scraps-digital-art-department-2685784\"\u003ehttps://news.artnet.com/market/christies-scraps-digital-art-department-2685784\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204305\"\u003ehttps://news.ycombinator.com/item?id=45204305\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "We Built a Vehicle History Report from Scratch",
      "link": "https://cardog.app/blog/reports-launch",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:42:25Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://cardog.app/blog/reports-launch\"\u003ehttps://cardog.app/blog/reports-launch\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204284\"\u003ehttps://news.ycombinator.com/item?id=45204284\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "US warns hidden radios may be embedded in solar-powered highway infrastructure",
      "link": "https://www.reuters.com/legal/government/us-warns-hidden-radios-may-be-embedded-solar-powered-highway-infrastructure-2025-09-10/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:41:04Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.reuters.com/legal/government/us-warns-hidden-radios-may-be-embedded-solar-powered-highway-infrastructure-2025-09-10/\"\u003ehttps://www.reuters.com/legal/government/us-warns-hidden-radios-may-be-embedded-solar-powered-highway-infrastructure-2025-09-10/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204260\"\u003ehttps://news.ycombinator.com/item?id=45204260\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 7\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "AI Is Coming for YouTube Creators",
      "link": "https://www.theatlantic.com/technology/archive/2025/09/youtube-ai-training-data-sets/684116/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:39:41Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.theatlantic.com/technology/archive/2025/09/youtube-ai-training-data-sets/684116/\"\u003ehttps://www.theatlantic.com/technology/archive/2025/09/youtube-ai-training-data-sets/684116/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204238\"\u003ehttps://news.ycombinator.com/item?id=45204238\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Show HN: SigNull – a to-do app that separates Signal from Noise",
      "link": "https://signull.app/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:38:28Z",
      "description": "\n\u003cp\u003eHi HN,\u003cp\u003eI’ve been struggling with productivity tools for years. Most of them help me collect more tasks, but very few help me figure out which tasks actually matter. I kept finding myself busy all day, yet not making real progress.\u003cp\u003eI borrowed a concept from engineering: Signal vs. Noise.\n • Signal tasks: high-impact, goal-driven work.\n • Noise tasks: necessary, but low-leverage (emails, reports, admin).\u003cp\u003eSo I built SigNull, a minimal to-do app that enforces this distinction:\n • New tasks go into an Inbox, where I classify them as Signal or Noise.\n • Each morning it surfaces a Top-3 Signal list to focus on first.\n • It gives me a Noise Budget (e.g., 45 minutes/day). Once that’s used, I have to either Defer the task or Justify why it’s worth extra time.\n • At the end of the day, it shows my Signal-to-Noise Ratio (SNR) so I can see if I spent my time on what really mattered.\u003cp\u003eIt’s web-based, simple, and still pretty early. I’m looking for feedback:\n • Does the Signal/Noise distinction resonate with you?\n • Is the Noise Budget too rigid, or a useful forcing function?\n • Where might this approach fall apart in real-world workflows?\u003cp\u003eYou can try it here: signull.app\u003cp\u003eThanks!\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204222\"\u003ehttps://news.ycombinator.com/item?id=45204222\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Vaccine to curb chlamydia epidemic devastating koalas approved",
      "link": "https://www.bbc.com/news/articles/cwylp71vnjgo",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:38:25Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.bbc.com/news/articles/cwylp71vnjgo\"\u003ehttps://www.bbc.com/news/articles/cwylp71vnjgo\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204221\"\u003ehttps://news.ycombinator.com/item?id=45204221\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 5\u003c/p\u003e\n\u003cp\u003e# Comments: 1\u003c/p\u003e\n"
    },
    {
      "title": "Back from Chaos (1998)",
      "link": "https://www.theatlantic.com/magazine/archive/1998/03/back-from-chaos/308700/",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:38:12Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.theatlantic.com/magazine/archive/1998/03/back-from-chaos/308700/\"\u003ehttps://www.theatlantic.com/magazine/archive/1998/03/back-from-chaos/308700/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204217\"\u003ehttps://news.ycombinator.com/item?id=45204217\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Ask HN: Would you use a CAPTCHA that blocks browser agents?",
      "link": "https://news.ycombinator.com/item?id=45204185",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:37:00Z",
      "description": "\n\u003cp\u003eAssuming it works, would you consider using it on your site or app? Why or why not? What factors would influence your decision?\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204185\"\u003ehttps://news.ycombinator.com/item?id=45204185\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 2\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Exploring Canton: a privacy-preserving distributed ledger for finance",
      "link": "https://quant.engineering/canton-distributed-ledger.html",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:36:30Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://quant.engineering/canton-distributed-ledger.html\"\u003ehttps://quant.engineering/canton-distributed-ledger.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204174\"\u003ehttps://news.ycombinator.com/item?id=45204174\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 0\u003c/p\u003e\n"
    },
    {
      "title": "Atlassian says its 'Don't F– the Customer' principle drove cloud-only decision",
      "link": "https://www.computerworld.com/article/4054807/atlassian-says-its-dont-f-the-customer-principle-drove-cloud-only-decision.html",
      "source": "Hacker News",
      "category": "tech",
      "publishedAt": "2025-09-10T21:36:02Z",
      "description": "\n\u003cp\u003eArticle URL: \u003ca href=\"https://www.computerworld.com/article/4054807/atlassian-says-its-dont-f-the-customer-principle-drove-cloud-only-decision.html\"\u003ehttps://www.computerworld.com/article/4054807/atlassian-says-its-dont-f-the-customer-principle-drove-cloud-only-decision.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eComments URL: \u003ca href=\"https://news.ycombinator.com/item?id=45204168\"\u003ehttps://news.ycombinator.com/item?id=45204168\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePoints: 1\u003c/p\u003e\n\u003cp\u003e# Comments: 2\u003c/p\u003e\n"
    },
    {
      "title": "Stability AI Introduces Stable Audio 2.5, the First Audio Model Built for Enterprise Sound Production at Scale",
      "link": "https://stability.ai/news/stability-ai-introduces-stable-audio-25-the-first-audio-model-built-for-enterprise-sound-production-at-scale",
      "source": "News - Stability AI",
      "category": "tech",
      "publishedAt": "2025-09-10T14:07:07Z",
      "description": "We’re excited to release Stable Audio 2.5, our latest audio model and the \nfirst developed for enterprise-grade use cases. Stable Audio 2.5 introduces \nadvancements in quality and control that address the demand for dynamic \ncompositions that can be adapted for custom brand needs."
    },
    {
      "title": "Paint It Blackwell: GeForce RTX 5080 SuperPOD Rollout Begins",
      "link": "https://blogs.nvidia.com/blog/geforce-now-thursday-blackwell-rtx-launch/",
      "source": "NVIDIA Blog",
      "category": "tech",
      "publishedAt": "2025-09-10T13:00:06Z",
      "description": "GeForce NOW Blackwell RTX 5080-class SuperPODs are now rolling out, unlocking a new level of ultra high-performance, cinematic cloud gaming. GeForce NOW Ultimate members will see GeForce RTX 5080 performance arriving to a server near them, enabling even richer experiences in blockbuster titles like DUNE: Awakening, Borderlands 4, Hell Is Us, Dying Light: The Beast,\t\u003ca class=\"read-more\" href=\"https://blogs.nvidia.com/blog/geforce-now-thursday-blackwell-rtx-launch/\"\u003e\n\t\tRead Article\t\t\u003cspan data-icon=\"y\"\u003e\u003c/span\u003e\n\t\u003c/a\u003e\n\t"
    },
    {
      "title": "Scaling high-performance inference cost-effectively",
      "link": "https://cloud.google.com/blog/products/ai-machine-learning/gke-inference-gateway-and-quickstart-are-ga/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-09-10T17:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAt Google Cloud Next 2025, we announced \u003c/span\u003e\u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/understanding-new-gke-inference-capabilities?e=48754805\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003enew inference capabilities\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e with \u003c/span\u003e\u003ca href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGKE Inference Gateway\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, including support for vLLM on TPUs, \u003c/span\u003e\u003ca href=\"https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eIronwood TPUs\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, and Anywhere Cache. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOur inference solution is based on \u003c/span\u003e\u003ca href=\"https://cloud.google.com/solutions/ai-hypercomputer\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eAI Hypercomputer\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, a system built on our experience running models like Gemini and Veo 3, which serve over 980 trillion tokens a month to more than 450 million users. AI Hypercomputer services provide intelligent and optimized inferencing, including resource management, workload optimization and routing, and advanced storage for scale and performance, all co-designed to work together with industry leading GPU and TPU accelerators. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_xN8hT4E.max-1000x1000.png\"\n        \n          alt=\"1\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eToday, GKE Inference Gateway is generally available, and we are launching new capabilities that deliver even more value. This underscores our commitment to helping companies deliver more intelligence, with increased performance and optimized costs for both training and serving. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_x9nbvDh.max-1000x1000.png\"\n        \n          alt=\"2\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eLet’s take a look at the new capabilities we are announcing.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eEfficient model serving and load balancing\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eA user’s experience of a generative AI application highly depends on both a fast initial response to a request and a smooth streaming of the response through to completion. With these new features, we’ve improved time-to-first-token (TTFT) and time-per-output-token (TPOT) on AI Hypercomputer. TTFT is based on the prefill phase, a compute-bound process where a full pass through the model creates a key-value (KV) cache. TPOT is based on the decode phase, a memory-bound process where tokens are generated using the KV cache from the prefill stage. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWe improve both of these in a variety of ways. Generative AI applications like chatbots and code generation often reuse the same prefix in API calls. To optimize for this, GKE Inference Gateway\u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e now offers prefix-aware load balancing\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. This new, generally available feature improves TTFT latency by up to 96% at peak throughput for prefix-heavy workloads over other clouds by intelligently routing requests with the same prefix to the same accelerators, while balancing the load to prevent hotspots and latency spikes. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_peupLyO.max-1000x1000.png\"\n        \n          alt=\"3\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eConsider a chatbot for a financial services company that helps users with account inquiries. A user starts a conversation to ask about a recent credit card transaction. Without prefix-aware routing, when the user asks follow up questions, such as the date of the charge or the confirmation number, the LLM has to re-read and re-process the entire initial query before it can answer the follow up question. The re-computation of the prefill phase is very inefficient and adds unnecessary latency, with the user experiencing delays between each question. With prefix-aware routing, the system intelligently reuses the data from the initial query by routing the request back to the same KV cache. This bypasses the prefill phase, allowing the model to answer almost instantly. Less computation also means fewer accelerators for the same workload, providing significant cost savings.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTo further optimize inference performance, you can now also run \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003edisaggregated serving\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e using AI Hypercomputer, which can improve throughput by 60%. Enhancements in GKE Inference Gateway, llm-d, and vLLM, work together to enable dynamic selection of prefill and decode nodes based on query size. This significantly improves both TTFT and TPOT by increasing the utilization of compute and memory resources at scale.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTake an example of an AI-based code completion application, which needs to provide low-latency responses to maintain interactivity. When a developer submits a completion request, the application must first process the input codebase; this is referred to as the prefill phase. Next, the application generates a code suggestion token by token; this is referred to as the decode phase. These tasks have dramatically different demands on accelerator resources — compute-intensive vs. memory-intensive processing. Running both phases on a single node results in neither being fully optimized, causing higher latency and poor response times. Disaggregated serving assigns these phases to separate nodes, allowing for independent scaling and optimization of each phase. For example, if the user base of developers submit a lot of requests based on large codebases, you can scale the prefill nodes. This improves latency and throughput, making the entire system more efficient.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eJust as prefix-aware routing optimizes the reuse of conversational context, and disaggregated serving enhances performance by intelligently separating the computational demands of model prefill and token decoding, we have also addressed the fundamental challenge of getting these massive models running in the first place. As generative AI models grow to hundreds of gigabytes in size, they can often take over ten minutes to load, leading to slow startup and scaling. To solve this, we now support the \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRun:ai model streamer with Google Cloud Storage and Anywhere Cache for vLLM\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, with support for SGLang coming soon. This enables 5.4 GiB/s of direct throughput to accelerator memory, reducing model load times by over 4.9x, resulting in a better end user experience.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_r7rSh3L.max-1000x1000.png\"\n        \n          alt=\"4\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"120vc\"\u003evLLM Model Load Time\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eGet started faster with data-driven decisions\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eFinding the ideal technology stack for serving AI models is a significant industry challenge. Historically, customers have had to navigate rapidly evolving technologies, the switching costs that impact hardware choices, and hundreds of thousands of possible deployment architectures. This inherent complexity makes it difficult to quickly achieve the best price-performance for your inference environment.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe \u003c/span\u003e\u003ca href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGKE Inference Quickstart\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, now generally available, can save you time, improve performance, and reduce costs when deploying AI workloads by helping determine the right accelerator for your workloads in the right configuration, suggesting the best accelerators, model server, and scaling configuration for your AI/ML inference applications. New improvements to GKE Inference Quickstart include cost insights and benchmarked performance best practices, so you can easily compare costs and understand latency profiles, saving you months on evaluation and qualification. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eGKE Inference Quickstart’s recommendations are grounded in a living repository of model and accelerator performance data that we generate by benchmarking our GPU and TPU accelerators against leading large language models like Llama, Mixtral, and Gemma more than 100 times per week. This extensive performance data is then enriched with the same storage, network, and software optimizations that power AI inferencing on Google’s \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eglobal-scale services like Gemini, Search, and YouTube\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eLet’s say you’re tasked with deploying a new, public-facing chatbot. The goal is to provide fast, high-quality responses at the lowest cost. Until now, finding the most optimal and cost-effective solution for deploying AI models was a significant challenge. Developers and engineers had to rely on a painstaking process of trial and error. This involved manually benchmarking countless combinations of different models, accelerators, and serving architectures, with all the data logged into a spreadsheet to calculate the cost per query for each scenario. This manual, weeks-long, or even months-long, project was prone to human error and offered no guarantee that the best possible solution was ever found.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eUsing Google Colab and the built-in optimizations in the Google Cloud console, GKE Inference Quickstart lets you choose the most cost-effective accelerators for, say, serving a Llama 3-based chatbot application that needs a TTFT of less than 500ms. These recommendations are deployable manifests, making it easy to choose a technology stack that you can provision from GKE in your Google Cloud environment. With GKE Inference Quickstart, your evaluation and qualification effort has gone from months to days.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_ZJMuHsY.max-1000x1000.png\"\n        \n          alt=\"5\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_nLrGCdL.max-1000x1000.png\"\n        \n          alt=\"6\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"120vc\"\u003eViews from the \u003ca href=\"http://goto.google.com/giq-colab\"\u003eGoogle Colab\u003c/a\u003e that helps the engineer with their evaluation.\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eTry these new capabilities for yourself. \u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTo get started with \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eGKE\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eInference QuickStart\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, from the \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eGoogle Cloud console\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, go to Kubernetes Engine \u0026gt; AI/ML, and select “+ Deploy Models” near the top of the screen. Use the Filter to select Optimized \u0026gt; Values = True. This will show you all of the models that have price/performance optimization to select from. Once you select a model, you’ll see a sliding bar to select latency. The compatible accelerators from the drop-down will change to ones that match the performance of the latency you are selecting. You will notice that the cost/million output token will also change based on your selections.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/7_XBrZ58A.max-1000x1000.png\"\n        \n          alt=\"7\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThen, via \u003c/span\u003e\u003ca href=\"http://goto.google.com/giq-colab\" rel=\"noopener\" target=\"_blank\"\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGoogle Cola\u003c/strong\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eb\u003c/strong\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, you can plot and view the price/performance of leading AI models on Google Cloud. \u003c/span\u003e\u003ca href=\"https://lmarena.ai/leaderboard\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eChatbot Arena\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e ratings are integrated to help you determine the best model for your needs based on model size, rating, and price per million tokens. You can also pull in your organization’s in-house quality measures into the colab to join with Google’s comprehensive benchmarks to make data-driven decisions. \u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDedicated to optimizing inference\u003c/span\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAt Google Cloud, we are committed to helping companies deploy and improve their AI inference workloads at scale. Our focus is on providing a comprehensive platform that delivers unmatched performance and cost-efficiency for serving large language models and other generative AI applications. By leveraging a codesigned stack of industry-leading hardware and software innovations — including the AI Hypercomputer, GKE Inference Gateway, and purpose-built optimizations like prefix-aware routing, disaggregated serving, and model streaming — we ensure that businesses can deliver more intelligence with faster, more responsive user experiences and lower total cost of ownership. Our solutions are designed to address the unique challenges of inference, from model loading times to resource utilization, enabling you to deliver on the promise of generative AI. To learn more and get started, visit our \u003c/span\u003e\u003ca href=\"https://cloud.google.com/solutions/ai-hypercomputer?e=48754805\u0026amp;hl=en\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eAI Hypercomputer\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e site. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e"
    },
    {
      "title": "Fast and efficient AI inference with new NVIDIA Dynamo recipe on AI Hypercomputer",
      "link": "https://cloud.google.com/blog/products/compute/ai-inference-recipe-using-nvidia-dynamo-with-ai-hypercomputer/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-09-10T17:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAs generative AI becomes more widespread, it’s important for developers and ML engineers to be able to easily configure infrastructure that supports efficient AI inference, i.e., using a trained AI model to make predictions or decisions based on new, unseen data. While great at training models, traditional GPU-based serving architectures struggle with the \"multi-turn\" nature of inference, characterized by back-and-forth conversations where the model must maintain context and understand user intent. Further, deploying large generative AI models can be both complex and resource-intensive.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAt Google Cloud, we’re committed to providing customers with the best choices for their AI needs. That's why we are excited to announce a new recipe for disaggregated inferencing with \u003c/span\u003e\u003ca href=\"https://www.nvidia.com/en-us/ai/dynamo/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eNVIDIA Dynamo\u003c/strong\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, a high-performance, low-latency platform for a variety of AI models. Disaggregated inference separates out model processing phases, offering a significant leap in performance and cost-efficiency.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eSpecifically, this recipe makes it easy to deploy NVIDIA Dynamo on Google Cloud’s \u003c/span\u003e\u003ca href=\"https://cloud.google.com/solutions/ai-hypercomputer\"\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eAI Hypercomputer\u003c/strong\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, including Google Kubernetes Engine (GKE), vLLM inference engine, and A3 Ultra GPU-accelerated instances powered by NVIDIA H200 GPUs. By running the recipe on Google Cloud, you can achieve higher performance and greater inference efficiency while meeting your AI applications’ latency requirements. You can find this recipe, along with other resources, in our growing \u003c/span\u003e\u003ca href=\"https://github.com/ai-hypercomputer\" rel=\"noopener\" target=\"_blank\"\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eAI Hypercomputer resources repository\u003c/strong\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e on GitHub. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eLet’s take a look at how to deploy it.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eThe two phases of inference\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eLLM inference is not a monolithic task; it's a tale of two distinct computational phases. First is the \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eprefill\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e (or context) phase, where the input prompt is processed. Because this stage is compute-bound, it benefits from access to massive parallel processing power. Following prefill is the \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003edecode\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e (or generation) phase, which generates a response, token by token, in an autoregressive loop. This stage is bound by memory bandwidth, requiring extremely fast access to the model's weights and the KV cache. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIn traditional architectures, these two phases run on the same GPU, creating resource contention. A long, compute-heavy prefill can block the rapid, iterative decode steps, leading to poor GPU utilization, higher inference costs, and increased latency for all users.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-aside\"\u003e\u003cdl\u003e\n    \u003cdt\u003easide_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;title\u0026#x27;, \u0026#x27;Try Google Cloud for free\u0026#x27;), (\u0026#x27;body\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3e18bf4829d0\u0026gt;), (\u0026#x27;btn_text\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;href\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;image\u0026#x27;, None)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eA specialized, disaggregated inference architecture\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOur new solution tackles this challenge head-on by disaggregating, or physically separating, the prefill and decode stages across distinct, independently managed GPU pools.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eHere’s how the components work in concert:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eA3 Ultra instances and GKE:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e The recipe uses GKE to orchestrate separate node pools of A3 Ultra instances, powered by NVIDIA H200 GPUs. This creates specialized resource pools — one optimized for compute-heavy prefill tasks and another for memory-bound decode tasks.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003ca href=\"https://www.nvidia.com/en-us/ai/dynamo/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eNVIDIA Dynamo\u003c/strong\u003e\u003c/a\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e Acting as the inference server, NVIDIA Dynamo's modular front end and KV cache-aware router processes incoming requests. It then pairs GPUs from the prefill and decode GKE node pools and orchestrates workload execution between them, transferring the KV cache that’s generated in the prefill pool to the decode pool to begin token generation.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003evLLM:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e Running on pods within each GKE pool, the vLLM inference engine helps ensure best-in-class performance for the actual computation, using innovations like PagedAttention to maximize throughput on each individual node.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis disaggregated approach allows each phase to scale independently based on real-time demand, helping to ensure that compute-intensive prompt processing doesn’t interfere with fast token generation. Dynamo supports popular inference engines including SGLang, TensorRT-LLM and vLLM. The result is a dramatic boost in overall throughput and maximized utilization of every GPU.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_lTFF8Zu.max-1000x1000.png\"\n        \n          alt=\"1\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eExperiment with Dynamo Recipes for Google Cloud\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe \u003c/span\u003e\u003ca href=\"https://github.com/AI-Hypercomputer/gpu-recipes/tree/main/inference/a3ultra/disaggregated-serving/dynamo\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ereproducible recipe\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e shows the steps to deploy disaggregated inference with NVIDIA Dynamo on the A3 Ultra (H200) VMs on Google Cloud using GKE for orchestration and vLLM as the inference engine. The single node recipe demonstrates disaggregated inference with one node of A3 Ultra using four GPUs for prefill and four GPUs for decode. The multi-node recipe demonstrates disaggregated inference with one node of A3 Ultra for prefill and one node of A3 Ultra for decode for the Llama-3.3-70B-Instruct Model.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eFuture recipes will provide support for additional NVIDIA GPUs (e.g. A4, A4X) and inference engines with expanded coverage of models. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe recipe highlights the following key steps: \u003c/span\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: decimal; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003ePerform initial setup - This sets up environment variables and secrets; this needs to be done one-time only. \u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: decimal; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eInstall Dynamo Platform and CRDs - This sets up the various Dynamo Kubernetes components; this needs to be done one-time only.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: decimal; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eDeploy inference backend for a specific model workload - This deploys vLLM/SGLang as the inference backend for Dynamo disaggregated inference for a specific model workload. Repeat this step for every new model inference workload deployment.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: decimal; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eProcess inference requests - Once the model is deployed for inference, incoming queries are processed to provide responses to users.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eOnce the server is up, you will see the prefill and decode workers along with the frontend pod which acts as the primary interface to serve the requests.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_JsYfFJV.max-1000x1000.png\"\n        \n          alt=\"2\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWe can verify if everything works as intended by sending a request to the server like this. The response is generated and truncated to max_tokens.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;curl -s localhost:8000/v1/chat/completions \\\\\\r\\n  -H \u0026quot;Content-Type: application/json\u0026quot; \\\\\\r\\n  -d \\\u0026#x27;{\\r\\n    \u0026quot;model\u0026quot;: \u0026quot;meta-llama/Llama-3.3-70B-Instruct\u0026quot;,\\r\\n    \u0026quot;messages\u0026quot;: [\\r\\n    {\\r\\n        \u0026quot;role\u0026quot;: \u0026quot;user\u0026quot;,\\r\\n        \u0026quot;content\u0026quot;: \u0026quot;what is the meaning of life ?\u0026quot;\\r\\n    }\\r\\n    ],\\r\\n    \u0026quot;stream\u0026quot;:false,\\r\\n    \u0026quot;max_tokens\u0026quot;: 30\\r\\n  }\\\u0026#x27; | jq -r \\\u0026#x27;.choices[0].message.content\\\u0026#x27;\\r\\n\\r\\n\\r\\n---\\r\\nThe question of the meaning of life is a complex and deeply philosophical one that has been debated by scholars, theologians, philosophers, and scientists for\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3e18bf4a77c0\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eGet started today\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eBy moving beyond the constraints of traditional serving, the new disaggregated inference recipe represents the future of efficient, scalable LLM inference. It enables you to right-size resources for each specific task, unlocking new performance paradigms and significant cost savings for your most demanding generative AI applications. We are excited to see how you will leverage this recipe to build the next wave of AI-powered services. We encourage you to try out our \u003c/span\u003e\u003ca href=\"https://github.com/AI-Hypercomputer/gpu-recipes/tree/main/inference/a3ultra/disaggregated-serving/dynamo\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eDynamo Disaggregated Inference Recipe\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e which provides a starting point with recommended configurations and easy steps. We hope you have fun experimenting and share your feedback!\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e"
    },
    {
      "title": "Deliver intuitive shopping experiences with Conversational Commerce agent",
      "link": "https://cloud.google.com/blog/products/ai-machine-learning/introducing-conversational-commerce-agent-on-vertex-ai/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-09-10T16:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eConsumer search behavior is shifting, with users now entering longer, more complex questions into search bars in pursuit of more relevant results. For instance, instead of a simple \"best kids snacks,\" queries have evolved to \"What are some nutritious snack options for a 7-year-old’s birthday party?\" \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eHowever, many digital platforms have yet to adapt to this new era of discovery, leaving shoppers frustrated as they find themselves sifting through extensive catalogs and manually applying filters. This results in quick abandonment and lost transactions, including an estimated\u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e \u003c/strong\u003e\u003ca href=\"https://cloud.google.com/blog/topics/retail/new-research-on-search-abandonment-in-retail?e=48754805\"\u003e\u003cstrong style=\"text-decoration: underline; vertical-align: baseline;\"\u003eannual global loss of $2 trillion\u003c/strong\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWe are excited to announce the general availability of Google Cloud’s \u003c/span\u003e\u003ca href=\"https://cloud.google.com/retail/docs/conversational-search\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eConversational Commerce agent\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e designed to engage shoppers in \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003enatural, human-like conversations to guide them \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003efrom initial intent to a completed purchase. Companies like \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAlbertsons Cos\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e., who was a marquee collaborator on this product and is using Conversational Commerce agent within their Ask AI tool, are already seeing an impact. Early results show customers using Ask AI \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eoften add one or more additional items to their cart\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, uncovering products they might not have found otherwise. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eYou can access Conversational Commerce agent today in the Vertex AI \u003c/span\u003e\u003ca href=\"https://cloud.google.com/solutions/vertex-ai-search-commerce?e=48754805\u0026amp;hl=en\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003econsole\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_IKmw1Mh.gif\"\n        \n          alt=\"1\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"q22sx\"\u003eShoppers can ask complex questions in their own words and find exactly what they're looking for through back-and-forth conversation that drives them to purchase.\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eIntroducing the next generation of retail experiences \u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eGo beyond traditional keyword search to deliver a personalized and streamlined shopping experience to drive revenue. Conversational Commerce agent integrates easily into your website and applications, guiding customers from discovery to purchase.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eConversational Commerce agent turns e-commerce challenges into opportunities through a more intuitive shopping experience: \u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eTurn your search into a sales associate:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e Unlike generic chatbots, our agent is built to sell. Its intelligent intent classifier understands \u003c/span\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003ehow\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e your customers are shopping and tailors their experience. Just browsing? Guide them with personalized, conversational search that inspires them to find—and buy—items they wouldn’t have found otherwise. Know exactly what they want? The agent defaults to traditional search results for simple queries.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eDrive revenue with natural conversation:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e Our agent leverages the power of Gemini to understand complex and ambiguous requests, suggest relevant products from your catalog, answer questions on product details, and even provide helpful details such as store hours. \u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eRe-engage returning shoppers: \u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe agent retains context across site interactions and devices. This allows returning customers to pick up exactly where they left off, creating a simplified journey that reduces friction and guides them back to their cart.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eSafety and responsibility built-in:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e You have complete control to boost, bury, or restrict products and categories from conversations. There are also safety controls in place, ensuring all interactions are helpful and brand-appropriate.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWe believe our ability to provide transformative business impact for e-commerce is affirmed by our recent positioning as a Leader in the \u003c/span\u003e\u003ca href=\"https://cloud.google.com/resources/content/gartner-mq-2025-vertex-ai\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003e2025 Gartner® Magic Quadrant™ for Search and Product Discovery\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_SOsr1a7.gif\"\n        \n          alt=\"2\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"q22sx\"\u003eComing soon: Unlock new methods of discovery for your customers. Shoppers can soon search with images and video, locate in-store products, find store hours, and connect with customer support.\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAlbertsons Cos. is leading the way in AI-powered product discovery\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAlbertsons Cos., is redefining how customers discover, plan and shop for groceries with Conversational Commerce agent. When Albertsons Cos. customers interacted with the Ask AI platform, \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003emore than 85% of conversations started with open-ended or exploratory questions\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e demonstrating the need for personalized guidance.  \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e\"At Albertsons Cos., we are focused on giving our customers the best experience possible for when and how they choose to shop,” said Jill Pavlovich, SVP, Digital Customer Experience for Albertsons Cos. \"By collaborating with Google Cloud to bring Conversational Commerce agent to market, we are delivering a more personalized interaction to help make our customers’ lives easier. Now they can digitally shop across aisles, plan quick meal ideas, discover new products, and even get recommendations for unexpected items that pair well together.\"\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe Ask AI tool \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eis accessible now via the search bar in all Albertsons Cos. banner apps\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, to help customers build smarter, faster baskets through simplified product discovery, personalized recommendations and a more intuitive shopping experience.\u003c/span\u003e\u003c/p\u003e\n\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eGet started\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eConversational Commerce agent guides customers to purchase, is optimized for revenue-per-visitor, and is available 24/7. Built on Vertex AI, onboarding is quick and easy, requiring minimal development effort.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTo get started with Vertex AI today, \u003c/span\u003e\u003ca href=\"https://cloud.google.com/contact?e=48754805\u0026amp;hl=en\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003econtact sales\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003chr/\u003e\n\u003cp\u003e\u003csup\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003eGartner, Magic Quadrant for Search and Product Discovery - Mike Lowndes, Noam Dorros, Sandy Shen, Aditya Vasudevan, June 24, 2025\u003c/span\u003e\u003c/sup\u003e\u003c/p\u003e\n\u003cp\u003e\u003csup\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003eDisclaimer: Gartner does not endorse any vendor, product or service depicted in its research publications, and does not advise technology users to select only those vendors with the highest ratings or other designation. Gartner research publications consist of the opinions of Gartner's research organization and should not be construed as statements of fact. Gartner disclaims all warranties, expressed or implied, with respect to this research, including any warranties of merchantability or fitness for a particular purpose. This graphic was published by Gartner, Inc. as part of a larger research document and should be evaluated in the context of the entire document. The Gartner document is available upon request from Google.\u003c/span\u003e\u003c/sup\u003e\u003c/p\u003e\n\u003cp\u003e\u003csup\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003eGARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally, and MAGIC QUADRANT is a registered trademark of Gartner, Inc. and/or its affiliates and are used herein with permission. All rights reserved.\u003c/span\u003e\u003c/sup\u003e\u003c/p\u003e\u003c/div\u003e"
    },
    {
      "title": "Automate app deployment and security analysis with new Gemini CLI extensions",
      "link": "https://cloud.google.com/blog/products/ai-machine-learning/automate-app-deployment-and-security-analysis-with-new-gemini-cli-extensions/",
      "source": "AI \u0026 Machine Learning",
      "category": "tech",
      "publishedAt": "2025-09-10T14:00:00Z",
      "description": "\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eFind and fix security vulnerabilities. Deploy your app to the cloud. All without leaving your command-line. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eToday, we’re closing the gap between your terminal and the cloud with a first look at the future of Gemini CLI, delivered through two new extensions: \u003c/span\u003e\u003ca href=\"https://github.com/google-gemini/gemini-cli-security/tree/main\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003esecurity extension\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e and \u003c/span\u003e\u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-run-mcp/?tab=readme-ov-file#use-as-a-gemini-cli-extension\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eCloud Run extension\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. These extensions are designed to handle critical parts of your workflows with simple, intuitive commands:\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e1)  \u003c/span\u003e\u003cstrong style=\"font-style: italic; vertical-align: baseline;\"\u003e/security:analyze\u003c/strong\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e \u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eperforms a comprehensive scan right in your local repository, with support for GitHub pull requests coming soon. This makes security a natural part of your development cycle.\u003c/span\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e2)  \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e/deploy\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e deploys your application to Cloud Run, our fully managed serverless platform, in just a few minutes. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThese commands are the first expression of a new extensibility framework for Gemini CLI. While we'll be sharing more about the full \u003c/span\u003e\u003ca href=\"https://github.com/google-gemini/gemini-cli/blob/main/docs/extension.md\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGemini CLI extension\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e world soon, we couldn't wait to get these capabilities into your hands. Consider this a sneak peak of what’s coming next!\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eSecurity extension: automate security analysis with /security:analyze \u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTo help teams address software vulnerabilities early in the development lifecycle, we are launching the \u003c/span\u003e\u003ca href=\"https://github.com/google-gemini/gemini-cli-security\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGemini CLI Security extension\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. This new open-source tool automates security analysis, enabling you to proactively catch and fix issues using the \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003e/security:analyze \u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003ecommand at the terminal or through a soon-coming GitHub Actions integration. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIntegrated directly into your local development workflow and CI/CD pipeline, this extension:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eAnalyzes code changes:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e When triggered, the extension automatically takes the \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003egit diff\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e of your local changes or pull request.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eIdentifies vulnerabilities:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e Using a specialized prompt and tools, Gemini CLI analyzes the changes for a wide range of potential vulnerabilities, such as hardcoded-secrets, injection vulnerabilities, broken access control, and insecure data handling.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eProvides actionable feedback:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e Gemini returns a detailed, easy-to-understand report directly in your terminal or as a comment on your pull request. This report doesn't just flag issues; it explains the potential risks and provides concrete suggestions for remediation, helping you fix issues quickly and learn as you go.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eAnd after the report is generated, you can also ask Gemini CLI to save it to disk or even implement fixes for each issue.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_Gemini_CLI_Security_Extension_Terminal_Gif.gif\"\n        \n          alt=\"1 Gemini CLI Security Extension Terminal Gif\"\u003e\n        \n        \u003c/a\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eGetting started with /security:analyze\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eIntegrating security analysis into your workflow is simple. First, download the Gemini CLI and install the extension \u003c/span\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003e(requires Gemini CLI v0.4.0+)\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;gemini extensions install https://github.com/google-gemini/gemini-cli-security\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3e18a9299a30\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThen you can start run your first scan:\u003c/span\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eLocally:\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e After making local changes, simply run \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e/security:analyze \u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e in the Gemini CLI.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli aria-level=\"1\" style=\"list-style-type: disc; vertical-align: baseline;\"\u003e\n\u003cp role=\"presentation\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eIn CI/CD (Coming Soon): \u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eWe're bringing security analysis directly into your CI/CD workflow. Soon,\u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e \u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eyou’ll be able to configure the GitHub Action to automatically review pull requests as they are opened.\u003c/span\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThis is just the beginning. The team is actively working on further enhancing the extension's capabilities, and we are also inviting the community to contribute to this open source project by reporting bugs, suggesting features, continuously improving security practices and submitting code improvements. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eFor complete documentation and to contribute, visit the \u003c/span\u003e\u003ca href=\"https://github.com/google-gemini/gemini-cli-security\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eofficial GitHub repository\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eCloud Run extension: automate deployment with \u003c/strong\u003e\u003cstrong style=\"font-style: italic; vertical-align: baseline;\"\u003e/deploy\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe\u003c/span\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003e \u003c/span\u003e\u003cstrong style=\"font-style: italic; vertical-align: baseline;\"\u003e/deploy\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e command in Gemini CLI automates the entire deployment pipeline for your web applications. You can now deploy a project directly from your local workspace. Once you issue the command, Gemini returns a public URL for your live application.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e/deploy\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e command automates a full CI/CD pipeline to deploy web applications and cloud services from the command line using the \u003c/span\u003e\u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-run-mcp/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eCloud Run MCP server\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. What used to be a multi-step process of building, containerizing, pushing, and configuring is now a single, intuitive command from within the Gemini CLI.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eYou can access this feature across three different surfaces – in Gemini CLI in the terminal, in VS Code via \u003c/span\u003e\u003ca href=\"https://codeassist.google/\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eGemini Code Assist\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e agent mode, and in Gemini CLI in \u003c/span\u003e\u003ca href=\"https://cloud.google.com/shell/docs\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eCloud Shell\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e. \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_aA6mg0y.gif\"\n        \n          alt=\"2\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"dvesx\"\u003eUse /deploy command in Gemini CLI at the terminal to deploy application to Cloud Run\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eGet started with /deploy:\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eFor existing Google Cloud users, getting started with \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e/deploy\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e is straightforward in Gemini CLI at the terminal:\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003ePrerequisites:\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e You'll need the gcloud CLI installed and configured on your machine and have an existing app or use Gemini CLI to create one.\u003c/span\u003e\u003c/p\u003e\n\u003cp style=\"padding-left: 40px;\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eStep 1: Install the Cloud Run extension\u003cbr/\u003e\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e/deploy\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e command is enabled through a \u003c/span\u003e\u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-run-mcp\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eModel Context Protocol (MCP) server\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, which is included in the Cloud Run extension.  To install the Cloud Run extension \u003c/span\u003e\u003cspan style=\"font-style: italic; vertical-align: baseline;\"\u003e(Requires Gemini CLI v0.4.0+)\u003c/span\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, run this command:  \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;gemini extensions install https://github.com/GoogleCloudPlatform/cloud-run-mcp\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3e18a9299df0\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp style=\"padding-left: 40px;\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eStep 2: Authenticate with Google Cloud\u003cbr/\u003e\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eEnsure your local environment is authenticated to your Google Cloud account by running:\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\n    \u003cdt\u003ecode_block\u003c/dt\u003e\n    \u003cdd\u003e\u0026lt;ListValue: [StructValue([(\u0026#x27;code\u0026#x27;, \u0026#x27;gcloud auth login\\r\\ngcloud auth application-default login\u0026#x27;), (\u0026#x27;language\u0026#x27;, \u0026#x27;\u0026#x27;), (\u0026#x27;caption\u0026#x27;, \u0026lt;wagtail.rich_text.RichText object at 0x3e18a92995b0\u0026gt;)])]\u0026gt;\u003c/dd\u003e\n\u003c/dl\u003e\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003cp style=\"padding-left: 40px;\"\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eStep 3: Deploy your app\u003cbr/\u003e\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eNavigate to your application's root directory in your terminal and type \u003c/span\u003e\u003ccode style=\"vertical-align: baseline;\"\u003egemini\u003c/code\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to launch Gemini CLI. Once inside, type \u003c/span\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003e/deploy\u003c/strong\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e to deploy your app to Cloud Run.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThat's it! In a few moments, Gemini CLI will return a public URL where you can access your newly deployed application. You can also visit the Google Cloud Console to see your new service running in Cloud Run. \u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eBesides Gemini CLI at the terminal, this feature can also be accessed  in VS Code via Gemini Code Assist \u003c/span\u003e\u003ca href=\"https://cloud.google.com/gemini/docs/codeassist/release-notes\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003eagent mode\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e, powered by Gemini CLI,  and in Gemini CLI in Cloud Shell, where the authentication step will be automatically handled out of the box.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\n\u003cdiv class=\"block-image_full_width\"\u003e\n\n\n\n\n\n\n  \n    \u003cdiv class=\"article-module h-c-page\"\u003e\n      \u003cdiv class=\"h-c-grid\"\u003e\n  \n\n    \u003cfigure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \"\n      \u003e\n\n      \n      \n        \n        \u003cimg\n            src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/3_deploy-agentmode.gif\"\n        \n          alt=\"3 deploy-agentmode\"\u003e\n        \n        \u003c/a\u003e\n      \n        \u003cfigcaption class=\"article-image__caption \"\u003e\u003cp data-block-key=\"dvesx\"\u003eUse /deploy command to deploy application to Cloud Run in VS Code via Gemini Code Assist agent mode.\u003c/p\u003e\u003c/figcaption\u003e\n      \n    \u003c/figure\u003e\n\n  \n      \u003c/div\u003e\n    \u003c/div\u003e\n  \n\n\n\n\n\u003c/div\u003e\n\u003cdiv class=\"block-paragraph_advanced\"\u003e\u003ch3\u003e\u003cstrong style=\"vertical-align: baseline;\"\u003eBuilding a robust extension ecosystem  \u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eThe Security and Cloud Run extensions are two of the first extensions from Google built on our new framework, which is designed to create a rich and open ecosystem for the Gemini CLI. We are building a platform that will allow any developer to extend and customize the CLI's capabilities, and this is just an early preview of the full platform's potential. We will be sharing a more comprehensive look at our extensions platform soon, including how you can start building and sharing your own.\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003e\u003cspan style=\"vertical-align: baseline;\"\u003eTry Gemini CLI today, visit the GitHub \u003c/span\u003e\u003ca href=\"http://github.com/google-gemini/gemini-cli\" rel=\"noopener\" target=\"_blank\"\u003e\u003cspan style=\"text-decoration: underline; vertical-align: baseline;\"\u003ehere\u003c/span\u003e\u003c/a\u003e\u003cspan style=\"vertical-align: baseline;\"\u003e.\u003c/span\u003e\u003c/p\u003e\u003c/div\u003e"
    }
  ],
  "generatedAt": "2025-09-11T07:08:19.107355752+09:00"
}
